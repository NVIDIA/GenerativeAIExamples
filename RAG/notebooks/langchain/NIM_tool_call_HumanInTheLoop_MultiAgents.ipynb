{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ba963de-02e7-44c5-ada0-b74bb092064e",
   "metadata": {},
   "source": [
    "\n",
    "# Incorporating human-in-the-loop in agentic logic via LangGraph \n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "To run this notebook, you need to [follow the steps from here](https://python.langchain.com/docs/integrations/text_embedding/nvidia_ai_endpoints#setup) and generate an API key from [NVIDIA API Catalog](https://build.nvidia.com/).\n",
    "\n",
    "Please ensure you have the following dependencies installed  :\n",
    "\n",
    "- langchain\n",
    "- jupyterlab==4.0.8\n",
    "- langchain-core\n",
    "- langchain-nvidia-ai-endpoints==0.2.0\n",
    "- markdown\n",
    "- colorama\n",
    "\n",
    "you will also need to install the following -\n",
    "\n",
    "\n",
    "\n",
    "This notebook will walk you though how to incoporate **human-in-the-loop** into a **multi-agents** pipeline in a minimalistic examples.\n",
    "\n",
    "The cognitive agentic architecture will look like the below :\n",
    "\n",
    "![agent architecture](./data/imgs/HumanInTheLoopLangGraph.png) \n",
    "\n",
    "\n",
    "We will first construct the 2 agents in the middle : \n",
    "\n",
    "- Using **meta/llama-3.1-405b-instruct** to construct the 2 agents, each will be created with [LCEL expression ](https://python.langchain.com/v0.1/docs/expression_language/)\n",
    "\n",
    "- then we will give each agent one tool to use to achieve the task\n",
    "\n",
    "The task at hand is creating promotion assets with text and image for social medial promotion.\n",
    "We are aiming for something similar to the below ...\n",
    "\n",
    "\n",
    "<img src=\"./data/imgs/finish_social_post.png\" width=\"25%\"/>\n",
    "\n",
    "\n",
    "Just like in real world, a human in charge of the task will delegate tasks to specalist writer to writ the promotion text and assign a digital artist for the artworks.\n",
    "\n",
    "In this scenario, we will let human assign an agent ( either **ContentCreator** or **DigitalArtist** ) just like the flow depicted above. \n",
    "    \n",
    "\n",
    "\n",
    "Note: As one can see, since we are using NVIDIA AI Catalog as an API, there is no further requirement in the prerequisites about GPUs as compute hardware\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd38971e-d3c4-4adc-9986-c1d5f3ccabd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## install a few python packages we will need\n",
    "#!pip install colorama markdown langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7285dbc-31ce-4a95-aee9-901e472c5073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "## API Key can be found by going to NVIDIA NGC -> AI Foundation Models -> (some model) -> Get API Code or similar.\n",
    "## 10K free queries to any endpoint (which is a lot actually).\n",
    "\n",
    "# del os.environ['NVIDIA_API_KEY']  ## delete key and reset\n",
    "if os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    print(\"Valid NVIDIA_API_KEY already in environment. Delete to reset\")\n",
    "else:\n",
    "    global nvapi_key\n",
    "    nvapi_key = getpass.getpass(\"NVAPI Key (starts with nvapi-): \")\n",
    "    assert nvapi_key.startswith(\"nvapi-\"), f\"{nvapi_key[:5]}... is not a valid key\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvapi_key\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a190d598-f2bc-4662-aad2-a69edd247c3b",
   "metadata": {},
   "source": [
    "## We will prepare the 2 agents , each is made out of [LCEL expression ](https://python.langchain.com/v0.1/docs/expression_language/)\n",
    "\n",
    "For simplicity , each agent will be given one tool to use.\n",
    "\n",
    "- a **content_creator** agent which will create promotion message per input **_product_desc_**\n",
    "- an **digital_artist** agent what is able to create visually appealing image from the promotion title\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166362e6-f511-4c3f-9c52-50df49452ce1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1 : construct **content_creator** agent \n",
    "\n",
    "in order to construct the **content_creator** agent we need the following :\n",
    "\n",
    "- system prompt which anchor the task for the agent\n",
    "\n",
    "- provide a seeded product desc  \n",
    "\n",
    "- a powerful LLM [llama3.1-405b from NVIDIA NIM](https://build.nvidia.com/meta/llama-3_1-405b-instruct) \n",
    "\n",
    "- using **with_structured_output** for formatting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c20c3e5-b620-4bb6-996b-b402958bef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test run and see that you can genreate a respond successfully \n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain import prompts, chat_models, hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from typing import Optional, List\n",
    "\n",
    "## construct the system prompt \n",
    "prompt_template = \"\"\"\n",
    "### [INST]\n",
    "\n",
    "You are an expert social media content creator.\n",
    "Your task is to create a different promotion message with the following \n",
    "Product Description :\n",
    "------\n",
    "{product_desc}\n",
    "------\n",
    "\n",
    "The output promotion message MUST use the following format :\n",
    "\n",
    "'''\n",
    "Title: a powerful, short message that dipict what this product is about \n",
    "Message: be creative for the promotion message, but make it short and ready for social media feeds.\n",
    "Tags: the hash tag human will nomally use in social media\n",
    "'''\n",
    "\n",
    "Begin!\n",
    "\n",
    "[/INST]\n",
    " \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "input_variables=['produce_desc'],\n",
    "template=prompt_template,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "## provide the product_desc\n",
    "product_desc=\"Explore the latest community-built AI models with an API optimized and accelerated by NVIDIA, then deploy anywhere with NVIDIA NIMâ„¢ inference microservices.\"\n",
    "\n",
    "## structural output using LMFE \n",
    "class StructureOutput(BaseModel):     \n",
    "    Title: str = Field(description=\"Title of the promotion message\")\n",
    "    Message : str = Field(description=\"The actual promption message\")\n",
    "    Tags: List[str] = Field(description=\"Hash tags for social media, usually starts with #\")\n",
    "\n",
    "llm_with_output_structure=ChatNVIDIA(model=\"meta/llama-3.1-405b-instruct\").with_structured_output(StructureOutput)     \n",
    "\n",
    "## construct the content_creator agent\n",
    "content_creator = ( prompt | llm_with_output_structure )\n",
    "out=content_creator.invoke({\"product_desc\":product_desc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1416b3-02d8-4d1a-8362-aa9d6bb1e5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.Title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a508c-81ec-4f20-9cc2-d762d3d5e3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6208b390-cf0a-44a8-8cc5-ef517e7ef1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db74d3c-f6bd-43dd-8f14-9d2f4e35e7f5",
   "metadata": {},
   "source": [
    "## Step 2 : we will now create **digital_artist** agent \n",
    "\n",
    "We will equip the **digital_artist** with the following :\n",
    "\n",
    "- a text-to-image model [stableXL-turbo from NVIDIA NIM ](https://build.nvidia.com/explore/visual-design?snippet_tab=Python#sdxl-turbo)\n",
    "- wrap this tool into llm with llm.bind_tools\n",
    "- construct our **digital_artist** agent with LCEL expression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bc0564-11e4-4ae9-b952-969cfa624865",
   "metadata": {},
   "source": [
    "##  a text-to-image model [stableXL-turbo from NVIDIA NIM ](https://build.nvidia.com/explore/visual-design?snippet_tab=Python#sdxl-turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca69380-937e-46d2-b4a0-37fd2899045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test run and see that you can genreate a respond successfully \n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain import prompts, chat_models, hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "\n",
    "def llm_rewrite_to_image_prompts(user_query):\n",
    "    prompt = prompts.ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"Summarize the following user query into a very short, one-sentence theme for image generation, MUST follow this format : A iconic, futuristic image of , no text, no amputation, no face, bright, vibrant\",\n",
    "            ),\n",
    "            (\"user\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    model = ChatNVIDIA(model=\"mistralai/mixtral-8x7b-instruct-v0.1\")\n",
    "    chain = ( prompt    | model   | StrOutputParser() )\n",
    "    out= chain.invoke({\"input\":user_query})\n",
    "    #print(type(out))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599ebaf2-4c79-4cf4-a7c9-53971c9238e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64, io\n",
    "from PIL import Image\n",
    "import requests, json\n",
    "def generate_image(prompt :str) -> str :\n",
    "    \"\"\"\n",
    "    generate image from text\n",
    "    Args:\n",
    "        prompt: input text\n",
    "    \"\"\"\n",
    "    ## re-writing the input promotion title in to appropriate image_gen prompt \n",
    "    gen_prompt=llm_rewrite_to_image_prompts(prompt)\n",
    "    print(\"start generating image with llm re-write prompt:\", gen_prompt)\n",
    "    invoke_url = \"https://ai.api.nvidia.com/v1/genai/stabilityai/sdxl-turbo\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {nvapi_key}\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    }\n",
    "    \n",
    "    payload = {\n",
    "        \"text_prompts\": [{\"text\": gen_prompt}],\n",
    "        \"seed\": 0,\n",
    "        \"sampler\": \"K_EULER_ANCESTRAL\",\n",
    "        \"steps\": 2\n",
    "    }\n",
    "    \n",
    "    response = requests.post(invoke_url, headers=headers, json=payload)\n",
    "    \n",
    "    response.raise_for_status()\n",
    "    response_body = response.json()\n",
    "    ## load back to numpy array \n",
    "    print(response_body['artifacts'][0].keys())\n",
    "    imgdata = base64.b64decode(response_body[\"artifacts\"][0][\"base64\"])\n",
    "    filename = 'output.jpg'\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(imgdata)   \n",
    "    im = Image.open(filename)  \n",
    "    img_location=f\"the output of the generated image will be stored in this path : {filename}\"\n",
    "    return img_location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fed6358-8d59-4b11-ab71-8387f1415526",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=generate_image(\"NVIDIA NeMo is a powerful SDK for all your GenAI needs\")\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36422d22-1155-4a71-abd8-3078f172d6e0",
   "metadata": {},
   "source": [
    "## Wrap the tool into llm with **llm.bind_tools**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcdbc6c-00c3-4d01-a55f-86483d42eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatNVIDIA(model=\"meta/llama-3.1-405b-instruct\")\n",
    "llm_with_img_gen_tool=llm.bind_tools([generate_image],tool_choice=\"generate_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee33b1a-b02b-4e8a-9260-2c2c815afec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=llm_with_img_gen_tool.invoke(\"NVIDIA power GenAI workflow\")\n",
    "out.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77f5ac2-49b8-468c-95db-740c80acdd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_to_invoke_tools(out):\n",
    "    tool_calls=out.tool_calls\n",
    "    ## check there are indeed tool_calls in the output\n",
    "    if len(tool_calls) > 0 :\n",
    "        ## assert the args attribute exists \n",
    "        if 'args' in tool_calls[0] :            \n",
    "            \n",
    "            prompt=tool_calls[0]['args']['prompt']\n",
    "            output=generate_image(prompt)\n",
    "        else:\n",
    "            print(\"### out.tool_calls\", out.tool_calls[0].keys() )\n",
    "            output=\"cannot find input prompt from llm output, please rerun again\"\n",
    "    else:\n",
    "        print(\"------------\" , out)\n",
    "        print(\"### out.tool_calls\", out.tool_calls )\n",
    "        output=\"agent did not find generate_image tool, please check the tool binding is successful\"\n",
    "    return output\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11458491-bb01-4ee5-9eb0-ceff5c5593b8",
   "metadata": {},
   "source": [
    "## creating **digital_artist** using LCEL chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb3f231-9096-458d-989c-1b8908b6d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_artist = (\n",
    "    llm_with_img_gen_tool\n",
    "    | output_to_invoke_tools\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3e6616-2e4f-4673-a486-2ec42723a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_artist.invoke(\"NVIDIA power GenAI workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b8b225-ea9a-4d3f-857a-39fd99afde13",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3 - Embed Human-in-the-loop agentic logic with LangGraph\n",
    "\n",
    "- construct a **get_human_input** function to integrate into the first node of LangGraph putting Human-in-the-loop deciding which tool to use\n",
    "- establish **State** to keep track of the internal states\n",
    "- create functions as graph nodes for LangGraph \n",
    "- compose the agentic cognitive logic in langGraph by connecting the nodes and edges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879af9be-472d-466d-9cb4-cc3a7fa86f2c",
   "metadata": {},
   "source": [
    "## construct a **get_human_input** function to integrate into the first node of LangGraph \n",
    "\n",
    "putting Human-in-the-loop deciding which tool to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cae427-1b34-4f2d-854f-3c765d2ab6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or you can directly instantiate the tool\n",
    "from langchain_community.tools import HumanInputRun\n",
    "from langchain.agents import AgentType, load_tools\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "\n",
    "\n",
    "def get_human_input() -> str:\n",
    "    \"\"\" Put human as decision maker, human will decide which agent is best for the task\"\"\"\n",
    "    \n",
    "    print(\"You have been given 2 agents. Please select exactly _ONE_ agent to help you with the task, enter 'y' to confirm your choice.\")\n",
    "    print(\"\"\"Available agents are : \\n\n",
    "            1 ContentCreator  \\n\n",
    "            2 DigitalArtist \\n          \n",
    "            Enter 1 or 2\"\"\")\n",
    "    contents = []\n",
    "    while True:\n",
    "        try:            \n",
    "            line = input()\n",
    "            if line=='1':\n",
    "                tool=\"ContentCreator\"                \n",
    "                line=tool\n",
    "                \n",
    "            elif line=='2':\n",
    "                tool=\"DigitalArtist\"                \n",
    "                line=tool\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        except EOFError:\n",
    "            break\n",
    "        if line == \"y\":\n",
    "            print(f\"tool selected : {tool} \")\n",
    "            break\n",
    "        contents.append(line)\n",
    "        \n",
    "    return \"\\n\".join(contents)\n",
    "\n",
    "\n",
    "# You can modify the tool when loading\n",
    "\n",
    "ask_human = HumanInputRun(input_func=get_human_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2528761f-d478-4d04-b22b-d1cc55a49d6c",
   "metadata": {},
   "source": [
    "## establish **State** to keep track of the internal states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8bb5db-80c9-4f62-a0bb-572e376c3a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## first we define GraphState \n",
    "from typing import Dict, TypedDict\n",
    "from typing import TypedDict, Annotated, List, Union\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "import operator\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "class State(TypedDict):\n",
    "    # The input string\n",
    "    input: str\n",
    "    input_to_agent : str\n",
    "    agent_choice : str\n",
    "    agent_use_tool_respond : str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ede35dc-e8b2-4bac-94bb-6b7aa283157d",
   "metadata": {},
   "source": [
    "## create functions as graph nodes for LangGraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e6051c-c732-4e3f-8e09-f006cfff352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "from colorama  import Fore,Style\n",
    "# Define the functions needed \n",
    "def human_assign_to_agent(state):\n",
    "    # ensure using original prompt \n",
    "    inputs = state[\"input\"]\n",
    "    input_to_agent = state[\"input_to_agent\"]\n",
    "\n",
    "    concatenate_str = Fore.BLUE+inputs+ ' : '+Fore.CYAN+input_to_agent + Fore.RESET\n",
    "    print(concatenate_str)\n",
    "    print(\"---\"*10)\n",
    "    \n",
    "    agent_choice=ask_human.invoke(concatenate_str)\n",
    "    print(Fore.CYAN+ \"choosen_agent : \" + agent_choice + Fore.RESET)\n",
    "    return {\"agent_choice\": agent_choice }\n",
    "\n",
    "def agent_execute_task(state):    \n",
    "    inputs= state[\"input\"]\n",
    "    input_to_agent = state[\"input_to_agent\"]\n",
    "    print(Fore.CYAN+input_to_agent + Fore.RESET)\n",
    "    # choosen agent will execute the task\n",
    "    choosen_agent = state['agent_choice']\n",
    "    if choosen_agent=='ContentCreator':\n",
    "        structured_respond=content_creator.invoke({\"product_desc\":input_to_agent})\n",
    "        respond='\\n'.join([structured_respond.Title,structured_respond.Message,''.join(structured_respond.Tags)])       \n",
    "    elif choosen_agent==\"DigitalArtist\":\n",
    "        respond=digital_artist.invoke(input_to_agent)\n",
    "    else:\n",
    "        respond=\"please reselect the agent, there are only 2 agents available: 1.ContentCreator or 2.DigitalArtist\"\n",
    "        \n",
    "    \n",
    "    print(Fore.CYAN+ \"agent_output: \\n\" + respond + Fore.RESET)\n",
    "\n",
    "    return {\"agent_use_tool_respond\": respond}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fedc500-a3d0-468d-b1b1-582d3e1145f6",
   "metadata": {},
   "source": [
    "## compose the agentic cognitive logic in langGraph by connecting the nodes and edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c30754b-6399-47c9-9bb1-bbc8f304d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Define the two nodes \n",
    "workflow.add_node(\"start\", human_assign_to_agent)\n",
    "workflow.add_node(\"end\", agent_execute_task)\n",
    "\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"start\")\n",
    "workflow.add_edge(\"start\", \"end\")\n",
    "workflow.add_edge(\"end\", END)\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f0ac2a-c57d-4e2b-814d-44b040272a01",
   "metadata": {},
   "source": [
    "---\n",
    "## time to test this out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5fe0c9-c922-4b0d-bb94-ac47c140e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_query=\"create a good promption message for social promotion events using the following inputs\"\n",
    "product_desc=\"NVIDIA NIM microservices power GenAI workflow\"\n",
    "respond=app.invoke({\"input\":my_query, \"input_to_agent\":product_desc})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d086169b-e38d-4506-a6dd-5b55d5246db3",
   "metadata": {},
   "source": [
    "#### now we will use the output from the **ContentCreator** agent to go for a 2nd round to generate beautiful image for this promotion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f64885a-0302-4548-be2f-79b81f0fdeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_for_image=respond['agent_use_tool_respond'].split('\\n')[0].split(':')[-1].strip()\n",
    "prompt_for_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e2e1b2-c257-46ee-b241-9d56b99f7479",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_query=\"generate an image for me from the below promotion message\"\n",
    "respond2=app.invoke({\"input\":input_query, \"input_to_agent\":prompt_for_image})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6afdfd1-1e5d-4861-84fd-5f8da527f3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('output.jpg')  \n",
    "im.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b646514b-9fe4-4cc2-a3b5-24b9fe06961e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## let's try to print this out using markdown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dede634-2dc4-4312-8649-31ded97e6979",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = respond['agent_use_tool_respond'].split('\\n')[0].split(':')[-1].strip()\n",
    "promotion_msg = respond['agent_use_tool_respond'].split('\\n')[1].split(':')[-1].strip()\n",
    "hash_tags =  ['#'+s for s in respond['agent_use_tool_respond'].split('\\n')[-1].split(':')[-1].split('#') if s!=\"\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8df416c-6f3c-4a79-ba0a-67f66c4be2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_tag_in_md=[]\n",
    "for hash_tag in hash_tags:\n",
    "    \n",
    "    temp=f\"\"\"<span>{hash_tag}</span>\"\"\"\n",
    "    hash_tag_in_md.append(temp)\n",
    "\n",
    "hashtags_in_md= '<br>'+ ''.join(hash_tag_in_md) + '</br>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fee6c74-e2bd-4701-be6f-4bf05bbf7560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "import markdown\n",
    "markdown_str = markdown.markdown(f'''\n",
    "<img src=\"output.jpg\" width=600 height=480 class=center/>\n",
    "\n",
    "\n",
    "#### {title}\n",
    "\n",
    "{promotion_msg}\n",
    "\n",
    "{hashtags_in_md}\n",
    "\n",
    "''')\n",
    "\n",
    "def printmd(markdown_str):\n",
    "    display(Markdown(markdown_str))\n",
    "printmd(markdown_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
