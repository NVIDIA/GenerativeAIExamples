{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Securing Generative AI Deployments with NVIDIA NIM Microservices and NVIDIA NeMo Guardrails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating NVIDIA NIMs with NeMo Guardrails\n",
    "\n",
    "This tutorial contains all of the code snippets presented in the technical blog [Securing Generative AI Deployments with NVIDIA NIM and NVIDIA NeMo Guardrails](https://developer.nvidia.com/blog/securing-generative-ai-deployments-with-nvidia-nim-and-nvidia-nemo-guardrails/) in a complete notebook. Please feel free to read the blog for full context.\n",
    "\n",
    "As a reference for how to deploy NIM on your chosen infrastructure, check out this [simple guide to deploying a NIM container and testing an inference request](https://developer.nvidia.com/blog/a-simple-guide-to-deploying-generative-ai-with-nvidia-nim/). \n",
    "\n",
    "In this tutorial, we deploy two NIM microservices — a NeMo Retriever Embedding NIM and an LLM NIM.  We then integrate both with NeMo Guardrails to prevent malicious use in the form of user account hacking attempted through queries that pertain to personal data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the LLM NIM, we use Meta’s new [Llama-3.1-70B-Instruct](https://build.nvidia.com/meta/llama-3_1-70b-instruct) model. For the embedding NIM, we use NVIDIA’s new [EmbedQA-E5-V5](https://build.nvidia.com/nvidia/nv-embedqa-e5-v5). The NeMo Retriever Embedding NIM assists the guardrails by converting each input query into an embedding vector. This enables efficient comparison with guardrails policies, ensuring that the query does not match with any prohibited or out-of-scope policies, thereby preventing the LLM NIM from giving unauthorized outputs. \n",
    "\n",
    "By integrating these NIM with NeMo Guardrails, we accelerate the performance of safety filtering and dialog management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will cover: \n",
    "* Defining the use case\n",
    "* Setting up a guardrailing system with NIM\n",
    "* Testing the integration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we demonstrate how to intercept any incoming user questions that pertain to personal data using topical rails. These rails ensure the LLM response adheres to topics which do not share any sensitive information. They also help to keep the LLM outputs on track by fact-checking before answering the user's questions. The integration pattern of these rails with the NIMs can be seen in the figure below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![An architectural diagram showing how Guardrails runtime works with the application code and the NIMs](guardrails-nim-architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a guardrailing system with NIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, let’s make sure that our NeMo Guardrails library is up to date with the latest version. The version that would work with this tutorial is 0.9.1.1 or later.\n",
    "\n",
    "We can check the version of the NeMo Guardrails library by running the following command in the terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nemoguardrails --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not have [NeMo Guardrails](https://pypi.org/project/nemoguardrails/) installed, run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nemoguardrails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have versions that are older than 0.9.1.1, upgrade to the latest version by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nemoguardrails --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is defining the configuration of the guardrails. To learn more, see the [configuration guide](https://docs.nvidia.com/nemo/guardrails/user_guides/configuration-guide.html). We start by creating the config directory as follows:\n",
    "\n",
    "\n",
    "```\n",
    "├── config\n",
    "│   ├── config.yml\n",
    "│   ├── flows.co\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p config\n",
    "!touch config/config.yml\n",
    "!touch config/flows.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `config.yml` file, we configure the NIM as follows:\n",
    "* if you'd like to use [NVIDIA-hosted NIMs](https://build.nvidia.com/), comment out the parameters and base_url lines\n",
    "* if you'd like to use your self-hosted NIMs, replace <BASE_URL_LLM_NIM> and <BASE_URL_EMBEDDING_NIM> with your own base URL for the NIMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_yml_content = '''models:\n",
    "  - type: main\n",
    "    engine: nvidia_ai_endpoints\n",
    "    model: meta/llama-3.1-70b-instruct\n",
    "    # parameters:\n",
    "    #   base_url: <BASE_URL_LLM_NIM>\n",
    "  - type: embeddings\n",
    "    engine: nvidia_ai_endpoints\n",
    "    model: nvidia/nv-embedqa-e5-v5\n",
    "    # parameters:\n",
    "    #   base_url: <BASE_URL_EMBEDDING_NIM>\n",
    "'''\n",
    "\n",
    "with open('config/config.yml', 'w') as file:\n",
    "  file.write(config_yml_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are testing with NVIDIA-hosted NIMs, remove `parameters` and `base_url` from the `config.yml` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the `config.yml` has the correct content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/config.yml', 'r') as file:\n",
    "    contents = file.read()\n",
    "    print(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the configuration is added with the respective NIM, we can add rails in the flows.co file. An example of adding dialog rails is as follows:\n",
    "\n",
    "```\n",
    "define user greet\n",
    "  \"Hello\"\n",
    "\n",
    "define bot greet\n",
    "  \"Hello. I'm the Guardrails Bot. How can I help you?\"\n",
    "\n",
    "define flow\n",
    "  user greet\n",
    "  bot greet\n",
    "```\n",
    "\n",
    "The script above shows a simple dialog rail that explicitly greets the user in a specific manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add more dialog rails in the flows.co file as follows:\n",
    "\n",
    "```\n",
    "define user ask about user sensitive data\n",
    "  \"Can you hack into someone's email account?\"\n",
    "  \"How do I get my friend's photos without permission?\"\n",
    "\n",
    "define bot refuse to respond about user sensitive data\n",
    "  \"Apologies, but the Guardrails Bot can't help with actions that asks about user sensitive data. It's important to respect privacy.\"\n",
    "\n",
    "define flow\n",
    "  user ask about user sensitive data\n",
    "  bot refuse to respond about user sensitive data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_co_content = '''define user greet\n",
    "  \"Hello\"\n",
    "\n",
    "define bot greet\n",
    "  \"Hello. I'm the Guardrails Bot. How can I help you?\"\n",
    "\n",
    "define flow\n",
    "  user greet\n",
    "  bot greet\n",
    "\n",
    "define user ask about user sensitive data\n",
    "  \"Can you hack into someone's email account?\"\n",
    "  \"How do I get my friend's photos without permission?\"\n",
    "\n",
    "define bot refuse to respond about user sensitive data\n",
    "  \"Apologies, but the Guardrails Bot can't help with actions that asks about user sensitive data. It's important to respect privacy.\"\n",
    "\n",
    "define flow\n",
    "  user ask about user sensitive data\n",
    "  bot refuse to respond about user sensitive data'''\n",
    "\n",
    "with open('config/flows.co', 'w') as file:\n",
    "  file.write(flows_co_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the `flows.co` has the correct content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config/flows.co', 'r') as file:\n",
    "    contents = file.read()\n",
    "    print(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Colang and YAML files in the config folder, we should be ready to set up our guardrails. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can import the related libraries and import the config folder to instantiate our guardrails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemoguardrails import RailsConfig, LLMRails\n",
    "\n",
    "config = RailsConfig.from_path('config')\n",
    "rails = LLMRails(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to test out our guardrails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we greet our LLM NIM through our guardrails and see if the guardrails pick up one of the predefined dialog rails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rails.generate(messages=[{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Hi!\"\n",
    "}])\n",
    "print(response['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, our query to the LLM NIM is intercepted by the guardrails that we have set up because our query matches with one of the predefined dialog rails. The NeMo Retriever Embedding NIM assists our guardrails in turning our query into an embedding vector. Our guardrails then perform a semantic search to return the most similar results of the utterances that we provide as part of `flows.co`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we ask the LLM NIM to provide us with a way to hack into a phone. This query falls into the category of topics pertaining to personal data. This is expected to be blocked by the guardrails based on the configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rails.generate(messages=[{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"How can I hack into my partner's phone?\"\n",
    "}])\n",
    "print(response['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen, our guardrails are able to intercept the message and block the LLM NIM from responding to the query since we have defined dialog rails to prevent further discussion of this topic.\n",
    "\n",
    "The tutorial above is for users to only get started with a simple use case. To create a more robust guardrailing system, users are encouraged to set up [various types of rails](https://docs.nvidia.com/nemo/guardrails/user_guides/guardrails-library.html) allowing for further customization of their use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post, we detailed the steps for integrating NVIDIA NIMs with NeMo Guardrails. In this instance, we were able to stop our application from responding to questions pertaining to personal data. With the integration of NVIDIA NIMs and NeMo Guardrails, developers are able to deploy AI models to production quickly and safely. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
