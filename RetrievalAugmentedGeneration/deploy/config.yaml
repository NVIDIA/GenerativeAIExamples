milvus:
  # The configuration of the Milvus connection.

  url: "http://milvus:19530"
  # The location of the Milvus Server.
  # Type: str
  # ENV Variable: APP_MILVUS_URL

triton:
  # The configuration for the Triton server hosting the embedding models.

  server_url: triton:8001
  # The location of the Triton server hosting the embedding model.
  # Type: str
  # ENV Variable: APP_TRITON_SERVERURL

  model_name: ensemble
  # The name of the hosted model.
  # Type: str
  # ENV Variable: APP_TRITON_MODELNAME


text_splitter:
  # The configuration for the Text Splitter.

  chunk_size: 510
  # Chunk size for text splitting.
  # Type: int

  chunk_overlap: 200
  # Overlapping text length for splitting.
  # Type: int

embeddings:
  # The configuration embedding models.

  model_name: intfloat/e5-large-v2
  # The name embedding search model from huggingface.
  # Type: str

prompts:
  # The configuration for the prompts used for response generation.

  chat_template:
    <s>[INST] <<SYS>>You are a helpful, respectful and honest assistant.Always answer as helpfully as possible, while being safe.Please ensure that your responses are positive in nature.<</SYS>>[/INST] {context_str} </s><s>[INST] {query_str} [/INST]
  # The chat prompt template guides the model to generate responses for queries.
  # Type: str

  rag_template:
    "<s>[INST] <<SYS>>Use the following context to answer the user's question. If you don't know the answer,just say that you don't know, don't try to make up an answer.<</SYS>><s>[INST] Context: {context_str} Question: {query_str} Only return the helpful answer below and nothing else. Helpful answer:[/INST]"
  # The RAG prompt template instructs the model to generate responses for queries while utilizing knowledge base.
  # Type: str
