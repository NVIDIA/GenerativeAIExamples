<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Kimi K2.5: Visual Agentic Intelligence</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem;
            background: #fafafa;
        }
        
        h1 {
            font-size: 2rem;
            color: #1a1a1a;
            margin-bottom: 0.5rem;
        }
        
        .authors {
            color: #666;
            font-size: 0.9rem;
            margin-bottom: 2rem;
        }
        
        h2 {
            font-size: 1.3rem;
            color: #2c3e50;
            margin-top: 2rem;
            margin-bottom: 1rem;
            border-bottom: 2px solid #e0e0e0;
            padding-bottom: 0.5rem;
        }
        
        .abstract {
            background: white;
            padding: 1.5rem;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            margin-bottom: 2rem;
        }
        
        ul {
            list-style-position: inside;
            margin-left: 1rem;
        }
        
        li {
            margin-bottom: 0.5rem;
        }
        
        .animation-container {
            background: white;
            padding: 2rem;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            margin: 2rem 0;
            height: 400px;
            position: relative;
            overflow: hidden;
        }
        
        .animation-title {
            text-align: center;
            font-weight: bold;
            margin-bottom: 1rem;
            color: #2c3e50;
        }
        
        .swarm-diagram {
            position: relative;
            width: 100%;
            height: 100%;
        }
        
        .orchestrator {
            position: absolute;
            width: 80px;
            height: 80px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 50%;
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%);
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-weight: bold;
            font-size: 0.8rem;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
            z-index: 10;
        }
        
        .subagent {
            position: absolute;
            width: 60px;
            height: 60px;
            background: #f8f9fa;
            border: 2px solid #4facfe;
            border-radius: 12px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 0.7rem;
            text-align: center;
            color: #2c3e50;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        
        .subagent:nth-child(1) { left: 50%; top: 10%; transform: translate(-50%, 0); }
        .subagent:nth-child(2) { right: 10%; top: 30%; }
        .subagent:nth-child(3) { right: 10%; bottom: 30%; }
        .subagent:nth-child(4) { left: 50%; bottom: 10%; transform: translate(-50%, 0); }
        .subagent:nth-child(5) { left: 10%; bottom: 30%; }
        .subagent:nth-child(6) { left: 10%; top: 30%; }
        
        .particle {
            position: absolute;
            width: 8px;
            height: 8px;
            background: #4facfe;
            border-radius: 50%;
            pointer-events: none;
        }
        
        @keyframes process {
            0%, 100% { 
                box-shadow: 0 0 0 0 rgba(79, 172, 254, 0.4);
                border-color: #4facfe;
                background: #f8f9fa;
            }
            50% { 
                box-shadow: 0 0 20px 5px rgba(79, 172, 254, 0.6);
                border-color: #667eea;
                background: #e3f2fd;
            }
        }
        
        @keyframes pulse {
            0%, 100% { transform: translate(-50%, -50%) scale(1); }
            50% { transform: translate(-50%, -50%) scale(1.1); }
        }
        
        @keyframes showResult {
            0% { opacity: 0; transform: translate(-50%, -50%) scale(0.5); }
            100% { opacity: 1; transform: translate(-50%, -50%) scale(1); }
        }
        
        .processing {
            animation: process 1.5s ease-in-out infinite;
        }
        
        .orchestrator.pulsing {
            animation: pulse 2s ease-in-out infinite;
        }
        
        .final-result {
            position: absolute;
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%);
            background: #10b981;
            color: white;
            padding: 10px 20px;
            border-radius: 20px;
            font-weight: bold;
            opacity: 0;
            z-index: 20;
            box-shadow: 0 4px 12px rgba(16, 185, 129, 0.4);
        }
        
        .legend {
            position: absolute;
            bottom: 10px;
            left: 10px;
            font-size: 0.8rem;
            color: #666;
            background: rgba(255,255,255,0.9);
            padding: 5px 10px;
            border-radius: 4px;
        }
    </style>
</head>
<body>
    <h1>Kimi K2.5: Visual Agentic Intelligence</h1>
    <div class="authors">Technical Report</div>
    
    <div class="abstract">
        <strong>Abstract:</strong> Kimi K2.5 represents the most powerful open-source model to date, building on Kimi K2 with continued pretraining over approximately 15 trillion mixed visual and text tokens. As a native multimodal model, K2.5 delivers state-of-the-art coding and vision capabilities alongside a self-directed agent swarm paradigm. The model can self-direct an agent swarm with up to 100 sub-agents, executing parallel workflows across up to 1,500 tool calls, reducing execution time by up to 4.5x compared to single-agent setups. Key capabilities include coding with vision (front-end development, image/video-to-code generation), autonomous visual debugging, and office productivity tasks (documents, spreadsheets, PDFs, slide decks).
    </div>
    
    <h2>Key Contributions</h2>
    <ul>
        <li>Native multimodal architecture trained on ~15T mixed visual and text tokens</li>
        <li>Self-directed Agent Swarm paradigm supporting up to 100 sub-agents and 1,500 coordinated tool calls</li>
        <li>Parallel-Agent Reinforcement Learning (PARL) for training parallel orchestrators without predefined workflows</li>
        <li>Staged reward shaping methodology transitioning from encouraging parallelism to optimizing task success</li>
        <li>Critical Steps metric for evaluating latency in parallel agent execution</li>
        <li>State-of-the-art performance on coding benchmarks (SWE-Bench, Terminal-Bench) and vision benchmarks (MMMU Pro, MathVision)</li>
        <li>Autonomous visual debugging and website reconstruction from video inputs</li>
    </ul>
    
    <h2>Agent Swarm Architecture</h2>
    <div class="animation-container">
        <div class="animation-title">Self-Directed Parallel Execution (PARL)</div>
        <div class="swarm-diagram" id="swarm">
            <div class="orchestrator" id="orch">Orchestrator</div>
            <div class="subagent" id="sa1">AI<br>Researcher</div>
            <div class="subagent" id="sa2">Physics<br>Researcher</div>
            <div class="subagent" id="sa3">Fact<br>Checker</div>
            <div class="subagent" id="sa4">Web<br>Developer</div>
            <div class="subagent" id="sa5">Code<br>Debugger</div>
            <div class="subagent" id="sa6">Doc<br>Analyzer</div>
            <div class="final-result" id="result">Aggregated Result</div>
            <div class="legend">Cycle: Task Distribution → Parallel Processing → Result Aggregation</div>
        </div>
    </div>
    
    <h2>Core Concepts</h2>
    <ul>
        <li><strong>Visual Agentic Intelligence:</strong> Native multimodal reasoning combining vision and action</li>
        <li><strong>Agent Swarm:</strong> Self-directed coordination of up to 100 parallel sub-agents</li>
        <li><strong>Parallel-Agent Reinforcement Learning (PARL):</strong> Training method for dynamic task decomposition</li>
        <li><strong>Staged Reward Shaping:</strong> Gradual transition from parallelism incentives to task quality optimization</li>
        <li><strong>Critical Steps Metric:</strong> Latency evaluation based on slowest subagent (critical path analysis)</li>
        <li><strong>Autonomous Visual Debugging:</strong> Self-correcting code generation from visual inputs</li>
    </ul>
    
    <h2>Conclusions</h2>
    <p>
        Kimi K2.5 represents a meaningful step toward AGI for the open-source community, demonstrating strong capability on real-world tasks under real-world constraints. Grounded in advances in coding with vision, agent swarms, and office productivity, the model redefines boundaries of AI in knowledge work. The architecture achieves up to 4.5x execution time reduction through parallel agent coordination, while maintaining state-of-the-art performance across coding, vision, and agentic benchmarks at significantly lower cost than proprietary alternatives.
    </p>
    
    <script>
        function runAnimation() {
            const orch = document.getElementById('orch');
            const subagents = document.querySelectorAll('.subagent');
            const result = document.getElementById('result');
            const swarm = document.getElementById('swarm');
            
            // Reset
            result.style.animation = 'none';
            subagents.forEach(sa => {
                sa.classList.remove('processing');
                sa.style.opacity = '1';
            });
            orch.classList.remove('pulsing');
            
            setTimeout(() => {
                orch.classList.add('pulsing');
                
                // Distribution phase
                subagents.forEach((sa, index) => {
                    setTimeout(() => {
                        const particle = document.createElement('div');
                        particle.className = 'particle';
                        particle.style.left = '50%';
                        particle.style.top = '50%';
                        swarm.appendChild(particle);
                        
                        const saRect = sa.getBoundingClientRect();
                        const swarmRect = swarm.getBoundingClientRect();
                        const endX = saRect.left - swarmRect.left + saRect.width/2;
                        const endY = saRect.top - swarmRect.top + saRect.height/2;
                        
                        particle.animate([
                            { left: '50%', top: '50%', opacity: 1, transform: 'translate(-50%, -50%)' },
                            { left: endX + 'px', top: endY + 'px', opacity: 0, transform: 'translate(-50%, -50%) scale(0.5)' }
                        ], {
                            duration: 800,
                            easing: 'ease-out'
                        }).onfinish = () => {
                            particle.remove();
                            sa.classList.add('processing');
                        };
                    }, index * 150);
                });
                
                // Aggregation phase
                setTimeout(() => {
                    subagents.forEach((sa, index) => {
                        setTimeout(() => {
                            sa.classList.remove('processing');
                            const particle = document.createElement('div');
                            particle.className = 'particle';
                            particle.style.background = '#10b981';
                            
                            const saRect = sa.getBoundingClientRect();
                            const swarmRect = swarm.getBoundingClientRect();
                            const startX = saRect.left - swarmRect.left + saRect.width/2;
                            const startY = saRect.top - swarmRect.top + saRect.height/2;
                            
                            particle.style.left = startX + 'px';
                            particle.style.top = startY + 'px';
                            swarm.appendChild(particle);
                            
                            particle.animate([
                                { left: startX + 'px', top: startY + 'px', opacity: 1, transform: 'translate(-50%, -50%)' },
                                { left: '50%', top: '50%', opacity: 0, transform: 'translate(-50%, -50%) scale(0.5)' }
                            ], {
                                duration: 800,
                                easing: 'ease-in'
                            }).onfinish = () => {
                                particle.remove();
                                if (index === subagents.length - 1) {
                                    result.style.animation = 'showResult 0.5s forwards';
                                }
                            };
                        }, index * 100);
                    });
                }, 3000);
            }, 100);
        }
        
        window.onload = runAnimation;
        setInterval(runAnimation, 5500);
    </script>
</body>
</html>