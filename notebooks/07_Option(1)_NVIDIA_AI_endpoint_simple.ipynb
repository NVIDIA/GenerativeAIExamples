{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ff7339a",
   "metadata": {},
   "source": [
    "# NVIDIA AI Endpoints with LangChain\n",
    "\n",
    "In this notebook, we are going to use the **mixtral_8x7b as LLM** as well as the **nvolveqa_40k embedding** provided by [NVIDIA_AI_Endpoint](https://python.langchain.com/docs/integrations/text_embedding/nvidia_ai_endpoints) and build a simply RAG example with faiss as vectorstore\n",
    "\n",
    "### Prerequisite \n",
    "In order to successfully run this notebook, you will need the following -\n",
    "\n",
    "1. Already successfully gone through the [setup](https://python.langchain.com/docs/integrations/text_embedding/nvidia_ai_endpoints#setup) and generated an API key.\n",
    "2. install necesary python dependencies in [requirements.txt](https://github.com/NVIDIA/GenerativeAIExamples/blob/3d29acf677466c5c301370cab5867cb09e04e318/notebooks/requirements.txt) : then upgrade the langchain-core with the below  \n",
    "pip install langchain-core==0.1.15 \n",
    "\n",
    "Note: change **faiss-gpu --> faiss-cpu** in pre-requisite 2\n",
    "if you do not have access to a GPU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612375a9",
   "metadata": {},
   "source": [
    "### Step 1  - Export the NVIDIA_API_KEY\n",
    "You can supply the NVIDIA_API_KEY directly in this notebook when you run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d6bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-core==0.1.15\n",
    "!pip install faiss-cpu # replace with faiss-gpu if you are using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d479e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "## API Key can be found by going to NVIDIA NGC -> AI Foundation Models -> (some model) -> Get API Code or similar.\n",
    "## 10K free queries to any endpoint (which is a lot actually).\n",
    "\n",
    "# del os.environ['NVIDIA_API_KEY']  ## delete key and reset\n",
    "if os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    print(\"Valid NVIDIA_API_KEY already in environment. Delete to reset\")\n",
    "else:\n",
    "    nvapi_key = getpass.getpass(\"NVAPI Key (starts with nvapi-): \")\n",
    "    assert nvapi_key.startswith(\"nvapi-\"), f\"{nvapi_key[:5]}... is not a valid key\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvapi_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4afb52",
   "metadata": {},
   "source": [
    "### Step 2 - initialize the LLM \n",
    "Here we will use **mixtral_8x7b** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3cb734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test run and see that you can genreate a respond successfully\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "llm = ChatNVIDIA(model=\"mixtral_8x7b\", nvidia_api_key=nvapi_key)\n",
    "result = llm.invoke(\"Write a ballad about LangChain.\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bba1c4",
   "metadata": {},
   "source": [
    "### Step 3 - We intiatlize the embedding as well \n",
    "We selected **nvolveqa_40k** as the embedding \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf81da21",
   "metadata": {},
   "source": [
    "## first we initialize the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b13c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "\n",
    "embedder = NVIDIAEmbeddings(model=\"nvolveqa_40k\")\n",
    "\n",
    "# Alternatively, if you want to specify whether it will use the query or passage type\n",
    "# embedder = NVIDIAEmbeddings(model=\"nvolveqa_40k\", model_type=\"passage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2104106",
   "metadata": {},
   "source": [
    "### Step 4 - Obtain some toy text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31699728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# Here we read in the text data and prepare them into vectorstore\n",
    "ps = os.listdir(\"./toy_data/\")\n",
    "data = []\n",
    "sources = []\n",
    "for p in ps:\n",
    "    if p.endswith('.txt'):\n",
    "        path2file=\"./toy_data/\"+p\n",
    "        with open(path2file,encoding=\"utf-8\") as f:\n",
    "            lines=f.readlines()\n",
    "            for line in lines:\n",
    "                if len(line)>=1:\n",
    "                    data.append(line)\n",
    "                    sources.append(path2file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710c5a6e",
   "metadata": {},
   "source": [
    "### Step 5 - Do some basic cleaning and remove empty lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a005bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=[d for d in data if d is not '\\n']\n",
    "len(data), len(documents), data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa261d0",
   "metadata": {},
   "source": [
    "### Step 6a (optional) - Speed test: check how fast ( in seconds) processing 1 document vs. a batch of 10 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc07f199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"Single Document Embedding: \")\n",
    "s = time.perf_counter()\n",
    "q_embedding  = embedder.embed_documents([documents[0]])\n",
    "elapsed = time.perf_counter() - s\n",
    "print(\"\\033[1m\" + f\"Executed in {elapsed:0.2f} seconds.\" + \"\\033[0m\")\n",
    "print(\"Shape:\", (len(q_embedding),))\n",
    "\n",
    "print(\"\\nBatch Document Embedding: \")\n",
    "s = time.perf_counter()\n",
    "d_embeddings = embedder.embed_documents(documents[:10])\n",
    "elapsed = time.perf_counter() - s\n",
    "print(\"\\033[1m\" + f\"Executed in {elapsed:0.2f} seconds.\" + \"\\033[0m\")\n",
    "print(\"Shape:\",len(d_embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5b0aee",
   "metadata": {},
   "source": [
    "### Step 6b - Process the documents into faiss vectorstore and save it to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create a vector store from the documents and save it to disk.\n",
    "import faiss\n",
    "from operator import itemgetter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "import faiss\n",
    "import pickle\n",
    "# create my own uuid\n",
    "text_splitter = CharacterTextSplitter(chunk_size=400, separator=\" \")\n",
    "docs = []\n",
    "metadatas = []\n",
    "\n",
    "for i, d in enumerate(documents):\n",
    "    splits = text_splitter.split_text(d)\n",
    "    #print(len(splits))\n",
    "    docs.extend(splits)\n",
    "    metadatas.extend([{\"source\": sources[i]}] * len(splits))\n",
    "\n",
    "store = FAISS.from_texts(docs, embedder , metadatas=metadatas)\n",
    "faiss.write_index(store.index, \"./toy_data/nv_embedding.index\")\n",
    "store.index = None\n",
    "with open(\"./toy_data/nv_embedding.pkl\", \"wb\") as f:\n",
    "    pickle.dump(store, f)\n",
    "# you will only need to do this once, later on we will restore the already saved vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3787d615",
   "metadata": {},
   "source": [
    "### Step 6c - Read the previously processed & saved Faiss vectore store back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d889737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the vectorestore back.\n",
    "import faiss\n",
    "import pickle\n",
    "\n",
    "index = faiss.read_index(\"./toy_data/nv_embedding.index\")\n",
    "with open(\"./toy_data/nv_embedding.pkl\", \"rb\") as f:\n",
    "    store = pickle.load(f)\n",
    "store.index = index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03406c1",
   "metadata": {},
   "source": [
    "### Step 7- Wrap the restored vectorsore into a retriever and ask our question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e032143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retriever = store.as_retriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer solely based on the following context:\\n<Documents>\\n{context}\\n</Documents>\",\n",
    "        ),\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatNVIDIA(model=\"mixtral_8x7b\")\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke(\"Tell me about Sweden.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d367584c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
