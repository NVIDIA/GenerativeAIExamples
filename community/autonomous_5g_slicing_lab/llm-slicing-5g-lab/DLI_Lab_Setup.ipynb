{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start 5G Network Simulator\n",
    "\n",
    "In this DLI you will use an Agentic Generative AI solution to solve a bandwidth allocation problem. The lab will consist of two different parts. In the first part, the lab will show you how to setup an open source 5G Network Lab consisting of the following parts:\n",
    "- 5G Core Lab simulation by Open Air Interface: https://openairinterface.org/oai-5g-core-network-project/\n",
    "- FlexRIC that will be connected to the gNodeB and will be used to change the bandwidth allocation for each slice in the gNodeB\n",
    "- RAN Lab composed by a gNodeB and two Use Equipment simulation components from Open Air OAI Softmode: https://github.com/simula/openairinterface5g/blob/dreibh/simulamet-testbed/doc/RUNMODEM.md\n",
    "- Traffic generation over the Open Air network simulator using Iperf Tool: https://iperf.fr/\n",
    "\n",
    "The Lab setup will start with the initialization of the 5G Core Network, then we will set up the gNodeB and the RIC connecting both via the E1 protocol. We will attach two UEs to the 5G network, each UE1 will have its own slice as seen in the diagram. Once UEs are functional, we will use the Iperf tool to generate traffic. First we will set up the Iperf server on the OAI External Network connected by the User Plane Function UPF.  Then we will use the Iperf Client to generate traffic against the External Network using the UEs connection. \n",
    "\n",
    "![5G Lab](./5glab.png)\n",
    "\n",
    "In this Jupyter Notebook we will set the lab for the experiment. In a separate Jupyter Notebook we will build the Agentic Workflow for the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Requirements\n",
    "In this first cell we will install the requirements for the Blueprint and we will restart the kernel, so you will need to press \"yes\" to the window that will pop up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!sudo apt install -y iperf3\n",
    "!pip install -r ../requirements.txt\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Flexric and gNodeB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will take between 7 and 8 minutes to run. It  will compile the ric and gNodeB components within the DLI environment. If you want to install this lab in your computer, you just need to download the DLI directory and execute this command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!chmod +x build_ric_oai_ne.sh\n",
    "!./build_ric_oai_ne.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OAI 5G Network \n",
    "To set up the 5G core Network funcitons we will use the docker compose comand. First, we will setup the standard network funciton for the core and then we will set up an additonal slice (slice 2) that will have its own SMF and UPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!docker compose --progress=plain -f docker-compose-oai-cn-slice1.yaml up -d\n",
    "import time\n",
    "time.sleep(20)\n",
    "!docker compose --progress=plain -f docker-compose-oai-cn-slice2.yaml up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start RIC\n",
    "\n",
    "Then we will start the FlexRIC to be able to modify parameters in the gNodeB on an ad hoc basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process started with PID 102070, logging to logs/RIC.log.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Ensure the logs directory exists\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "cmd = \"./flexric/build/examples/ric/nearRT-RIC\"\n",
    "logfile = \"logs/RIC.log\"\n",
    "\n",
    "# Open log file for writing and start the process\n",
    "with open(logfile, \"a\") as log:\n",
    "    process = subprocess.Popen(\n",
    "        [\"bash\", \"-c\", f\"stdbuf -oL {cmd}\"],  # stdbuf ensures real-time logging\n",
    "        stdout=log,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        universal_newlines=True\n",
    "    )\n",
    "\n",
    "print(f\"Process started with PID {process.pid}, logging to {logfile}.\")\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Trouble Shooting - Sample output</summary>\n",
    "  \n",
    "  If flexric starts successfully you should see a similar output in logs/RIC.log\n",
    "  ```\n",
    "  [UTIL]: Setting the config -c file to /usr/local/etc/flexric/flexric.conf\n",
    "[UTIL]: Setting path -p for the shared libraries to /usr/local/lib/flexric/\n",
    "[NEAR-RIC]: nearRT-RIC IP Address = 127.0.0.1, PORT = 36421\n",
    "[NEAR-RIC]: Initializing \n",
    "[NEAR-RIC]: Loading SM ID = 142 with def = MAC_STATS_V0 \n",
    "[NEAR-RIC]: Loading SM ID = 143 with def = RLC_STATS_V0 \n",
    "[NEAR-RIC]: Loading SM ID = 3 with def = ORAN-E2SM-RC \n",
    "[NEAR-RIC]: Loading SM ID = 146 with def = TC_STATS_V0 \n",
    "[NEAR-RIC]: Loading SM ID = 148 with def = GTP_STATS_V0 \n",
    "[NEAR-RIC]: Loading SM ID = 145 with def = SLICE_STATS_V0 \n",
    "[NEAR-RIC]: Loading SM ID = 2 with def = ORAN-E2SM-KPM \n",
    "[NEAR-RIC]: Loading SM ID = 144 with def = PDCP_STATS_V0 \n",
    "[iApp]: Initializing ... \n",
    "[iApp]: nearRT-RIC IP Address = 127.0.0.1, PORT = 36422\n",
    "[NEAR-RIC]: Initializing Task Manager with 2 threads \n",
    "[E2AP]: E2 SETUP-REQUEST rx from PLMN   1. 1 Node ID 3584 RAN type ngran_gNB\n",
    "[NEAR-RIC]: Accepting RAN function ID 2 with def = ORAN-E2SM-KPM \n",
    "[NEAR-RIC]: Accepting RAN function ID 3 with def = ORAN-E2SM-RC \n",
    "[NEAR-RIC]: Accepting RAN function ID 142 with def = MAC_STATS_V0 \n",
    "[NEAR-RIC]: Accepting RAN function ID 143 with def = RLC_STATS_V0 \n",
    "[NEAR-RIC]: Accepting RAN function ID 144 with def = PDCP_STATS_V0 \n",
    "[NEAR-RIC]: Accepting RAN function ID 145 with def = SLICE_STATS_V0 \n",
    "[NEAR-RIC]: Accepting RAN function ID 146 with def = TC_STATS_V0 \n",
    "[NEAR-RIC]: Accepting RAN function ID 148 with def = GTP_STATS_V0 \n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the gNodeB\n",
    "Then we will run the gNodeB using the OAI softmoden software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process started with PID 117275, logging to logs/gNodeB.log.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "cmd = \"sudo ./openairinterface5g/cmake_targets/ran_build/build/nr-softmodem -O ran-conf/gnb.conf --sa --rfsim -E --gNBs.[0].min_rxtxtime 6\"\n",
    "logfile = \"logs/gNodeB.log\"\n",
    "\n",
    "env = os.environ.copy()\n",
    "env[\"LD_LIBRARY_PATH\"] = \".\"\n",
    "\n",
    "# Open log file for writing and start the process\n",
    "with open(logfile, \"a\") as log:\n",
    "    process = subprocess.Popen(\n",
    "        [\"bash\", \"-c\", f\"stdbuf -oL {cmd}\"],  # stdbuf ensures real-time logging\n",
    "        stdout=log,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        universal_newlines=True\n",
    "    )\n",
    "\n",
    "print(f\"Process started with PID {process.pid}, logging to {logfile}.\")\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Bandwidth 50 50 \n",
    "The gNodeB will have initially allocated 50% of its bandwidth to each of the slices. \n",
    "\n",
    "- Note : Incase you get `[E2AP]: Resending Setup Request after timeout`error, rerun the `Start RIC` cell.\n",
    "\n",
    "***\n",
    "Please check `./logs/RIC.log` to ensure that flexRIC is working. Incase you see a \"failed\" message, try rerunning the `Start RIC` cell above. \n",
    "\n",
    "Error message : \n",
    "```\n",
    "nearRT-RIC: /dli/task/llm-slicing-5g-lab/flexric/src/lib/e2ap/v2_03/enc/e2ap_msg_enc_asn.c:3165: e2ap_enc_e42_setup_response_asn_pdu: Assertion `sr->len_e2_nodes_conn > 0 && \"No global node conected??\"' failed.\n",
    "```\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50+50\n",
      "[UTIL]: Setting the config -c file to /usr/local/etc/flexric/flexric.conf\n",
      "[UTIL]: Setting path -p for the shared libraries to /usr/local/lib/flexric/\n",
      "[xAapp]: Initializing ... \n",
      "[xApp]: nearRT-RIC IP Address = 127.0.0.1, PORT = 36422\n",
      "[E2 AGENT]: Opening plugin from path = /usr/local/lib/flexric/libslice_sm.so \n",
      "[E2 AGENT]: Opening plugin from path = /usr/local/lib/flexric/libmac_sm.so \n",
      "[E2 AGENT]: Opening plugin from path = /usr/local/lib/flexric/libkpm_sm.so \n",
      "[E2 AGENT]: Opening plugin from path = /usr/local/lib/flexric/librc_sm.so \n",
      "[E2 AGENT]: Opening plugin from path = /usr/local/lib/flexric/librlc_sm.so \n",
      "[E2 AGENT]: Opening plugin from path = /usr/local/lib/flexric/libtc_sm.so \n",
      "[E2 AGENT]: Opening plugin from path = /usr/local/lib/flexric/libgtp_sm.so \n",
      "[E2 AGENT]: Opening plugin from path = /usr/local/lib/flexric/libpdcp_sm.so \n",
      "[NEAR-RIC]: Loading SM ID = 145 with def = SLICE_STATS_V0 \n",
      "[NEAR-RIC]: Loading SM ID = 142 with def = MAC_STATS_V0 \n",
      "[NEAR-RIC]: Loading SM ID = 2 with def = ORAN-E2SM-KPM \n",
      "[NEAR-RIC]: Loading SM ID = 3 with def = ORAN-E2SM-RC \n",
      "[NEAR-RIC]: Loading SM ID = 143 with def = RLC_STATS_V0 \n",
      "[NEAR-RIC]: Loading SM ID = 146 with def = TC_STATS_V0 \n",
      "[NEAR-RIC]: Loading SM ID = 148 with def = GTP_STATS_V0 \n",
      "[NEAR-RIC]: Loading SM ID = 144 with def = PDCP_STATS_V0 \n",
      "[xApp]: DB filename = /tmp/xapp_db_1747219577414412 \n",
      " [xApp]: E42 SETUP-REQUEST tx\n",
      "[xApp]: E42 SETUP-RESPONSE rx \n",
      "[xApp]: xApp ID = 7 \n",
      "[xApp]: Registered E2 Nodes = 1 \n",
      "Connected E2 nodes = 1\n",
      "Setting PRB Ratio to 50:50\n",
      "[xApp]: CONTROL-REQUEST tx \n",
      "[xApp]: CONTROL ACK rx\n",
      "[xApp]: Successfully received CONTROL-ACK \n",
      "[xApp]: Control Loop Latency: 828 us\n",
      "[xApp]: Sucessfully stopped \n",
      "Test xApp run SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "!./change_rc_slice.sh 50 50\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the UE\n",
    "After we will create a User Equipment Simulator and attach it to the gNodeB. Following cell creates UE1 and UE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "import logging\n",
    "from typing import Optional, List\n",
    "\n",
    "import colorlog\n",
    "\n",
    "# Configure colored logging.\n",
    "handler = colorlog.StreamHandler()\n",
    "handler.setFormatter(colorlog.ColoredFormatter(\n",
    "    fmt=\"%(log_color)s%(asctime)s %(levelname)s: %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    log_colors={\n",
    "        'DEBUG':    'blue',\n",
    "        'INFO':     'green',\n",
    "        'WARNING':  'yellow',\n",
    "        'ERROR':    'red',\n",
    "        'CRITICAL': 'red,bg_white',\n",
    "    }\n",
    "))\n",
    "logger = colorlog.getLogger(__name__)\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.propagate = False\n",
    "\n",
    "def start_async_process(name: str, cmd: str, logfile: str) -> Optional[subprocess.Popen]:\n",
    "    \"\"\"\n",
    "    Start an asynchronous process and log its status.\n",
    "\n",
    "    Args:\n",
    "        name: Name of the process.\n",
    "        cmd: The command to run.\n",
    "        logfile: Path to the log file.\n",
    "\n",
    "    Returns:\n",
    "        The subprocess.Popen object if the process started successfully;\n",
    "        None otherwise.\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting process %s with command: %s\", name, cmd)\n",
    "    try:\n",
    "        with open(logfile, \"a\") as log:\n",
    "            process = subprocess.Popen(\n",
    "                [\"bash\", \"-c\", f\"stdbuf -oL {cmd}\"],\n",
    "                stdout=log,\n",
    "                stderr=subprocess.STDOUT,\n",
    "                universal_newlines=True,\n",
    "            )\n",
    "        if process.pid:\n",
    "            logger.info(\"Process %s started with PID %s, logging to %s\", name, process.pid, logfile)\n",
    "            return process\n",
    "        else:\n",
    "            logger.error(\"Process %s did not start properly.\", name)\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        logger.error(\"Failed to start process %s: %s\", name, str(e))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-14 10:46:32 INFO: Starting process UE1 with command: \n",
      "    sudo ./multi_ue.sh -c1 -e & \n",
      "    sleep 5\n",
      "    sudo ip netns exec ue1 bash -c '\n",
      "        sudo LD_LIBRARY_PATH=. ./openairinterface5g/cmake_targets/ran_build/build/nr-uesoftmodem \\\n",
      "        --rfsimulator.serveraddr 10.201.1.100 -r 106 --numerology 1 --band 78 -C 3619200000 \\\n",
      "        --rfsim --sa -O ran-conf/ue_1.conf -E\n",
      "    '\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-14 10:46:32 INFO: Process UE1 started with PID 118709, logging to logs/UE1.log\u001b[0m\n",
      "\u001b[32m2025-05-14 10:46:32 INFO: Starting process UE3 with command: \n",
      "    sudo ./multi_ue.sh -c3 -e & \n",
      "    sleep 5\n",
      "    sudo ip netns exec ue3 bash -c '\n",
      "        sudo LD_LIBRARY_PATH=. ./openairinterface5g/cmake_targets/ran_build/build/nr-uesoftmodem \\\n",
      "        --rfsimulator.serveraddr 10.203.1.100 -r 106 --numerology 1 --band 78 -C 3619200000 \\\n",
      "        --rfsim --sa -O ran-conf/ue_2.conf -E\n",
      "    '\n",
      "    \u001b[0m\n",
      "\u001b[32m2025-05-14 10:46:32 INFO: Process UE3 started with PID 118712, logging to logs/UE3.log\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    sudo ./multi_ue.sh -c1 -e & \n",
      "    sleep 5\n",
      "    sudo ip netns exec ue1 bash -c '\n",
      "        sudo LD_LIBRARY_PATH=. ./openairinterface5g/cmake_targets/ran_build/build/nr-uesoftmodem \\\n",
      "        --rfsimulator.serveraddr 10.201.1.100 -r 106 --numerology 1 --band 78 -C 3619200000 \\\n",
      "        --rfsim --sa -O ran-conf/ue_1.conf -E\n",
      "    '\n",
      "    \n",
      "\n",
      "    sudo ./multi_ue.sh -c3 -e & \n",
      "    sleep 5\n",
      "    sudo ip netns exec ue3 bash -c '\n",
      "        sudo LD_LIBRARY_PATH=. ./openairinterface5g/cmake_targets/ran_build/build/nr-uesoftmodem \\\n",
      "        --rfsimulator.serveraddr 10.203.1.100 -r 106 --numerology 1 --band 78 -C 3619200000 \\\n",
      "        --rfsim --sa -O ran-conf/ue_2.conf -E\n",
      "    '\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def start_ue(ue_id: str, config_file: str, namespace: str, server_addr: str, port: str = \"106\") -> Optional[subprocess.Popen]:\n",
    "    \"\"\"\n",
    "    Start a UE process.\n",
    "\n",
    "    Args:\n",
    "        ue_id: Identifier for the UE (used in command arguments and logging).\n",
    "        config_file: Path to the UE configuration file.\n",
    "        namespace: The network namespace for the UE.\n",
    "        server_addr: The server address for the UE.\n",
    "        port: The port used by the UE (default is \"106\").\n",
    "\n",
    "    Returns:\n",
    "        The subprocess.Popen object if the process started successfully; None otherwise.\n",
    "    \"\"\"\n",
    "    cmd = f\"\"\"\n",
    "    sudo ./multi_ue.sh -c{ue_id} -e & \n",
    "    sleep 5\n",
    "    sudo ip netns exec {namespace} bash -c '\n",
    "        sudo LD_LIBRARY_PATH=. ./openairinterface5g/cmake_targets/ran_build/build/nr-uesoftmodem \\\\\n",
    "        --rfsimulator.serveraddr {server_addr} -r {port} --numerology 1 --band 78 -C 3619200000 \\\\\n",
    "        --rfsim --sa -O {config_file} -E\n",
    "    '\n",
    "    \"\"\"\n",
    "    logfile = f\"logs/UE{ue_id}.log\"\n",
    "    print(cmd)\n",
    "    return start_async_process(f\"UE{ue_id}\", cmd, logfile)\n",
    "\n",
    "ue1_process = start_ue(\"1\", \"ran-conf/ue_1.conf\", \"ue1\", \"10.201.1.100\")\n",
    "ue2_process = start_ue(\"3\", \"ran-conf/ue_2.conf\", \"ue3\", \"10.203.1.100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Debugging tip: Print logs for sanity check**\n",
    "\n",
    "```\n",
    "tail -f logs/UE1.log\n",
    "tail -f logs/UE3.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Iperf Tool Server\n",
    "Once the 5G Network Simulation is running we will start the simulation of traffic by using with tool Iperf. First we will create an Iperf Server that will be on the External Network connected via the User Plane Function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-14 10:46:38 INFO: Starting process iPerf_server1 with command: docker exec -t oai-ext-dn iperf3 -s -p 5201\u001b[0m\n",
      "\u001b[32m2025-05-14 10:46:38 INFO: Process iPerf_server1 started with PID 119502, logging to logs/docker_iperfserver_server1.log\u001b[0m\n",
      "\u001b[32m2025-05-14 10:46:38 INFO: Starting process iPerf_server2 with command: docker exec -t oai-ext-dn iperf3 -s -p 5202\u001b[0m\n",
      "\u001b[32m2025-05-14 10:46:38 INFO: Process iPerf_server2 started with PID 119503, logging to logs/docker_iperfserver_server2.log\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def start_iperf(name: str, port: str) -> Optional[subprocess.Popen]:\n",
    "    \"\"\"\n",
    "    Start an iPerf3 server process.\n",
    "\n",
    "    Args:\n",
    "        name: Identifier for the iPerf3 instance.\n",
    "        port: Port on which the iPerf3 server should run.\n",
    "\n",
    "    Returns:\n",
    "        The subprocess.Popen object if started successfully; None otherwise.\n",
    "    \"\"\"\n",
    "    cmd = f\"docker exec -t oai-ext-dn iperf3 -s -p {port}\"\n",
    "    logfile = f\"logs/docker_iperfserver_{name}.log\"\n",
    "    return start_async_process(f\"iPerf_{name}\", cmd, logfile)\n",
    "\n",
    "iperf1_process = start_iperf(\"server1\", \"5201\")\n",
    "iperf2_process = start_iperf(\"server2\", \"5202\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Traffic generator and insert records in the database\n",
    "Once every element in The Network is up and running and the Iperf server is listening in the external network. We will run two iperf clients that will be generating traffic in both UEs. These scripts will generate udp traffic from the iperf server towards the UE and will alternate speeds 30M and 120M for 100 seconds. In the following cell we will\n",
    "\n",
    "1. Run traffic generator to alternate between 30M and 120M\n",
    "2. Insert UE1 and UE2 iperf logs into the Kinetica Database. Kinetica is a very fast, distributed, GPU-accelerated database with advanced analytics, visualization, geospatial, and machine learning functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate traffic \n",
    "\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "import threading\n",
    "from typing import Dict, List, Pattern\n",
    "\n",
    "from dotenv import load_dotenv, set_key\n",
    "from english_words import get_english_words_set\n",
    "import gpudb\n",
    "from gpudb import GPUdb\n",
    "from gpudb import GPUdbColumnProperty as cp\n",
    "from gpudb import GPUdbRecordColumn as rc\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "class IperfRecord:\n",
    "    def __init__(\n",
    "        self,\n",
    "        record_id: str = \"\",\n",
    "        record_ue: str = None,\n",
    "        record_timestamp: str = \"\",\n",
    "        record_stream: int = None,\n",
    "        record_interval_start: float = None,\n",
    "        record_interval_end: float = None,\n",
    "        record_duration: float = 0.0,\n",
    "        record_data_transferred: float = None,\n",
    "        record_bitrate: float = None,\n",
    "        record_jitter: float = None,\n",
    "        record_lost_packets: int = None,\n",
    "        record_total_packets: int = None,\n",
    "        record_loss_percentage: float = None\n",
    "    ) -> None:\n",
    "        self.id = record_id\n",
    "        self.ue = record_ue\n",
    "        self.timestamp = record_timestamp\n",
    "        self.stream = record_stream\n",
    "        self.interval_start = record_interval_start\n",
    "        self.interval_end = record_interval_end\n",
    "        self.duration = record_duration\n",
    "        self.data_transferred = record_data_transferred\n",
    "        self.bitrate = record_bitrate\n",
    "        self.jitter = record_jitter\n",
    "        self.lost_packets = record_lost_packets\n",
    "        self.total_packets = record_total_packets\n",
    "        self.loss_percentage = record_loss_percentage\n",
    "\n",
    "    def record_to_dict(self) -> Dict[str, str | float]:\n",
    "        return {\n",
    "            \"id\": self.id,\n",
    "            \"ue\": self.ue,\n",
    "            \"timestamp\": self.timestamp,\n",
    "            \"stream\": self.stream,\n",
    "            \"interval_start\": self.interval_start,\n",
    "            \"interval_end\": self.interval_end,\n",
    "            \"duration\": self.duration,\n",
    "            \"data_transferred\": self.data_transferred,\n",
    "            \"bitrate\": self.bitrate,\n",
    "            \"jitter\": self.jitter,\n",
    "            \"lost_packets\": self.lost_packets,\n",
    "            \"total_packets\": self.total_packets,\n",
    "            \"loss_percentage\": self.loss_percentage\n",
    "        }\n",
    "\n",
    "\n",
    "def convert_bandwidth(bw_str: str) -> int:\n",
    "    \"\"\"\n",
    "    Converts a bandwidth string like \"120M\" or \"30M\" into an integer in bits per second.\n",
    "    \"\"\"\n",
    "    if bw_str.endswith(\"M\"):\n",
    "        return int(bw_str[:-1]) * 1_000_000\n",
    "    elif bw_str.endswith(\"K\"):\n",
    "        return int(bw_str[:-1]) * 1_000\n",
    "    else:\n",
    "        return int(bw_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <b>Kinetica Table:</b> <a target=\"_blank\" href=\"https://demo72.kinetica.com/gadmin/#/table/nvidia_gtc_dli_2025/lineless_toolbuilding_squad_sciotheism_iperf3_logs\">lineless_toolbuilding_squad_sciotheism_iperf3_logs</a> </br>\n",
       "    <b>User:</b> nvidia_gtc_2025 </br>\n",
       "    <b>Password:</b> Kinetica123!\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-14 19:25:50 INFO: CURRENT ITERATION: 0\u001b[0m\n",
      "\u001b[32m2025-05-14 19:26:40 INFO: CURRENT ITERATION: 1\u001b[0m\n",
      "\u001b[32m2025-05-14 19:26:56 INFO: CURRENT ITERATION: 2\u001b[0m\n",
      "\u001b[32m2025-05-14 19:27:34 INFO: CURRENT ITERATION: 3\u001b[0m\n",
      "\u001b[32m2025-05-14 19:28:17 INFO: CURRENT ITERATION: 4\u001b[0m\n",
      "\u001b[32m2025-05-14 19:29:51 INFO: CURRENT ITERATION: 5\u001b[0m\n",
      "\u001b[32m2025-05-14 19:29:51 INFO: CURRENT ITERATION: 6\u001b[0m\n",
      "\u001b[32m2025-05-14 19:29:51 INFO: CURRENT ITERATION: 7\u001b[0m\n",
      "\u001b[32m2025-05-14 19:29:51 INFO: CURRENT ITERATION: 8\u001b[0m\n",
      "\u001b[32m2025-05-14 19:29:51 INFO: CURRENT ITERATION: 9\u001b[0m\n",
      "\u001b[32m2025-05-14 19:29:51 INFO: CURRENT ITERATION: 10\u001b[0m\n",
      "\u001b[32m2025-05-14 19:29:52 INFO: CURRENT ITERATION: 11\u001b[0m\n",
      "\u001b[32m2025-05-14 19:29:52 INFO: CURRENT ITERATION: 12\u001b[0m\n",
      "\u001b[32m2025-05-14 19:29:52 INFO: CURRENT ITERATION: 13\u001b[0m\n",
      "\u001b[32m2025-05-14 19:29:52 INFO: CURRENT ITERATION: 14\u001b[0m\n",
      "\u001b[32m2025-05-14 19:29:52 INFO: CURRENT ITERATION: 15\u001b[0m\n",
      "\u001b[32m2025-05-14 19:29:52 INFO: CURRENT ITERATION: 16\u001b[0m\n",
      "\u001b[32m2025-05-14 19:29:52 INFO: CURRENT ITERATION: 17\u001b[0m\n",
      "\u001b[32m2025-05-14 19:29:52 INFO: CURRENT ITERATION: 18\u001b[0m\n",
      "\u001b[32m2025-05-14 19:29:52 INFO: CURRENT ITERATION: 19\u001b[0m\n",
      "\u001b[32m2025-05-14 19:29:52 INFO: CURRENT ITERATION: 20\u001b[0m\n",
      "\u001b[32m2025-05-14 19:29:52 INFO: CURRENT ITERATION: 21\u001b[0m\n",
      "\u001b[32m2025-05-14 19:29:52 INFO: CURRENT ITERATION: 22\u001b[0m\n",
      "\u001b[32m2025-05-14 19:29:52 INFO: CURRENT ITERATION: 23\u001b[0m\n",
      "\u001b[32m2025-05-14 19:29:52 INFO: CURRENT ITERATION: 24\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load environment variables and initialize Kinetica connection.\n",
    "load_dotenv()\n",
    "kdbc_options = GPUdb.Options()\n",
    "kdbc_options.username = os.environ.get(\"KINETICA_USERNAME\")\n",
    "kdbc_options.password = os.environ.get(\"KINETICA_PASSWORD\")\n",
    "kdbc_options.disable_auto_discovery = True\n",
    "word_list: List[str] = list(get_english_words_set(['web2'], lower=True))\n",
    "\n",
    "\n",
    "def generate_random_table_name() -> str:\n",
    "    # Generate a table name with the correct schema, four random underscore-separated words, and the string \"_iperf_3_logs\"\n",
    "    fully_qualified_random_table_name: str = f\"{os.environ.get('KINETICA_SCHEMA', 'nvidia_gtc_dli_2025')}.\" + \"_\".join(random.choices(word_list, k=4)) + \"_iperf3_logs\"\n",
    "    \n",
    "    # Set our environment variable in the .env file for use by the Agents.\n",
    "    set_key(\n",
    "        dotenv_path=\"./.env\",\n",
    "        key_to_set=\"IPERF3_RANDOM_TABLE_NAME\",\n",
    "        value_to_set=fully_qualified_random_table_name,\n",
    "        quote_mode=\"always\",\n",
    "        export=False,\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "    return fully_qualified_random_table_name\n",
    "\n",
    "\n",
    "kdbc: GPUdb = GPUdb(\n",
    "    host=os.environ.get(\"KINETICA_HOST\"),\n",
    "    options=kdbc_options\n",
    ")\n",
    "\n",
    "iperf3_table_name: str = generate_random_table_name()\n",
    "if kdbc.has_table(table_name=iperf3_table_name).table_exists:\n",
    "    kdbc.clear_table(table_name=iperf3_table_name)\n",
    "\n",
    "schema, table = iperf3_table_name.split('.')\n",
    "url = f'https://demo72.kinetica.com/gadmin/#/table/{schema}/{table}'\n",
    "user = os.environ.get(\"KINETICA_USERNAME\")\n",
    "password = os.environ.get(\"KINETICA_PASSWORD\")\n",
    "html_out = f'''\n",
    "    <b>Kinetica Table:</b> <a target=\"_blank\" href=\"{url}\">{table}</a> </br>\n",
    "    <b>User:</b> {user} </br>\n",
    "    <b>Password:</b> {password}\n",
    "'''\n",
    "display(HTML(html_out))\n",
    "\n",
    "schema: List[List[str]] = [\n",
    "    [\"id\",               rc._ColumnType.STRING, cp.UUID,     cp.PRIMARY_KEY, cp.INIT_WITH_UUID],\n",
    "    [\"ue\",               rc._ColumnType.STRING, cp.CHAR8,    cp.DICT],\n",
    "    [\"timestamp\",        rc._ColumnType.STRING, cp.DATETIME, cp.INIT_WITH_NOW],\n",
    "    [\"stream\",           rc._ColumnType.INT,    cp.INT8,     cp.DICT],\n",
    "    [\"interval_start\",   rc._ColumnType.FLOAT],\n",
    "    [\"interval_end\",     rc._ColumnType.FLOAT],\n",
    "    [\"duration\",         rc._ColumnType.FLOAT],\n",
    "    [\"data_transferred\", rc._ColumnType.FLOAT],\n",
    "    [\"bitrate\",          rc._ColumnType.FLOAT],\n",
    "    [\"jitter\",           rc._ColumnType.FLOAT],\n",
    "    [\"lost_packets\",     rc._ColumnType.INT],\n",
    "    [\"total_packets\",    rc._ColumnType.INT],\n",
    "    [\"loss_percentage\",  rc._ColumnType.FLOAT]\n",
    "]\n",
    "kdbc_table = gpudb.GPUdbTable(\n",
    "    _type=schema,\n",
    "    name=iperf3_table_name,\n",
    "    db=kdbc\n",
    ")\n",
    "\n",
    "# Precompiled regex pattern to parse iperf3 output.\n",
    "filter_regex: str = (\n",
    "    r'^\\[ *([0-9]+)\\] +([0-9]+\\.[0-9]+)-([0-9]+\\.[0-9]+) +sec +'\n",
    "    r'([0-9\\.]+) +MBytes +([0-9\\.]+) +Mbits/sec +([0-9\\.]+) +ms +'\n",
    "    r'([0-9]+)/([0-9]+) +\\(([0-9\\.]+)%\\)$'\n",
    ")\n",
    "pattern: Pattern[str] = re.compile(filter_regex)\n",
    "\n",
    "\n",
    "def iperf_runner(\n",
    "    namespace: str,\n",
    "    ue_name: str,\n",
    "    bind_host: str,\n",
    "    server_host: str,\n",
    "    udp_port: int,\n",
    "    bandwidth: str,\n",
    "    test_length_secs: int,\n",
    "    kdbc_table: gpudb.GPUdbTable,\n",
    "    pattern: Pattern[str],\n",
    "    log_file: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Runs iperf for one UE, parses and inserts records into Kinetica,\n",
    "    and writes each record to a dedicated log file in the specified format.\n",
    "    Exits when the iperf process finishes.\n",
    "\n",
    "    :param namespace: The network namespace for the UE.\n",
    "    :param ue_name: A label/identifier for the UE (e.g., \"UE1\").\n",
    "    :param bind_host: IP address to bind to (iperf3 -B).\n",
    "    :param server_host: The remote iperf3 server IP address.\n",
    "    :param udp_port: The UDP port to use (iperf3 -p).\n",
    "    :param bandwidth: The bandwidth limit (e.g. \"30M\" or \"120M\").\n",
    "    :param test_length_secs: The test duration in seconds (iperf3 -t).\n",
    "    :param kdbc_table: The Kinetica table object where we insert records.\n",
    "    :param pattern: Precompiled regex to parse iperf3 output.\n",
    "    :param log_file: Path to the log file for this iperf3 process (e.g. \"logs/UE1_iperfc.log\").\n",
    "    \"\"\"\n",
    "    try:\n",
    "        iperf_cmd = (\n",
    "            f\"stdbuf -oL iperf3 \"\n",
    "            f\"-B {bind_host} \"\n",
    "            f\"-c {server_host} \"\n",
    "            f\"-p {udp_port} \"\n",
    "            f\"-R -u \"\n",
    "            f\"-b {bandwidth} \"\n",
    "            f\"-t {test_length_secs}\"\n",
    "        )\n",
    "        cmd = [\"sudo\", \"ip\", \"netns\", \"exec\", namespace, \"bash\", \"-c\", iperf_cmd]\n",
    "\n",
    "        # Open a subprocess to run iperf3.\n",
    "        with subprocess.Popen(\n",
    "            cmd,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            universal_newlines=True,\n",
    "            bufsize=1\n",
    "        ) as proc:\n",
    "            for line in proc.stdout:\n",
    "                line = line.strip()\n",
    "                match = pattern.match(line)\n",
    "                if match:\n",
    "                    # Create an IperfRecord from the parsed line.\n",
    "                    iperf_record = IperfRecord(\n",
    "                        record_ue=ue_name,\n",
    "                        record_stream=int(match.group(1)),\n",
    "                        record_interval_start=float(match.group(2)),\n",
    "                        record_interval_end=float(match.group(3)),\n",
    "                        record_data_transferred=float(match.group(4)),\n",
    "                        record_bitrate=float(match.group(5)),\n",
    "                        record_jitter=float(match.group(6)),\n",
    "                        record_lost_packets=int(match.group(7)),\n",
    "                        record_total_packets=int(match.group(8)),\n",
    "                        record_loss_percentage=float(match.group(9))\n",
    "                    )\n",
    "                    # Calculate duration.\n",
    "                    iperf_record.duration = iperf_record.interval_end - iperf_record.interval_start\n",
    "\n",
    "                    # Insert record into Kinetica.\n",
    "                    record_dict = iperf_record.record_to_dict()\n",
    "                    kdbc_table.insert_records(record_dict)\n",
    "                    kdbc_table.flush_data_to_server()\n",
    "\n",
    "                    # Write the raw iperf3 output line to the dedicated log file\n",
    "                    # with the format: \"[<UE>] [<timestamp>] <line>\"\n",
    "                    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    with open(log_file, \"a\") as f:\n",
    "                        f.write(f\"[{ue_name}] [{timestamp}] {line}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error running process: {e}\")\n",
    "    # When iperf3 ends, the function exits so that the main thread can handle any post-run activities.\n",
    "\n",
    "\n",
    "bandwidth_ue1: str = \"30M\"\n",
    "bandwidth_ue2: str = \"120M\"\n",
    "bind_host_ue1: str = \"12.1.1.2\"\n",
    "bind_host_ue2: str = \"12.1.1.130\"\n",
    "server_host_ue1: str = \"192.168.70.135\"\n",
    "server_host_ue2: str = \"192.168.70.135\"\n",
    "udp_port_ue1: int = 5201\n",
    "udp_port_ue2: int = 5202\n",
    "test_length_secs: int = 100\n",
    "\n",
    "test_iterations: int = 25 # Feel free to change this as you see fit to run the log generation for a longer period of time.\n",
    "current_iteration: int = 0\n",
    "\n",
    "while current_iteration < test_iterations:\n",
    "    logger.info(f\"\"\"CURRENT ITERATION: {current_iteration}\"\"\")\n",
    "    current_iteration += 1\n",
    "    \n",
    "    t1: threading.Thread = threading.Thread(\n",
    "        target=iperf_runner,\n",
    "        args=(\n",
    "            \"ue1\",\n",
    "            \"UE1\",\n",
    "            bind_host_ue1,\n",
    "            server_host_ue1,\n",
    "            udp_port_ue1,\n",
    "            bandwidth_ue1,\n",
    "            test_length_secs,\n",
    "            kdbc_table,\n",
    "            pattern,\n",
    "            \"logs/UE1_iperfc.log\"\n",
    "        ),\n",
    "        daemon=True\n",
    "    )\n",
    "\n",
    "    t2: threading.Thread = threading.Thread(\n",
    "        target=iperf_runner,\n",
    "        args=(\n",
    "            \"ue3\",\n",
    "            \"UE3\",\n",
    "            bind_host_ue2,\n",
    "            server_host_ue2,\n",
    "            udp_port_ue2,\n",
    "            bandwidth_ue2,\n",
    "            test_length_secs,\n",
    "            kdbc_table,\n",
    "            pattern,\n",
    "            \"logs/UE2_iperfc.log\"\n",
    "        ),\n",
    "        daemon=True\n",
    "    )\n",
    "\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "\n",
    "    if bandwidth_ue1 == \"30M\":\n",
    "        bandwidth_ue1 = \"120M\"\n",
    "    else:\n",
    "        bandwidth_ue1 = \"30M\"\n",
    "\n",
    "    if bandwidth_ue2 == \"30M\":\n",
    "        bandwidth_ue2 = \"120M\"\n",
    "    else:\n",
    "        bandwidth_ue2 = \"30M\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep the above cell running! If you want to see what is happening in the background, you can:\n",
    "1. Check out UE1, UE2 iperf logs to see how traffic generator works, and how it leads to packet loss:\n",
    "    ```bash\n",
    "    tail -f logs/UE1_iperfc.log\n",
    "    tail -f logs/UE2_iperfc.log\n",
    "    ```\n",
    "\n",
    "2. Access Kinetica database, and see how wlogs are updated there real-time. Login with your username and password, mentioned in the .env file.\n",
    "\n",
    "    - KINETICA_USERNAME=\"nvidia_gtc_2025\"\n",
    "    - KINETICA_PASSWORD=\"Kinetica123!\"\n",
    "    - KINETICA_SCHEMA=\"nvidia_gtc_dli_2025\"\n",
    "    - Table name: os.environment.get(\"IPERF3_RANDOM_TABLE_NAME\")\n",
    "    - URL : https://demo72.kinetica.com/gadmin/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be the final step setting up the 5G Lab for the Agentic Workflow.\n",
    "\n",
    "![stop](./Stop2.jpg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
