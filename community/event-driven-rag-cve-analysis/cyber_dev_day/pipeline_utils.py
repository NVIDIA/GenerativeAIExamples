# Copyright (c) 2024, NVIDIA CORPORATION.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging

from langchain.agents import AgentType
from langchain.agents import Tool
from langchain.agents import initialize_agent
from langchain.agents.agent import AgentExecutor
from langchain.embeddings.huggingface import HuggingFaceEmbeddings
from langchain.vectorstores.faiss import FAISS
from langchain import hub
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.tools.retriever import create_retriever_tool

from morpheus.llm import LLMEngine
from morpheus.llm.nodes.extracter_node import ExtracterNode
from morpheus.llm.nodes.langchain_agent_node import LangChainAgentNode
from cyber_dev_day.llm_service import LLMService
from cyber_dev_day.langchain_llm_client_wrapper import LangchainLLMClientWrapper
from morpheus.llm.task_handlers.simple_task_handler import SimpleTaskHandler

from .checklist_node import CVEChecklistNode
from .config import EngineAgentConfig
from .config import EngineConfig
from .tools import SBOMChecker

logger = logging.getLogger(__name__)


def build_agent_executor(config: EngineAgentConfig, handle_parsing_errors=False) -> AgentExecutor:
    llm_service = LLMService.create(config.model.service.type, **config.model.service.model_dump(exclude={"type"}))

    llm_client = llm_service.get_client(**config.model.model_dump(exclude={"service"}))

    # Wrap the Morpheus client in a LangChain compatible wrapper
    langchain_llm = LangchainLLMClientWrapper(client=llm_client)

    # tools = load_tools(["serpapi", "llm-math"], llm=llm)
    tools: list[Tool] = []

    if (config.sbom.data_file is not None):
        # Load the SBOM
        sbom_checker = SBOMChecker.from_csv(config.sbom.data_file)

        tools.append(
            Tool(name="SBOM Package Checker",
                 func=sbom_checker.sbom_checker,
                 description=("useful for when you need to check the Docker container's software bill of "
                              "materials (SBOM) to get whether or not a given library is in the container. "
                              "Input should be the name of the library or software, and no text following it until a response is returned. "
                              "If the package is "
                              "present a version number is returned, otherwise False is returned if the "
                              "package is not present.")))

    if (config.code_repo.faiss_dir is not None):
        embeddings = HuggingFaceEmbeddings(model_name=config.code_repo.embedding_model_name,
                                           model_kwargs={'device': 'cuda'},
                                           encode_kwargs={'normalize_embeddings': False})

        # load code vector DB
        code_vector_db = FAISS.load_local(folder_path=config.code_repo.faiss_dir,
                                          embeddings=embeddings,
                                          allow_dangerous_deserialization=True)

        tools.append(create_retriever_tool(
            code_vector_db.as_retriever(),
            "Docker Container Code QA System",
            ("useful for when you need to review code to check for an import or function usage in "
             "the Docker container. Input should be a question or the actual code. ")
        ))

    sys_prompt = ("You are a very powerful assistant who helps investigate Docker containers "
                  " given a checklist of investigation items. Your role is to walk through a provided checklist and answer each item in the checklist. "
                  " Do not investigate additional information per checklist item, just answer the checklist. "
                  " Information about the Docker container under investigation is stored in vector databases available to you via tools. ")

    if handle_parsing_errors:
        agent_executor = initialize_agent(tools,
                                          langchain_llm,
                                          agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
                                          verbose=config.verbose,
                                          handle_parsing_errors="Check your output. Each thought must end with a 'Final Anser', or 'Action'/'Action Input'. For action inputs, adhere to the tool description's instructions exactly. Thoughts cannot be empty strings.")
    else:
        agent_executor = initialize_agent(tools,
                                          langchain_llm,
                                          agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
                                          verbose=config.verbose)

    agent_executor.agent.llm_chain.prompt.template = (
            sys_prompt + ' ' + agent_executor.agent.llm_chain.prompt.template.replace(
        "Answer the following questions as best you can.",
        ("If the input is not a question, formulate it into a question first. "
         "Include intermediate thought in the final answer.")).replace(
        "Use the following format:",
        ("Use the following format (start each response with one of the following prefixes): "
         "[Question, Thought, Action, Action Input, Final Answer]). "
         "If you are making an action, wait for a response to the action input before making an observation. Every response must contain at least one action (and thoughts and observations if you have them), but you cannot have both a final answer and an action in a response. Action input must only contain the exact input, do not provide any text following that in your response. Always end your response with either an action, or a final answer.")))

    return agent_executor


def build_cve_llm_engine(config: EngineConfig, handle_parsing_errors=True) -> LLMEngine:
    engine = LLMEngine()

    engine.add_node("extracter", node=ExtracterNode())

    engine.add_node("checklist", inputs=["/extracter"], node=CVEChecklistNode(config=config.checklist))

    engine.add_node("agent",
                    inputs=[("/checklist")],
                    node=LangChainAgentNode(agent_executor=build_agent_executor(config=config.agent,
                                                                                handle_parsing_errors=handle_parsing_errors)))

    engine.add_task_handler(
        inputs=[("/checklist", "checklist"), ("/agent", "response")],
        handler=SimpleTaskHandler(output_columns=["checklist", "response"]),
    )

    return engine
