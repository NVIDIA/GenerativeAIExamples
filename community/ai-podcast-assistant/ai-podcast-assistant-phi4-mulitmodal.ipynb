{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podcast Notes, Summarization, and Translation using Phi‑4 Multimodal LLM with NVIDIA NIM Microservices\n",
    "\n",
    "This notebook demonstrates a complete workflow using the [**Phi‑4 Multimodal LLM**](https://azure.microsoft.com/en-us/blog/empowering-innovation-the-next-generation-of-the-phi-family/) model. Below are some key model details (from the internal model card):\n",
    "\n",
    "- **Parameters:** 5.6B\n",
    "- **Inputs:** Text, Image, Audio\n",
    "- **Context Length:** 128K tokens\n",
    "- **Training Data:** 5T text tokens, 2.3M speech hours, 1.1T image-text tokens\n",
    "- **Supported Languages:** Multilingual text and audio (e.g. English, Chinese, German, French, etc.)\n",
    "\n",
    "The Phi-4 LLM will be accelerated with NVIDIA NIM Microservices in this tutorial. NVIDIA NIM Microservices that is a set of easy-to-use inference microservices for accelerating the deployment of foundation models on any cloud or data center and helping to keep your data secure.\n",
    "\n",
    "We will be using [preview NIM microservice API](https://build.nvidia.com/microsoft/phi-4-multimodal-instruct) for Phi-4 through the  [NVIDIA API Catalog](https://build.nvidia.com/microsoft)\n",
    "\n",
    "This notebook covers:\n",
    "1. A podcast notes and summarization use-case (with long-audio chunking).\n",
    "2. Translation of the transcript and summary into another language.\n",
    "\n",
    "Ensure that you have the required dependencies (e.g. `pydub`, `requests`, `Pillow`) installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydub requests Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions for Audio Processing\n",
    "\n",
    "In this section, we define helper functions to process audio files, such as converting an audio segment to a base64-encoded string \n",
    "and splitting long audio into manageable chunks for transcription.\n",
    "\n",
    "\n",
    "### Function Overview\n",
    "\n",
    "- **audio_to_base64**: Converts audio segments to base64-encoded strings for API transmission\n",
    "- **generate_notes_chunk**: Processes individual audio chunks and generates transcription\n",
    "- **generate_detailed_notes**: Handles long audio files by splitting them into manageable chunks\n",
    "- **refine_transcription_to_notes**: Transforms raw transcription into well-formatted notes\n",
    "- **summarize_notes**: Creates a concise summary from the detailed notes\n",
    "- **translate_text**: Translates content to other languages while preserving formatting\n",
    "- **save_text_to_file**: Exports results to text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from pydub import AudioSegment\n",
    "\n",
    "API_URL = \"https://integrate.api.nvidia.com/v1/chat/completions\"\n",
    "\n",
    "def audio_to_base64(audio_segment):\n",
    "    \"\"\"Convert a pydub AudioSegment to a base64-encoded WAV string.\"\"\"\n",
    "    buffer = BytesIO()\n",
    "    audio_segment.export(buffer, format=\"mp3\")\n",
    "    return base64.b64encode(buffer.getvalue()).decode()\n",
    "\n",
    "def generate_notes_chunk(audio_chunk, api_key, chunk_index, total_chunks):\n",
    "    \"\"\"\n",
    "    Generate detailed notes for a single audio chunk.\n",
    "    \n",
    "    The prompt instructs the model to produce detailed notes without any extra commentary.\n",
    "    \"\"\"\n",
    "    audio_b64 = audio_to_base64(audio_chunk)\n",
    "    prompt = (\n",
    "        f\"Transcribe the following audio accurately. \"\n",
    "        f\"This is segment {chunk_index+1} of {total_chunks}. \"\n",
    "        \"Please do not include any system commentary or self-referential text.\"\n",
    "    )\n",
    "    # Append the audio data (encoded in base64)\n",
    "    prompt += f' <audio src=\"data:audio/wav;base64,{audio_b64}\" />'\n",
    "    \n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Accept\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": \"microsoft/phi-4-multimodal-instruct\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You're a transcription assistant.\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": 1024,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.7,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    result = response.json()\n",
    "    try:\n",
    "        text = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except Exception as e:\n",
    "        text = f\"[Error generating notes for chunk {chunk_index+1}: {e}]\"\n",
    "    return text\n",
    "\n",
    "def generate_detailed_notes(audio_path, api_key, chunk_duration_ms=30000):\n",
    "    \"\"\"\n",
    "    Process a long audio file by splitting it into chunks, generating detailed notes for each chunk,\n",
    "    and concatenating the results.\n",
    "    \"\"\"\n",
    "    # Load audio file using pydub\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    total_duration = len(audio)\n",
    "    total_chunks = (total_duration // chunk_duration_ms) + (1 if total_duration % chunk_duration_ms > 0 else 0)\n",
    "    \n",
    "    notes_chunks = []\n",
    "    for i in range(total_chunks):\n",
    "        start_ms = i * chunk_duration_ms\n",
    "        end_ms = min((i+1) * chunk_duration_ms, total_duration)\n",
    "        chunk = audio[start_ms:end_ms]\n",
    "        print(f\"Processing chunk {i+1}/{total_chunks} (from {start_ms}ms to {end_ms}ms)...\")\n",
    "        notes = generate_notes_chunk(chunk, api_key, i, total_chunks)\n",
    "        notes_chunks.append(notes)\n",
    "    \n",
    "    transcription = \"\\n\\n\".join(notes_chunks)\n",
    "    return transcription\n",
    "\n",
    "\n",
    "def refine_transcription_to_notes(transcription, api_key):\n",
    "    \"\"\"\n",
    "    Given a raw transcription, remove any system prompt lines and generate coherent, well-formatted detailed notes.\n",
    "    \"\"\"\n",
    "    # Remove unwanted system phrases\n",
    "    cleaned = transcription.replace(\"You are a helpful assistant.\", \"\").replace(\"you are a helpful assistant.\", \"\")\n",
    "    \n",
    "    # Build a prompt instructing the LLM to produce formatted notes\n",
    "    prompt = (\n",
    "        \"Based on the transcription below, generate well-formatted, detailed notes that capture the main points. \"\n",
    "        \"Organize the notes using bullet points or numbered lists for key points and separate paragraphs clearly for readability. \"\n",
    "        \"Do not include any system commentary or self-referential text.\\n\\n\"\n",
    "        \"Transcription:\\n\"\n",
    "        f\"{cleaned}\"\n",
    "    )\n",
    "    \n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Accept\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": \"microsoft/phi-4-multimodal-instruct\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a note-taking assistant. Provide only detailed, well-formatted notes.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": 1024,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.7,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    result = response.json()\n",
    "    try:\n",
    "        notes = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except Exception as e:\n",
    "        notes = f\"[Error generating refined notes: {e}]\"\n",
    "    return notes\n",
    "\n",
    "\n",
    "\n",
    "def summarize_notes(notes, api_key):\n",
    "    \"\"\"\n",
    "    Generate a concise summary based on the detailed notes.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"Based on the detailed notes provided below, please generate a concise summary of the content. \"\n",
    "        \"Do not include any extra commentary or self-referential text.\\n\\n\"\n",
    "        f\"{notes}\"\n",
    "    )\n",
    "    \n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Accept\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": \"microsoft/phi-4-multimodal-instruct\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a summarization assistant. Provide only a concise summary.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.7,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    result = response.json()\n",
    "    try:\n",
    "        summary = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except Exception as e:\n",
    "        summary = f\"[Error generating summary: {e}]\"\n",
    "    return summary\n",
    "\n",
    "\n",
    "def translate_text(text, target_lang, api_key):\n",
    "    \"\"\"\n",
    "    Translate the given text into the target language using the Phi‑4 API,\n",
    "    preserving all bullet points, formatting, and structure.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        f\"Translate the following text to {target_lang} exactly as it is, \"\n",
    "        \"preserving all bullet points, formatting, and structure. Do not omit any sections.\\n\\n\"\n",
    "        f\"{text}\"\n",
    "    )\n",
    "    \n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Accept\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": \"microsoft/phi-4-multimodal-instruct\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a translation assistant. Provide only the translated text with the original formatting preserved.\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": 1500,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.7,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    result = response.json()\n",
    "    try:\n",
    "        translated_text = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except Exception as e:\n",
    "        translated_text = f\"[Error generating translation: {e}]\"\n",
    "    return translated_text\n",
    "\n",
    "\n",
    "def save_text_to_file(text, filename):\n",
    "    \"\"\"Save the given text to a file.\"\"\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "    print(f\"Text saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow for detailed notes generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your NVIDIA API key and podcast audio file path\n",
    "API_KEY = \"your_api_key_here\"\n",
    "podcast_audio_path = \"podcast_audio.mp3\"  # update with your file path\n",
    "\n",
    "# Generate detailed notes from the audio file (with 30-second chunks by default)\n",
    "print(\"Starting detailed note generation...\")\n",
    "transcription = generate_detailed_notes(podcast_audio_path, API_KEY, chunk_duration_ms=30000)\n",
    "detailed_notes = refine_transcription_to_notes(transcription, API_KEY)\n",
    "\n",
    "print(\"\\n--- Detailed Notes ---\\n\")\n",
    "print(detailed_notes)\n",
    "\n",
    "# Generate a summary of the detailed notes\n",
    "print(\"\\nGenerating summary...\")\n",
    "summary = summarize_notes(detailed_notes, API_KEY)\n",
    "\n",
    "print(\"\\n--- Summary ---\\n\")\n",
    "print(summary)\n",
    "\n",
    "# Save detailed notes and summary to a text file\n",
    "combined_text = detailed_notes + \"\\n\\n--- SUMMARY ---\\n\\n\" + summary\n",
    "save_text_to_file(combined_text, \"podcast_detailed_notes.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation\n",
    "\n",
    "The following cell translates the combined notes and summary into another language (e.g., Spanish)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_language = \"Spanish\"\n",
    "print(f\"\\nTranslating transcript and summary to {target_language}...\")\n",
    "translated_text = translate_text(combined_text, target_language, API_KEY)\n",
    "\n",
    "print(\"\\n--- Translated Text ---\\n\")\n",
    "print(translated_text)\n",
    "\n",
    "# Save the translated text to a file\n",
    "save_text_to_file(translated_text, \"podcast_transcription_translated.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "If you encounter issues with the API, here are some common problems and solutions:\n",
    "\n",
    "1. **Payload Too Large**: Use the optimization functions with more aggressive parameters\n",
    "2. **Authentication Errors**: Verify your API key is correct and has the necessary permissions\n",
    "3. **Model Not Available**: Check that you're using a valid model name for your account tier\n",
    "4. **Format Issues**: Ensure your media files are in supported formats\n",
    "5. **Rate Limiting**: If processing many chunks, add delays between API calls to avoid rate limits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health_companion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
