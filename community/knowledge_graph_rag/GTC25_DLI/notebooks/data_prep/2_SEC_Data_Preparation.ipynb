{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdc37f31",
   "metadata": {},
   "source": [
    "# SEC Filing Data Extraction for GraphRAG\n",
    "\n",
    "This notebook processes XBRL files, extracts specific sections, and saves them in JSON format. This is particularly useful for creating a GraphRAG (Graph-based Retrieval-Augmented Generation) system for financial documents. By extracting structured data from these filings, we can enhance the knowledge graph with detailed financial information, which can be used for various analytical and generative tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11c89fa",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries\n",
    "\n",
    "We begin by importing the necessary libraries. `os` and `json` are used for file operations and data handling, while `BeautifulSoup` from the `bs4` library is used for parsing HTML/XBRL content. Parsing is crucial for extracting structured information from the filings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26bdfc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8adf544",
   "metadata": {},
   "source": [
    "## Define Functions for Data Extraction\n",
    "\n",
    "### Extract Sections\n",
    "This function extracts specific sections from the filing text. For a GraphRAG, it's important to have well-defined sections as they represent different nodes or entities in the graph. Each section corresponds to a key aspect of the financial document, such as business overview, risk factors, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bb86ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sections(text, form_type):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    text = soup.get_text(separator=' ')\n",
    "    \n",
    "    if form_type == \"10-K\":\n",
    "        sections = {\n",
    "            \"Item 1. Business\": extract_section(text, \"Item 1. Business\", \"Item 1A. Risk Factors\"),\n",
    "            \"Item 1A. Risk Factors\": extract_section(text, \"Item 1A. Risk Factors\", \"Item 1B. Unresolved Staff Comments\"),\n",
    "            \"Item 7. Management's Discussion and Analysis (MD&A)\": extract_section(text, \"Item 7. Management's Discussion and Analysis\", \"Item 7A. Quantitative and Qualitative Disclosures About Market Risk\"),\n",
    "            \"Item 8. Financial Statements and Supplementary Data\": extract_section(text, \"Item 8. Financial Statements and Supplementary Data\", \"Item 9. Changes in and Disagreements with Accountants on Accounting and Financial Disclosure\")\n",
    "        }\n",
    "    elif form_type == \"10-Q\":\n",
    "        sections = {\n",
    "            \"Item 2. Management's Discussion and Analysis (MD&A)\": extract_section(text, \"Item 2. Management's Discussion and Analysis of Financial Condition and Results of Operations\", \"Item 3. Quantitative and Qualitative Disclosures About Market Risk\"),\n",
    "            \"Item 1. Financial Statements\": extract_section(text, \"Item 1. Financial Statements\", \"Item 2. Management's Discussion and Analysis of Financial Condition and Results of Operations\"),\n",
    "            \"Item 1A. Risk Factors\": extract_section(text, \"Item 1A. Risk Factors\", \"Item 2. Unregistered Sales of Equity Securities and Use of Proceeds\"),\n",
    "            \"Item 4. Controls and Procedures\": extract_section(text, \"Item 4. Controls and Procedures\", \"Item 5. Other Information\")\n",
    "        }\n",
    "    else:\n",
    "        sections = {}\n",
    "    \n",
    "    return sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb3419",
   "metadata": {},
   "source": [
    "### Extract Section\n",
    "This helper function extracts a section of text between two headings. It's essential for isolating the content of interest, which can then be used to populate nodes in the knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c57ae281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_section(text, start_heading, end_heading):\n",
    "    start_index = text.find(start_heading)\n",
    "    end_index = text.find(end_heading, start_index)\n",
    "    if start_index != -1 and end_index != -1:\n",
    "        return text[start_index:end_index].strip()\n",
    "    elif start_index != -1:\n",
    "        return text[start_index:].strip()\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f1c791",
   "metadata": {},
   "source": [
    "### Extract CIK\n",
    "The Central Index Key (CIK) is a unique identifier for companies in the SEC's EDGAR database. Extracting this allows us to link the filing to the correct entity in our knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3318682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cik(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    cik_tag = soup.find('ix:nonNumeric', {'name': 'dei:EntityCentralIndexKey'})\n",
    "    if cik_tag:\n",
    "        return cik_tag.text.strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587b775f",
   "metadata": {},
   "source": [
    "### Extract Fiscal Year\n",
    "Extracting the fiscal year helps in organizing the data temporally within the knowledge graph, allowing for time-based queries and analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7ffb325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fiscal_year(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    fiscal_year_tag = soup.find('ix:nonNumeric', {'name': 'dei:DocumentFiscalYearFocus'})\n",
    "    if fiscal_year_tag:\n",
    "        return fiscal_year_tag.text.strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08afe6a",
   "metadata": {},
   "source": [
    "### Extract Fiscal Quarter\n",
    "Similar to fiscal year, the fiscal quarter provides finer granularity for temporal data organization in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d59f338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fiscal_quarter(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    fiscal_quarter_tag = soup.find('ix:nonNumeric', {'name': 'dei:DocumentFiscalPeriodFocus'})\n",
    "    if fiscal_quarter_tag:\n",
    "        return fiscal_quarter_tag.text.strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904df71e",
   "metadata": {},
   "source": [
    "## Process Tickers\n",
    "This function processes each ticker, extracts relevant data, and saves it in JSON format. The structured JSON output is suitable for ingestion into a knowledge graph, where each section can be linked to other related data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2eeea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tickers(ticker_file, input_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    with open(ticker_file, 'r') as file:\n",
    "        tickers = json.load(file)\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        ticker_dir = os.path.join(input_dir, ticker)\n",
    "        if os.path.isdir(ticker_dir):\n",
    "            for root, dirs, files in os.walk(ticker_dir):\n",
    "                for file in files:\n",
    "                    if file.endswith(\".txt\"):\n",
    "                        file_path = os.path.join(root, file)\n",
    "                        form_type = \"10-K\" if \"10-K\" in file else \"10-Q\"\n",
    "                        try:\n",
    "                            with open(file_path, 'r') as f:\n",
    "                                filing_text = f.read()\n",
    "                                cik = extract_cik(filing_text)\n",
    "                                fiscal_year = extract_fiscal_year(filing_text)\n",
    "                                fiscal_quarter = extract_fiscal_quarter(filing_text)\n",
    "                                sections = extract_sections(filing_text, form_type)\n",
    "                                \n",
    "                                if sections:\n",
    "                                    # Create the JSON structure\n",
    "                                    data = {\n",
    "                                        \"filing\": {\n",
    "                                            \"cik\": cik,\n",
    "                                            \"ticker\": ticker,\n",
    "                                            \"year\": fiscal_year,\n",
    "                                            \"quarter\": fiscal_quarter,\n",
    "                                            \"sections\": sections\n",
    "                                        }\n",
    "                                    }\n",
    "                                    \n",
    "                                    # Save the data to a JSON file\n",
    "                                    json_filename = os.path.join(output_dir, f\"{ticker}_{form_type}_{fiscal_year}_Q{fiscal_quarter}.json\")\n",
    "                                    with open(json_filename, 'w') as json_file:\n",
    "                                        json.dump(data, json_file, indent=4)\n",
    "                                    \n",
    "                                    print(f\"Processed and saved data for ticker: {ticker}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing file {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d381c8e",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "Set up the paths for the ticker file, input directory, and output directory, and then call the `process_tickers` function to start processing. This step is crucial for preparing the data for integration into a GraphRAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee9ca672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "ticker_file = 'company_tickers.json'  # Path to the JSON file containing the list of tickers\n",
    "input_dir = 'path_to_downloaded_files'  # Directory containing the downloaded XBRL files\n",
    "output_dir = 'output_directory'  # Directory to save the JSON files\n",
    "\n",
    "process_tickers(ticker_file, input_dir, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
