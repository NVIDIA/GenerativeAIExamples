{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "675acc69-4d0c-481c-b093-1f1b849019fa",
   "metadata": {},
   "source": [
    "# Part II: LoRA Fine-tuning Using NeMo Customizer\n",
    "\n",
    "This notebook covers the following:\n",
    "\n",
    "0. [Prerequisites: Configurations, Health Checks, and Namespaces](#step-0)\n",
    "1. [Upload Data to NeMo Datastore](#step-1)\n",
    "2. [LoRA Customization with NeMo Customizer](#step-2)\n",
    "3. [Running Inference on the Customized Model with NVIDIA NIM](#step-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96adf453-5f61-435c-9ed2-257cdcebe24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "from nemo_microservices import NeMoMicroservices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e84c255-d91b-4ee8-9db2-61634ab70179",
   "metadata": {},
   "source": [
    "<a id=\"step-0\"></a>\n",
    "## Prerequisites: Configurations, Health Checks, and Namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b175f7f-4ada-465e-ac84-e40aac6abb38",
   "metadata": {},
   "source": [
    "Before you proceed, make sure that you completed the first notebook on data preparation to obtain the assets required to follow along."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd6ee1a-0789-4724-8f12-5157363ebf9c",
   "metadata": {},
   "source": [
    "### Configure NeMo Microservices Endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa34fe25",
   "metadata": {},
   "source": [
    "This section includes importing required libraries, configuring endpoints, and performing health checks to ensure that the NeMo Data Store, NIM, and other services are running correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "655babe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "\n",
    "# Initialize NeMo Microservices SDK client\n",
    "nemo_client = NeMoMicroservices(\n",
    "    base_url=NEMO_URL,\n",
    "    inference_base_url=NIM_URL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d29578e1-6757-4e89-8f29-a0f6739015c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Store endpoint: http://data-store.test\n",
      "Entity Store, Customizer, Evaluator endpoint: http://nemo.test\n",
      "NIM endpoint: http://nim.test\n",
      "Namespace: xlam-tutorial-ns\n",
      "Base Model for Customization: meta/llama-3.2-1b-instruct@v1.0.0+A100\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data Store endpoint: {NDS_URL}\")\n",
    "print(f\"Entity Store, Customizer, Evaluator endpoint: {NEMO_URL}\")\n",
    "print(f\"NIM endpoint: {NIM_URL}\")\n",
    "print(f\"Namespace: {NMS_NAMESPACE}\")\n",
    "print(f\"Base Model for Customization: {BASE_MODEL}@{BASE_MODEL_VERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b039f7-f07d-4189-add1-d47941a4d78e",
   "metadata": {},
   "source": [
    "### Configure Path to Prepared data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa89d41",
   "metadata": {},
   "source": [
    "The following code sets the paths to the prepared dataset files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26e8c768-498e-47df-b8c4-805b25b63d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where data preparation notebook saved finetuning and evaluation data\n",
    "DATA_ROOT = os.path.join(os.getcwd(), \"data\")\n",
    "CUSTOMIZATION_DATA_ROOT = os.path.join(DATA_ROOT, \"customization\")\n",
    "VALIDATION_DATA_ROOT = os.path.join(DATA_ROOT, \"validation\")\n",
    "EVALUATION_DATA_ROOT = os.path.join(DATA_ROOT, \"evaluation\")\n",
    "\n",
    "# Sanity checks\n",
    "train_fp = f\"{CUSTOMIZATION_DATA_ROOT}/training.jsonl\"\n",
    "assert os.path.exists(train_fp), f\"The training data at '{train_fp}' does not exist. Please ensure that the data was prepared successfully.\"\n",
    "\n",
    "val_fp = f\"{VALIDATION_DATA_ROOT}/validation.jsonl\"\n",
    "assert os.path.exists(val_fp), f\"The validation data at '{val_fp}' does not exist. Please ensure that the data was prepared successfully.\"\n",
    "\n",
    "test_fp = f\"{EVALUATION_DATA_ROOT}/xlam-test-single.jsonl\"\n",
    "assert os.path.exists(test_fp), f\"The test data at '{test_fp}' does not exist. Please ensure that the data was prepared successfully.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062c7805-727f-4265-9248-5babc4a32fc5",
   "metadata": {},
   "source": [
    "### Resource Organization Using Namespace\n",
    "\n",
    "You can use a [namespace](https://docs.nvidia.com/nemo/microservices/latest/manage-entities/namespaces/index.html) to isolate and organize the artifacts in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e57ea9a-05b0-4e5e-9455-fc7c2c515ca1",
   "metadata": {},
   "source": [
    "#### Create Namespace\n",
    "\n",
    "Both Data Store and Entity Store use namespaces. The following code creates namespaces for the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dff1528-2c7c-4118-8921-f54167ba57ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created namespace in Entity Store: xlam-tutorial-ns\n",
      "Data Store namespace creation response: <Response [201]>\n"
     ]
    }
   ],
   "source": [
    "def create_namespaces(nemo_client, ds_host, namespace):\n",
    "    # Create namespace in Entity Store\n",
    "    try:\n",
    "        namespace_obj = nemo_client.namespaces.create(id=namespace)\n",
    "        print(f\"Created namespace in Entity Store: {namespace_obj.id}\")\n",
    "    except Exception as e:\n",
    "        # Handle if namespace already exists\n",
    "        if \"409\" in str(e) or \"422\" in str(e):\n",
    "            print(f\"Namespace {namespace} already exists in Entity Store\")\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # Create namespace in Data Store (still using requests as SDK doesn't cover Data Store)\n",
    "    nds_url = f\"{ds_host}/v1/datastore/namespaces\"\n",
    "    resp = requests.post(nds_url, data={\"namespace\": namespace})\n",
    "    assert resp.status_code in (200, 201, 409, 422), \\\n",
    "        f\"Unexpected response from Data Store during namespace creation: {resp.status_code}\"\n",
    "    print(f\"Data Store namespace creation response: {resp}\")\n",
    "\n",
    "create_namespaces(nemo_client=nemo_client, ds_host=NDS_URL, namespace=NMS_NAMESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057acae8-4d0b-48ee-bd8f-6f98bd941ba6",
   "metadata": {},
   "source": [
    "#### Verify Namespaces\n",
    "\n",
    "The following [Data Store API](https://docs.nvidia.com/nemo/microservices/latest/api/datastore.html) and [Entity Store API](https://docs.nvidia.com/nemo/microservices/latest/api/entity-store.html) list the namespace created in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "413166f0-a314-4db0-a341-914495b583ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Store - Status Code: 201\n",
      "Response JSON: {'namespace': 'xlam-tutorial-ns', 'created_at': '2025-06-20T03:56:39Z', 'updated_at': '2025-06-20T03:56:39Z'}\n",
      "\n",
      "Entity Store - Namespace: xlam-tutorial-ns\n",
      "Created at: 2025-06-20 03:56:39.457820\n",
      "Description: None\n",
      "Project: None\n"
     ]
    }
   ],
   "source": [
    "# Verify Namespace in Data Store (using requests as SDK doesn't cover Data Store)\n",
    "response = requests.get(f\"{NDS_URL}/v1/datastore/namespaces/{NMS_NAMESPACE}\")\n",
    "print(f\"Data Store - Status Code: {response.status_code}\\nResponse JSON: {response.json()}\")\n",
    "\n",
    "# Verify Namespace in Entity Store\n",
    "namespace_obj = nemo_client.namespaces.retrieve(namespace_id=NMS_NAMESPACE)\n",
    "print(f\"\\nEntity Store - Namespace: {namespace_obj.id}\")\n",
    "print(f\"Created at: {namespace_obj.created_at}\")\n",
    "print(f\"Description: {namespace_obj.description}\")\n",
    "print(f\"Project: {namespace_obj.project}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556e6df9-bb6b-4606-80da-e936f68a5d23",
   "metadata": {},
   "source": [
    "**Tips**:\n",
    "To list all available namespaces use\n",
    "```python\n",
    "requests.get(f\"{NDS_URL}/v1/datastore/namespaces/\") # For Data Store\n",
    "nemo_client.namespaces.list() # For Entity Store\n",
    "```\n",
    "\n",
    "To delete a namespace use:\n",
    "```python\n",
    "requests.delete(f\"{NDS_URL}/v1/datastore/namespaces/{namespace}\") # For Data Store\n",
    "nemo_client.namespaces.delete(namespace) # For Entity Store\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e83d04-e092-49bd-8769-3422526e135b",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"step-1\"></a>\n",
    "## Step 1: Upload Data to NeMo Data Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbdb147-9994-4e08-a742-38098f4dc911",
   "metadata": {},
   "source": [
    "The NeMo Data Store supports data management using the Hugging Face `HfApi` Client. \n",
    "\n",
    "**Note that this step does not interact with Hugging Face at all, it just uses the client library to interact with NeMo Data Store.** This is in comparison to the previous notebook, where we used the `load_dataset` API to download the xLAM dataset from Hugging Face's repository.\n",
    "\n",
    "More information can be found in [documentation](https://docs.nvidia.com/nemo/microservices/latest/manage-entities/tutorials/manage-dataset-files.html#set-up-hugging-face-client-with-nemo-data-store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29d515c-bd7d-4fdb-9c6d-42370d975e69",
   "metadata": {},
   "source": [
    "### 1.1 Create Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1a1178a-b516-4f50-96a3-2dee114f9cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = f\"{NMS_NAMESPACE}/{DATASET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd240212-3272-419e-b19b-d31d8aede2b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T14:02:46.351447Z",
     "start_time": "2025-02-28T14:02:46.343156Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepoUrl('datasets/xlam-tutorial-ns/xlam-ft-dataset', endpoint='http://data-store.test/v1/hf', repo_type='dataset', repo_id='xlam-tutorial-ns/xlam-ft-dataset')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "hf_api = HfApi(endpoint=f\"{NDS_URL}/v1/hf\", token=\"\")\n",
    "\n",
    "# Create repo\n",
    "hf_api.create_repo(\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ac352a-31b9-4144-ad0f-699fcceebfc2",
   "metadata": {},
   "source": [
    "Next, creating a dataset programmatically requires two steps: uploading and registration. More information can be found in [documentation](https://docs.nvidia.com/nemo/microservices/latest/manage-entities/datasets/create-dataset.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f927b0-b216-46f9-a8d0-0f9d6836868f",
   "metadata": {},
   "source": [
    "### 1.2 Upload Dataset Files to NeMo Data Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50be5cec-5df6-4092-82ff-29d39aceaa1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677700072a21408a8cbe5e3721d172a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training.jsonl:   0%|          | 0.00/6.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e08a0621634de9b75bdf04bfcf7aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation.jsonl:   0%|          | 0.00/1.30M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec14b764c8c4e67bc7dc609f9a604bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xlam-test-single.jsonl:   0%|          | 0.00/1.19M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='', commit_message='Upload testing/xlam-test-single.jsonl with huggingface_hub', commit_description='', oid='e55b3211ba39e6ce80dd8a03a79600183e900f1c', pr_url=None, repo_url=RepoUrl('', endpoint='https://huggingface.co', repo_type='model', repo_id=''), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_api.upload_file(path_or_fileobj=train_fp,\n",
    "    path_in_repo=\"training/training.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")\n",
    "\n",
    "hf_api.upload_file(path_or_fileobj=val_fp,\n",
    "    path_in_repo=\"validation/validation.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")\n",
    "\n",
    "hf_api.upload_file(path_or_fileobj=test_fp,\n",
    "    path_in_repo=\"testing/xlam-test-single.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5d0ab1-69b2-4ca5-9a25-d514cf72b7cd",
   "metadata": {},
   "source": [
    "Other tips:\n",
    "* Take a look at the `path_in_repo` argument above. If there are more than one files in the subfolders:\n",
    "    * All the .jsonl files in `training/` will be merged and used for training by customizer.\n",
    "    * All the .jsonl files in `validation/` will be merged and used for validation by customizer.\n",
    "* NeMo Data Store generally supports data management using the [HfApi API](https://huggingface.co/docs/huggingface_hub/en/package_reference/hf_api). For example, to delete a repo, you may use - \n",
    "```python\n",
    "   hf_api.delete_repo(\n",
    "     repo_id=repo_id,\n",
    "     repo_type=\"dataset\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a371c044-56df-412d-9fb3-7e0e191dd3a8",
   "metadata": {},
   "source": [
    "### 1.3 Register the Dataset with NeMo Entity Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ab2d1d-17d5-4c7a-9b1b-8f8b1c68204c",
   "metadata": {},
   "source": [
    "To use a dataset for operations such as evaluations and customizations, register a dataset using the `nemo_client.datasets.create()` method.\n",
    "Register the dataset to refer to it by its namespace and name afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a45fadd-df51-48e0-b30c-336c5bca071a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset: xlam-tutorial-ns/xlam-ft-dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset(files_url='hf://datasets/xlam-tutorial-ns/xlam-ft-dataset', id='dataset-3G75hURMVmSLfNahcqQZd5', created_at=datetime.datetime(2025, 6, 20, 3, 58, 16, 182000), custom_fields={}, description='Tool calling xLAM dataset in OpenAI ChatCompletions format', format=None, hf_endpoint=None, limit=None, name='xlam-ft-dataset', namespace='xlam-tutorial-ns', project='tool_calling', split=None, updated_at=datetime.datetime(2025, 6, 20, 3, 58, 16, 182001))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataset\n",
    "dataset = nemo_client.datasets.create(\n",
    "    name=DATASET_NAME,\n",
    "    namespace=NMS_NAMESPACE,\n",
    "    description=\"Tool calling xLAM dataset in OpenAI ChatCompletions format\",\n",
    "    files_url=f\"hf://datasets/{NMS_NAMESPACE}/{DATASET_NAME}\",\n",
    "    project=\"tool_calling\",\n",
    ")\n",
    "print(f\"Created dataset: {dataset.namespace}/{dataset.name}\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a2b58c7-30d7-4c04-b3a5-872032dbf4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files URL: hf://datasets/xlam-tutorial-ns/xlam-ft-dataset\n"
     ]
    }
   ],
   "source": [
    "# Sanity check to validate dataset\n",
    "dataset_obj = nemo_client.datasets.retrieve(namespace=NMS_NAMESPACE, dataset_name=DATASET_NAME)\n",
    "\n",
    "print(\"Files URL:\", dataset_obj.files_url)\n",
    "assert dataset_obj.files_url == f\"hf://datasets/{repo_id}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7cebbc-8a5f-492d-820c-b3fbbed6fafb",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"step-2\"></a>\n",
    "## 2. LoRA Customization with NeMo Customizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6915c1f5-9687-443f-92cd-cd30b55fc501",
   "metadata": {},
   "source": [
    "### 2.1 Start the Training Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e22fa48",
   "metadata": {},
   "source": [
    "Start the training job by calling `nemo_client.customization.jobs.create()` method.\n",
    "The following code sets the training parameters and starts the job.\n",
    "\n",
    "**The training job will take approximately 45 minutes to complete.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2e9678c-2785-4e95-b11b-1f41067bc920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created customization job: cust-FarcM8gwhL1XFDXQ57qGLL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomizationJobOutput(config='meta/llama-3.2-1b-instruct@v1.0.0+A100', config_snapshot=ConfigSnapshot(base_model='meta/llama-3.2-1b-instruct', max_seq_length=4096, precision='bf16-mixed', training_option=CustomizationTrainingOption(finetuning_type='lora', micro_batch_size=1, num_gpus=1, training_type='sft', data_parallel_size=1, num_nodes=1, pipeline_parallel_size=1, tensor_parallel_size=1, use_sequence_parallel=False), chat_prompt_template=None, name=None, namespace=None, prompt_template='{prompt} {completion}', tokenizer=None), dataset='xlam-tutorial-ns/xlam-ft-dataset', hyperparameters=Hyperparameters(finetuning_type='lora', batch_size=16, distillation=None, epochs=2, learning_rate=0.0001, log_every_n_steps=None, lora=Lora(adapter_dim=32, adapter_dropout=0.1, alpha=16, target_modules=None), p_tuning=None, sequence_packing_enabled=False, sft=None, training_type='sft', val_check_interval=None, weight_decay=None), id='cust-FarcM8gwhL1XFDXQ57qGLL', created_at=datetime.datetime(2025, 6, 20, 4, 20, 21, 387984), dataset_parameters=None, description=None, integrations=None, namespace='default', output_model='xlam-tutorial-ns/llama-3.2-1b-xlam-run1@cust-FarcM8gwhL1XFDXQ57qGLL', ownership=None, project=None, status='created', status_details={'created_at': '2025-06-20T04:20:22.061480', 'updated_at': '2025-06-20T04:20:22.061480', 'elapsed_time': 0.0, 'steps_completed': 0, 'epochs_completed': 0, 'percentage_done': 0.0, 'status_logs': [{'updated_at': '2025-06-20T04:20:22.061480', 'message': 'created'}]}, updated_at=datetime.datetime(2025, 6, 20, 4, 20, 21, 387989), warnings=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create customization job\n",
    "# If WANDB_API_KEY is set, we send it in the request header, which will report the training metrics to Weights & Biases (WandB).\n",
    "if WANDB_API_KEY:\n",
    "    client_with_wandb = nemo_client.with_options(default_headers={\"wandb-api-key\": WANDB_API_KEY})\n",
    "else:\n",
    "    client_with_wandb = nemo_client\n",
    "\n",
    "customization = client_with_wandb.customization.jobs.create(\n",
    "    name=\"llama-3.2-1b-xlam-ft\",\n",
    "    output_model=CUSTOM_MODEL,\n",
    "    config=f\"{BASE_MODEL}@{BASE_MODEL_VERSION}\",\n",
    "    dataset={\"name\": DATASET_NAME, \"namespace\": NMS_NAMESPACE},\n",
    "    hyperparameters={\n",
    "        \"training_type\": \"sft\",\n",
    "        \"finetuning_type\": \"lora\",\n",
    "        \"epochs\": 2,\n",
    "        \"batch_size\": 16,\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"lora\": {\n",
    "            \"adapter_dim\": 32,\n",
    "            \"adapter_dropout\": 0.1\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"Created customization job: {customization.id}\")\n",
    "customization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec19b6b-7c38-4bd9-91b5-e336ec0d9ff2",
   "metadata": {},
   "source": [
    "**Note**: In the snippet above, the model name and version are passed directly in the `config` argument. However, in production environments, administrators typically create customization **[targets](https://docs.nvidia.com/nemo/microservices/latest/fine-tune/manage-customization-targets/index.html)** and corresponding **[configs](https://docs.nvidia.com/nemo/microservices/latest/fine-tune/manage-customization-configs/index.html)**. This approach allows you to configure once and reuse model configurations for multiple customization jobs. In such cases, you simply reference the created configuration in the `config` argument. For more details, refer to the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69131ef8",
   "metadata": {},
   "source": [
    "The following code sets variables for storing the job ID and customized model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57eb5ae6-9b3e-4915-8242-34b65b0c0680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To track status\n",
    "JOB_ID = customization.id\n",
    "\n",
    "customization = nemo_client.customization.jobs.retrieve(JOB_ID)\n",
    "\n",
    "# This will be the name of the model that will be used to send inference queries to\n",
    "CUSTOMIZED_MODEL = customization.output_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9169153d-2ff0-4b34-9a3d-236ecedb7a5d",
   "metadata": {},
   "source": [
    "**Tips**:\n",
    "* If you configured the NeMo Customizer microservice with your own [Weights & Biases (WandB)](https://wandb.ai/) API key, you can find the training graphs and logs in your WandB account, \"nvidia-nemo-customizer\" project. Your run ID is similar to your customization `JOB_ID`.\n",
    "  \n",
    "* To cancel a job that you scheduled incorrectly, run the following code.\n",
    "  \n",
    "  ```python\n",
    "  nemo_client.customization.jobs.cancel(job_id=JOB_ID)\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab1b3b7-5e0d-4bbb-a7cb-476e0abb298b",
   "metadata": {},
   "source": [
    "### 2.2 Get Job Status\n",
    "\n",
    "Get the job status by using the `nemo_client.customization.jobs.status()` method.\n",
    "The following code sets the job ID and sends the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "900f28fb-fb8e-4d57-88d7-6c09699523e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage done: 100.0\n",
      "Job Status: {\n",
      "  \"created_at\": \"2025-06-20 04:20:22.061480\",\n",
      "  \"status\": \"failed\",\n",
      "  \"updated_at\": \"2025-06-20 04:46:50.376819\",\n",
      "  \"best_epoch\": 2,\n",
      "  \"elapsed_time\": 0.0,\n",
      "  \"epochs_completed\": 2,\n",
      "  \"metrics\": {\n",
      "    \"keys\": [\n",
      "      \"train_loss\",\n",
      "      \"val_loss\"\n",
      "    ],\n",
      "    \"metrics\": {\n",
      "      \"train_loss\": [\n",
      "        {\n",
      "          \"step\": 9,\n",
      "          \"timestamp\": \"2025-06-20T04:32:50.973138\",\n",
      "          \"value\": 1.8576767444610596\n",
      "        },\n",
      "        {\n",
      "          \"step\": 19,\n",
      "          \"timestamp\": \"2025-06-20T04:33:08.341909\",\n",
      "          \"value\": 0.5704246759414673\n",
      "        },\n",
      "        {\n",
      "          \"step\": 29,\n",
      "          \"timestamp\": \"2025-06-20T04:33:26.712158\",\n",
      "          \"value\": 0.12280075997114182\n",
      "        },\n",
      "        {\n",
      "          \"step\": 39,\n",
      "          \"timestamp\": \"2025-06-20T04:33:44.524580\",\n",
      "          \"value\": 0.04450385272502899\n",
      "        },\n",
      "        {\n",
      "          \"step\": 49,\n",
      "          \"timestamp\": \"2025-06-20T04:34:02.972717\",\n",
      "          \"value\": 0.16312028467655182\n",
      "        },\n",
      "        {\n",
      "          \"step\": 59,\n",
      "          \"timestamp\": \"2025-06-20T04:34:21.251629\",\n",
      "          \"value\": 0.06606246531009674\n",
      "        },\n",
      "        {\n",
      "          \"step\": 69,\n",
      "          \"timestamp\": \"2025-06-20T04:34:38.958870\",\n",
      "          \"value\": 0.06840228289365768\n",
      "        },\n",
      "        {\n",
      "          \"step\": 79,\n",
      "          \"timestamp\": \"2025-06-20T04:34:56.712386\",\n",
      "          \"value\": 0.014794548973441124\n",
      "        },\n",
      "        {\n",
      "          \"step\": 89,\n",
      "          \"timestamp\": \"2025-06-20T04:35:14.584432\",\n",
      "          \"value\": 0.06460676342248917\n",
      "        },\n",
      "        {\n",
      "          \"step\": 99,\n",
      "          \"timestamp\": \"2025-06-20T04:35:33.584602\",\n",
      "          \"value\": 0.06629155576229095\n",
      "        },\n",
      "        {\n",
      "          \"step\": 109,\n",
      "          \"timestamp\": \"2025-06-20T04:35:50.791133\",\n",
      "          \"value\": 0.0795985758304596\n",
      "        },\n",
      "        {\n",
      "          \"step\": 119,\n",
      "          \"timestamp\": \"2025-06-20T04:36:08.793632\",\n",
      "          \"value\": 0.0649154782295227\n",
      "        },\n",
      "        {\n",
      "          \"step\": 129,\n",
      "          \"timestamp\": \"2025-06-20T04:36:27.129566\",\n",
      "          \"value\": 0.03526812419295311\n",
      "        },\n",
      "        {\n",
      "          \"step\": 139,\n",
      "          \"timestamp\": \"2025-06-20T04:36:44.795064\",\n",
      "          \"value\": 0.05382717028260231\n",
      "        },\n",
      "        {\n",
      "          \"step\": 149,\n",
      "          \"timestamp\": \"2025-06-20T04:37:02.464071\",\n",
      "          \"value\": 0.06577281653881073\n",
      "        },\n",
      "        {\n",
      "          \"step\": 159,\n",
      "          \"timestamp\": \"2025-06-20T04:37:19.491135\",\n",
      "          \"value\": 0.07506256550550461\n",
      "        },\n",
      "        {\n",
      "          \"step\": 169,\n",
      "          \"timestamp\": \"2025-06-20T04:37:37.801428\",\n",
      "          \"value\": 0.05599074810743332\n",
      "        },\n",
      "        {\n",
      "          \"step\": 179,\n",
      "          \"timestamp\": \"2025-06-20T04:37:55.431594\",\n",
      "          \"value\": 0.05787814036011696\n",
      "        },\n",
      "        {\n",
      "          \"step\": 189,\n",
      "          \"timestamp\": \"2025-06-20T04:38:13.119979\",\n",
      "          \"value\": 0.12088055908679962\n",
      "        },\n",
      "        {\n",
      "          \"step\": 199,\n",
      "          \"timestamp\": \"2025-06-20T04:38:32.153647\",\n",
      "          \"value\": 0.028641901910305023\n",
      "        },\n",
      "        {\n",
      "          \"step\": 209,\n",
      "          \"timestamp\": \"2025-06-20T04:38:49.627884\",\n",
      "          \"value\": 0.02677938900887966\n",
      "        },\n",
      "        {\n",
      "          \"step\": 219,\n",
      "          \"timestamp\": \"2025-06-20T04:39:47.214580\",\n",
      "          \"value\": 0.040931180119514465\n",
      "        },\n",
      "        {\n",
      "          \"step\": 229,\n",
      "          \"timestamp\": \"2025-06-20T04:40:04.984682\",\n",
      "          \"value\": 0.046923473477363586\n",
      "        },\n",
      "        {\n",
      "          \"step\": 239,\n",
      "          \"timestamp\": \"2025-06-20T04:40:22.354650\",\n",
      "          \"value\": 0.04601616412401199\n",
      "        },\n",
      "        {\n",
      "          \"step\": 249,\n",
      "          \"timestamp\": \"2025-06-20T04:40:40.309953\",\n",
      "          \"value\": 0.017167748883366585\n",
      "        },\n",
      "        {\n",
      "          \"step\": 259,\n",
      "          \"timestamp\": \"2025-06-20T04:40:58.106455\",\n",
      "          \"value\": 0.05223283916711807\n",
      "        },\n",
      "        {\n",
      "          \"step\": 269,\n",
      "          \"timestamp\": \"2025-06-20T04:41:15.422867\",\n",
      "          \"value\": 0.02956080622971058\n",
      "        },\n",
      "        {\n",
      "          \"step\": 279,\n",
      "          \"timestamp\": \"2025-06-20T04:41:32.624669\",\n",
      "          \"value\": 0.008285900577902794\n",
      "        },\n",
      "        {\n",
      "          \"step\": 289,\n",
      "          \"timestamp\": \"2025-06-20T04:41:50.030973\",\n",
      "          \"value\": 0.04720735549926758\n",
      "        },\n",
      "        {\n",
      "          \"step\": 299,\n",
      "          \"timestamp\": \"2025-06-20T04:42:08.389922\",\n",
      "          \"value\": 0.045284420251846313\n",
      "        },\n",
      "        {\n",
      "          \"step\": 309,\n",
      "          \"timestamp\": \"2025-06-20T04:42:25.731052\",\n",
      "          \"value\": 0.018354125320911407\n",
      "        },\n",
      "        {\n",
      "          \"step\": 319,\n",
      "          \"timestamp\": \"2025-06-20T04:42:42.964505\",\n",
      "          \"value\": 0.030467215925455093\n",
      "        },\n",
      "        {\n",
      "          \"step\": 329,\n",
      "          \"timestamp\": \"2025-06-20T04:43:00.917284\",\n",
      "          \"value\": 0.07479127496480942\n",
      "        },\n",
      "        {\n",
      "          \"step\": 339,\n",
      "          \"timestamp\": \"2025-06-20T04:43:18.372081\",\n",
      "          \"value\": 0.00976032018661499\n",
      "        },\n",
      "        {\n",
      "          \"step\": 349,\n",
      "          \"timestamp\": \"2025-06-20T04:43:36.098891\",\n",
      "          \"value\": 0.005889382213354111\n",
      "        },\n",
      "        {\n",
      "          \"step\": 359,\n",
      "          \"timestamp\": \"2025-06-20T04:43:54.259327\",\n",
      "          \"value\": 0.006259406916797161\n",
      "        },\n",
      "        {\n",
      "          \"step\": 369,\n",
      "          \"timestamp\": \"2025-06-20T04:44:11.483810\",\n",
      "          \"value\": 0.005117898806929588\n",
      "        },\n",
      "        {\n",
      "          \"step\": 379,\n",
      "          \"timestamp\": \"2025-06-20T04:44:28.295927\",\n",
      "          \"value\": 0.025533676147460938\n",
      "        },\n",
      "        {\n",
      "          \"step\": 389,\n",
      "          \"timestamp\": \"2025-06-20T04:44:46.095441\",\n",
      "          \"value\": 0.00949533749371767\n",
      "        },\n",
      "        {\n",
      "          \"step\": 399,\n",
      "          \"timestamp\": \"2025-06-20T04:45:04.837562\",\n",
      "          \"value\": 0.02385464310646057\n",
      "        },\n",
      "        {\n",
      "          \"step\": 409,\n",
      "          \"timestamp\": \"2025-06-20T04:45:22.326863\",\n",
      "          \"value\": 0.034205105155706406\n",
      "        },\n",
      "        {\n",
      "          \"step\": 419,\n",
      "          \"timestamp\": \"2025-06-20T04:45:39.639773\",\n",
      "          \"value\": 0.029642079025506973\n",
      "        },\n",
      "        {\n",
      "          \"step\": 429,\n",
      "          \"timestamp\": \"2025-06-20T04:45:57.049268\",\n",
      "          \"value\": 0.011566996574401855\n",
      "        }\n",
      "      ],\n",
      "      \"val_loss\": [\n",
      "        {\n",
      "          \"step\": 218,\n",
      "          \"timestamp\": \"2025-06-20T04:39:44.782580\",\n",
      "          \"value\": 0.048260852694511414\n",
      "        },\n",
      "        {\n",
      "          \"step\": 437,\n",
      "          \"timestamp\": \"2025-06-20T04:46:50.015687\",\n",
      "          \"value\": 0.044774752110242844\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"percentage_done\": 100.0,\n",
      "  \"status_logs\": [\n",
      "    {\n",
      "      \"updated_at\": \"2025-06-20 04:20:22.061480\",\n",
      "      \"detail\": null,\n",
      "      \"message\": \"created\"\n",
      "    }\n",
      "  ],\n",
      "  \"steps_completed\": 438,\n",
      "  \"steps_per_epoch\": 219,\n",
      "  \"train_loss\": 0.005117898806929588,\n",
      "  \"val_loss\": 0.044774752110242844\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Get job status\n",
    "job_status = nemo_client.customization.jobs.status(job_id=JOB_ID)\n",
    "\n",
    "print(\"Percentage done:\", job_status.percentage_done)\n",
    "print(\"Job Status:\", json.dumps(job_status.model_dump(), indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84514e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add wait job function to wait for the customization job to complete\n",
    "\n",
    "from time import sleep, time\n",
    "\n",
    "def wait_job(nemo_client, job_id: str, polling_interval: int = 10, timeout: int = 6000):\n",
    "    \"\"\"Helper for waiting an eval job using SDK.\"\"\"\n",
    "    start_time = time()\n",
    "    job = nemo_client.customization.jobs.retrieve(job_id=job_id)\n",
    "    status = job.status\n",
    "\n",
    "    while (status in [\"pending\", \"created\", \"running\"]):\n",
    "        # Check for timeout\n",
    "        if time() - start_time > timeout:\n",
    "            raise RuntimeError(f\"Took more than {timeout} seconds.\")\n",
    "\n",
    "        # Sleep before polling again\n",
    "        sleep(polling_interval)\n",
    "\n",
    "        # Fetch updated status and progress\n",
    "        job = nemo_client.customization.jobs.retrieve(job_id=job_id)\n",
    "        status = job.status\n",
    "        progress = 0.0\n",
    "        if status == \"running\" and job.status_details:\n",
    "            progress = job.status_details.percentage_done or 0.0\n",
    "        elif status == \"completed\":\n",
    "            progress = 100\n",
    "\n",
    "        print(f\"Job status: {status} after {time() - start_time:.2f} seconds. Progress: {progress}%\")\n",
    "\n",
    "\n",
    "    return job\n",
    "\n",
    "job = wait_job(nemo_client, JOB_ID, polling_interval=5, timeout=2400)\n",
    "\n",
    "# Wait for 2 minutes, because sometimes, the job is finished, but the finetuned model is not ready in NIM yet.\n",
    "sleep(120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b721be-8ca0-4e8f-99a7-5eb12ea1b47f",
   "metadata": {},
   "source": [
    "**IMPORTANT:** At this point, the customization job should be completed. If waiting for the job to finish failed or the status is not `\"completed\"`, please check the logs (`job.status_details.status_logs`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec56031-ec55-4cec-9f65-b34b87818e01",
   "metadata": {},
   "source": [
    "### 2.3 Validate Availability of Custom Model\n",
    "The following NeMo Entity Store API should display the model when the training job is complete.\n",
    "The list below shows all models filtered by your namespace and sorted by the latest first.\n",
    "For more information about this API, see the [NeMo Entity Store API reference](https://docs.nvidia.com/nemo/microservices/latest/api/entity-store.html).\n",
    "With the following code, you can find all customized models, including the one trained in the previous cells.\n",
    "Look for the `name` fields in the output, which should match your `CUSTOMIZED_MODEL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebad3944-70d5-4b23-9a38-a83774bf20c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 models in namespace xlam-tutorial-ns:\n",
      "\n",
      "Model: llama-3.2-1b-xlam-run1@cust-FarcM8gwhL1XFDXQ57qGLL\n",
      "  Namespace: xlam-tutorial-ns\n",
      "  Base Model: meta/llama-3.2-1b-instruct\n",
      "  Created: 2025-06-20 04:20:22.162792\n",
      "  Fine-tuning Type: lora\n"
     ]
    }
   ],
   "source": [
    "# List models with filters\n",
    "models_page = nemo_client.models.list(\n",
    "    filter={\"namespace\": NMS_NAMESPACE},\n",
    "    sort=\"-created_at\"\n",
    ")\n",
    "\n",
    "# Print models information\n",
    "print(f\"Found {len(models_page.data)} models in namespace {NMS_NAMESPACE}:\")\n",
    "for model in models_page.data:\n",
    "    print(f\"\\nModel: {model.name}\")\n",
    "    print(f\"  Namespace: {model.namespace}\")\n",
    "    print(f\"  Base Model: {model.base_model}\")\n",
    "    print(f\"  Created: {model.created_at}\")\n",
    "    if model.peft:\n",
    "        print(f\"  Fine-tuning Type: {model.peft.finetuning_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d58618189fba2a5",
   "metadata": {},
   "source": [
    " The customized model can also be retrieved directly by using its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73d1badf-2204-4f36-9c43-915a6992389c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: xlam-tutorial-ns/llama-3.2-1b-xlam-run1@cust-FarcM8gwhL1XFDXQ57qGLL\n",
      "Base Model: meta/llama-3.2-1b-instruct\n",
      "Status: upload_completed\n"
     ]
    }
   ],
   "source": [
    "# CUSTOMIZED_MODEL is constructed as `namespace/model_name`, so we need to extract the model name\n",
    "model = nemo_client.models.retrieve(namespace=NMS_NAMESPACE, model_name=CUSTOMIZED_MODEL.split(\"/\")[1])\n",
    "\n",
    "print(f\"Model: {model.namespace}/{model.name}\")\n",
    "print(f\"Base Model: {model.base_model}\")\n",
    "print(f\"Status: {model.artifact.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b43d7dc-f442-41cb-a743-7fd5efd4bf6c",
   "metadata": {},
   "source": [
    "NVIDIA NIM directly picks up the LoRA adapters from NeMo Entity Store. You can also query the NIM endpoint to look for it, as shown in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43026f8a-3b98-4aa6-b4c6-7441862863fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the custom LoRA model is hosted by NVIDIA NIM\n",
    "models = nemo_client.inference.models.list()\n",
    "model_names = [model.id for model in models.data]\n",
    "\n",
    "assert CUSTOMIZED_MODEL in model_names, \\\n",
    "    f\"Model {CUSTOMIZED_MODEL} not found\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df0f9c5-98b2-476e-aa2f-3af69c5e45f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"step-3\"></a>\n",
    "## Step 3: Sanity Test the Customized Model By Running Sample Inference\n",
    "\n",
    "Once the model is customized, its adapter is automatically saved in NeMo Entity Store and is ready to be picked up by NVIDIA NIM.\n",
    "You can test the model by sending a prompt to its NIM endpoint.\n",
    "\n",
    "First, choose one of the examples from the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf4ada2-2ccb-4f82-bb7c-23134e67a7e0",
   "metadata": {},
   "source": [
    "### 3.1 Get Test Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3f7da82-cbbb-43a4-999b-2adad2cea227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 713 examples in the test set\n"
     ]
    }
   ],
   "source": [
    "def read_jsonl(file_path):\n",
    "    \"\"\"Reads a JSON Lines file and yields parsed JSON objects\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove leading/trailing whitespace\n",
    "            if not line:\n",
    "                continue  # Skip empty lines\n",
    "            try:\n",
    "                yield json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "test_data = list(read_jsonl(test_fp))\n",
    "\n",
    "print(f\"There are {len(test_data)} examples in the test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92f74f62-8427-438e-b1df-15fe53ce330c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'role': 'user',\n",
       "   'content': \"Calculate the integral of the function 'x^2 + 3x + 2' from 0 to 10 using the trapezoidal rule.\"}],\n",
       " [{'type': 'function',\n",
       "   'function': {'name': 'merge_sorted_lists',\n",
       "    'description': 'Merges two sorted lists into a single sorted list.',\n",
       "    'parameters': {'type': 'object',\n",
       "     'properties': {'list1': {'description': 'The first sorted list.',\n",
       "       'type': 'array'},\n",
       "      'list2': {'description': 'The second sorted list.', 'type': 'array'}}}}},\n",
       "  {'type': 'function',\n",
       "   'function': {'name': 'is_power_of_two',\n",
       "    'description': 'Checks if a number is a power of two.',\n",
       "    'parameters': {'type': 'object',\n",
       "     'properties': {'num': {'description': 'The number to check.',\n",
       "       'type': 'integer'}}}}},\n",
       "  {'type': 'function',\n",
       "   'function': {'name': 'trapezoidal_integration',\n",
       "    'description': 'Calculates the definite integral of a function using the trapezoidal rule.',\n",
       "    'parameters': {'type': 'object',\n",
       "     'properties': {'func': {'description': 'The function to integrate, expressed as a string (e.g., \"x**2 + 2*x\").',\n",
       "       'type': 'string',\n",
       "       'default': 10000},\n",
       "      'a': {'description': 'The lower limit of integration.',\n",
       "       'type': 'number',\n",
       "       'default': 10000},\n",
       "      'b': {'description': 'The upper limit of integration.',\n",
       "       'type': 'number'},\n",
       "      'n': {'description': 'The number of subdivisions for the trapezoidal approximation. Defaults to 10000.',\n",
       "       'type': 'integer'}}}}}])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly choose\n",
    "test_sample = random.choice(test_data)\n",
    "\n",
    "# Visualize the inputs to the LLM - user query and available tools\n",
    "test_sample['messages'], test_sample['tools']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8577c4b-e0f6-4596-9bbc-33c47ca424aa",
   "metadata": {},
   "source": [
    "### 3.2 Send an Inference Call to NIM\n",
    "\n",
    "NIM exposes an OpenAI-compatible completions API endpoint, which you can query using the `OpenAI` client library as shown in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af83f794-f8cc-4cc8-8d42-a031dfb7f9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionMessageToolCall(id='chatcmpl-tool-1c74f457beee40398662f22c6aaede86', function=Function(arguments='{\"a\": 56, \"b\": 98}', name='greatest_common_divisor'), type='function')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_client = OpenAI(\n",
    "  base_url = f\"{NIM_URL}/v1\",\n",
    "  api_key = \"None\"\n",
    ")\n",
    "\n",
    "completion = inference_client.chat.completions.create(\n",
    "  model = CUSTOMIZED_MODEL,\n",
    "  messages = test_sample[\"messages\"],\n",
    "  tools = test_sample[\"tools\"],\n",
    "  tool_choice = 'auto',\n",
    "  temperature = 0.1,\n",
    "  top_p = 0.7,\n",
    "  max_tokens = 512,\n",
    "  stream = False\n",
    ")\n",
    "\n",
    "completion.choices[0].message.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25011860e8afaaa8",
   "metadata": {},
   "source": [
    "The Python SDK also supports the same inference call, as shown in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6aeaf7dc-87bd-4b61-963c-f8cc400f2737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChoiceMessageToolCall(id='chatcmpl-tool-c616cace9d8e4693a7aa514ef4c6a31a', function=Function(arguments='{\"a\": 56, \"b\": 98}', name='greatest_common_divisor'), type='function')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = nemo_client.chat.completions.create(\n",
    "  model = CUSTOMIZED_MODEL,\n",
    "  messages = test_sample[\"messages\"],\n",
    "  tools = test_sample[\"tools\"],\n",
    "  tool_choice = 'auto',\n",
    "  temperature = 0.1,\n",
    "  top_p = 0.7,\n",
    "  max_tokens = 512,\n",
    "  stream = False\n",
    ")\n",
    "\n",
    "completion.choices[0].message.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459bb488-3bd9-4092-9c3a-f77f904606e4",
   "metadata": {},
   "source": [
    "Given that the fine-tuning job was successful, you can get an inference result comparable to the ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcbdaedf-6fb4-41d6-8297-b7480c907892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'trapezoidal_integration',\n",
       "   'arguments': {'func': 'x**2 + 3*x + 2', 'a': 0, 'b': 10}}}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The ground truth answer\n",
    "test_sample['tool_calls']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ed066-cb0d-4abe-812a-fe87d075cf7c",
   "metadata": {},
   "source": [
    "**Note:** In production environments, application developers typically provide their own set of tools relevant to the specific task. The model must select from these tools based on the given query. To explore this further, you can sample a data point from the dataset to see which tools are available, then experiment by constructing a query and observing the model’s response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f0fce4-3169-4ac4-8785-8a8f15959594",
   "metadata": {},
   "source": [
    "### 3.3 Take Note of Your Custom Model Name\n",
    "\n",
    "Take note of your custom model name, as you will use it to run evaluations in the subsequent notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36398168-1051-4e54-ac3e-7a3e406f393a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of your custom model is: xlam-tutorial-ns/llama-3.2-1b-xlam-run1@cust-FarcM8gwhL1XFDXQ57qGLL\n"
     ]
    }
   ],
   "source": [
    "print(f\"Name of your custom model is: {CUSTOMIZED_MODEL}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
