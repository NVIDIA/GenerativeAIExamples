{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d4d1645",
   "metadata": {},
   "source": [
    "# Part II: Supervised Fine-tuning Using NeMo Customizer\n",
    "\n",
    "This notebook covers the following:\n",
    "\n",
    "0. [Prerequisites: Configurations, Health Checks, and Namespaces](#step-0)\n",
    "1. [Upload Data to NeMo Datastore](#step-1)\n",
    "2. [SFT Customization with NeMo Customizer](#step-2)\n",
    "3. [Model Deployment with Deployment Management Service](#step-3)\n",
    "4. [Running Inference on the Customized Model with NVIDIA NIM](#step-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99b27c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from time import sleep, time\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "from huggingface_hub import HfApi\n",
    "from openai import OpenAI\n",
    "\n",
    "from nemo_microservices import NeMoMicroservices, APIStatusError\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7fa32c",
   "metadata": {},
   "source": [
    "<a id=\"step-0\"></a>\n",
    "## Prerequisites: Configurations, Health Checks, and Namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5209bd",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "Before you proceed, make sure you completed the **[1_data_preparation.ipynb](./1_data_preparation.ipynb)** notebook to:\n",
    "- Download and format the SPECTER dataset\n",
    "- Create training and validation splits\n",
    "- Generate the required data files (`training.jsonl` and `validation.jsonl`)\n",
    "\n",
    "This notebook will upload that prepared data, fine-tune an embedding model, deploy it as a NIM, and run inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833396b2",
   "metadata": {},
   "source": [
    "### Configure NeMo Microservices Endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388844e3",
   "metadata": {},
   "source": [
    "Import the configurations from `config.py` and initialize the NeMo Microservices SDK client to interact with the platform services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e944c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize NeMo Microservices SDK client\n",
    "nemo_client = NeMoMicroservices(\n",
    "    base_url=NEMO_URL,\n",
    "    inference_base_url=NIM_URL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cdc79c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Store endpoint: http://data-store.test\n",
      "Entity Store, Customizer, Evaluator endpoint: http://nemo.test\n",
      "NIM endpoint: http://nim.test\n",
      "Namespace: embed-sft-ns\n",
      "Base Model for Customization: nvidia/llama-3.2-nv-embedqa-1b@v2\n",
      "Retriever NIM Image: nvcr.io/nim/nvidia/llama-3.2-nv-embedqa-1b-v2:1.6.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data Store endpoint: {NDS_URL}\")\n",
    "print(f\"Entity Store, Customizer, Evaluator endpoint: {NEMO_URL}\")\n",
    "print(f\"NIM endpoint: {NIM_URL}\")\n",
    "print(f\"Namespace: {NMS_NAMESPACE}\")\n",
    "print(f\"Base Model for Customization: {BASE_MODEL}@{BASE_MODEL_VERSION}\")\n",
    "print(f\"Retriever NIM Image: {BASE_MODEL_IMAGE_NAME_EMBEDDING}:{BASE_MODEL_IMAGE_TAG_EMBEDDING}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c474ff21",
   "metadata": {},
   "source": [
    "### Configure Path to Prepared Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c6edad",
   "metadata": {},
   "source": [
    "The following code sets the file paths to the prepared dataset files. We use `train_fp` and `val_fp` as shorthand for \"training file path\" and \"validation file path\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f26e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where data preparation notebook saved finetuning and evaluation data\n",
    "DATA_ROOT = os.path.join(os.getcwd(), \"data/specter_10pct\")\n",
    "CUSTOMIZATION_DATA_ROOT = os.path.join(DATA_ROOT, \"training\")\n",
    "VALIDATION_DATA_ROOT = os.path.join(DATA_ROOT, \"validation\")\n",
    "\n",
    "# Sanity checks\n",
    "train_fp = f\"{CUSTOMIZATION_DATA_ROOT}/training.jsonl\"\n",
    "assert os.path.exists(train_fp), f\"The training data at '{train_fp}' does not exist. Please ensure that the data was prepared successfully.\"\n",
    "\n",
    "val_fp = f\"{VALIDATION_DATA_ROOT}/validation.jsonl\"\n",
    "assert os.path.exists(val_fp), f\"The validation data at '{val_fp}' does not exist. Please ensure that the data was prepared successfully.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa58ea2",
   "metadata": {},
   "source": [
    "### Resource Organization Using Namespaces\n",
    "\n",
    "**Why Namespaces Matter:** When working with NeMo Microservices, you'll create datasets, models, and deployments. Without namespaces, all resources would mix together, making it hard to organize experiments or separate projects.\n",
    "\n",
    "**What are Namespaces?** A [namespace](https://docs.nvidia.com/nemo/microservices/latest/manage-entities/namespaces/index.html) is a logical container that isolates your resources. Think of it like a project folder that keeps your datasets, models, and deployments organized and separate from others.\n",
    "\n",
    "**Entity Store vs Data Store:** NeMo Microservices uses two storage systems:\n",
    "- **Entity Store**: Registry for models, configurations, and metadata\n",
    "- **Data Store**: Storage for training and evaluation datasets\n",
    "\n",
    "Both use namespaces to organize resources. You'll create a namespace in both stores for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeb6461",
   "metadata": {},
   "source": [
    "#### Create Namespace\n",
    "\n",
    "Both Data Store and Entity Store use namespaces. The following code creates namespaces for the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "abca8b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created namespace in Entity Store: embed-sft-ns\n",
      "Data Store namespace creation response: <Response [201]>\n"
     ]
    }
   ],
   "source": [
    "def create_namespaces(nemo_client, ds_host, namespace):\n",
    "    # Create namespace in Entity Store\n",
    "    try:\n",
    "        namespace_obj = nemo_client.namespaces.create(id=namespace)\n",
    "        print(f\"Created namespace in Entity Store: {namespace_obj.id}\")\n",
    "    except Exception as e:\n",
    "        # Handle if namespace already exists\n",
    "        if \"409\" in str(e) or \"422\" in str(e):\n",
    "            print(f\"Namespace {namespace} already exists in Entity Store\")\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # Create namespace in Data Store (still using requests as SDK doesn't cover Data Store)\n",
    "    nds_url = f\"{ds_host}/v1/datastore/namespaces\"\n",
    "    resp = requests.post(nds_url, data={\"namespace\": namespace})\n",
    "    assert resp.status_code in (200, 201, 409, 422), \\\n",
    "        f\"Unexpected response from Data Store during namespace creation: {resp.status_code}\"\n",
    "    print(f\"Data Store namespace creation response: {resp}\")\n",
    "\n",
    "create_namespaces(nemo_client=nemo_client, ds_host=NDS_URL, namespace=NMS_NAMESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d87a8dd",
   "metadata": {},
   "source": [
    "#### Verify Namespaces\n",
    "\n",
    "The following [Data Store API](https://docs.nvidia.com/nemo/microservices/latest/api/datastore.html) and [Entity Store API](https://docs.nvidia.com/nemo/microservices/latest/api/entity-store.html) list the namespace created in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ab35e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Store - Status Code: 201\n",
      "Response JSON: {'namespace': 'embed-sft-ns', 'created_at': '2025-11-03T16:43:04Z', 'updated_at': '2025-11-03T21:47:38Z'}\n",
      "\n",
      "Entity Store - Namespace: embed-sft-ns\n",
      "Created at: 2025-11-03 16:43:04.282771\n",
      "Description: None\n",
      "Project: None\n"
     ]
    }
   ],
   "source": [
    "# Verify Namespace in Data Store (using requests as SDK doesn't cover Data Store)\n",
    "response = requests.get(f\"{NDS_URL}/v1/datastore/namespaces/{NMS_NAMESPACE}\")\n",
    "print(f\"Data Store - Status Code: {response.status_code}\\nResponse JSON: {response.json()}\")\n",
    "\n",
    "# Verify Namespace in Entity Store\n",
    "namespace_obj = nemo_client.namespaces.retrieve(namespace_id=NMS_NAMESPACE)\n",
    "print(f\"\\nEntity Store - Namespace: {namespace_obj.id}\")\n",
    "print(f\"Created at: {namespace_obj.created_at}\")\n",
    "print(f\"Description: {namespace_obj.description}\")\n",
    "print(f\"Project: {namespace_obj.project}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e47d752-a0c3-4d42-a7a5-aae3ab1483de",
   "metadata": {},
   "source": [
    "> **Tip**: To delete a namespace, you can use the following code -\n",
    "\n",
    "```python\n",
    "nemo_client.namespaces.delete(\n",
    "    namespace_id=NMS_NAMESPACE, \n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642b82f5",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"step-1\"></a>\n",
    "## Step 1: Upload Data to NeMo Data Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bef2c33",
   "metadata": {},
   "source": [
    "The NeMo Data Store supports data management using the Hugging Face `HfApi` Client. \n",
    "\n",
    "**Note that this step does not interact with Hugging Face at all, it just uses the client library to interact with NeMo Data Store.** This is in comparison to the previous notebook, where we used the `load_dataset` API to download the dataset from Hugging Face's repository.\n",
    "\n",
    "More information can be found in [documentation](https://docs.nvidia.com/nemo/microservices/latest/manage-entities/tutorials/manage-dataset-files.html#set-up-hugging-face-client-with-nemo-data-store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69acea26",
   "metadata": {},
   "source": [
    "### 1.1 Create Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cace07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = f\"{NMS_NAMESPACE}/{DATASET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a6705b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Created repository: embed-sft-ns/embed-sft-data\n"
     ]
    }
   ],
   "source": [
    "hf_api = HfApi(endpoint=f\"{NDS_URL}/v1/hf\", token=None)\n",
    "\n",
    "\n",
    "# Create repo\n",
    "hf_api.create_repo(\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")\n",
    "\n",
    "print(f\"\u2705 Created repository: {repo_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd8a073",
   "metadata": {},
   "source": [
    "`Tip:` To delete a repo, you may use the following method\n",
    "\n",
    "```python\n",
    "hf_api.delete_repo(\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f09116",
   "metadata": {},
   "source": [
    "The `CommitInfo` output above confirms the files were successfully uploaded to the NeMo Data Store. The `oid` (object ID) is a hash identifying this specific upload, and the `commit_message` describes what was uploaded.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff2bd86",
   "metadata": {},
   "source": [
    "### 1.2 Upload Dataset Files to NeMo Data Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25655162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training.jsonl: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 15.8M/15.8M [00:00<00:00, 231MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "validation.jsonl: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 882k/882k [00:00<00:00, 79.2MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='', commit_message='Upload validation/validation.jsonl with huggingface_hub', commit_description='', oid='0fb9cfe46f41ac80b6884c99142e0b280b720cf8', pr_url=None, repo_url=RepoUrl('', endpoint='https://huggingface.co', repo_type='model', repo_id=''), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_api.upload_file(\n",
    "    path_or_fileobj=train_fp,\n",
    "    path_in_repo=\"training/training.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")\n",
    "\n",
    "hf_api.upload_file(\n",
    "    path_or_fileobj=val_fp,\n",
    "    path_in_repo=\"validation/validation.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcedd8b",
   "metadata": {},
   "source": [
    "### 1.3 Register the Dataset with NeMo Entity Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45771ad",
   "metadata": {},
   "source": [
    "To use a dataset for operations such as evaluations and customizations, register a dataset using the `nemo_client.datasets.create()` method.\n",
    "Register the dataset to refer to it by its namespace and name afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db62956c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset: embed-sft-ns/embed-sft-data\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "dataset = nemo_client.datasets.create(\n",
    "    name=DATASET_NAME,\n",
    "    namespace=NMS_NAMESPACE,\n",
    "    description=\"Embedding SFT Dataset\",\n",
    "    files_url=f\"hf://datasets/{NMS_NAMESPACE}/{DATASET_NAME}\",\n",
    "    project=\"embedding_sft\",\n",
    ")\n",
    "print(f\"Created dataset: {dataset.namespace}/{dataset.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465de09",
   "metadata": {},
   "source": [
    "`Tip:` If you'd like to delete a dataset, you may use the following -\n",
    "\n",
    "```python\n",
    "# Delete dataset\n",
    "dataset = nemo_client.datasets.delete(\n",
    "    namespace=NMS_NAMESPACE,\n",
    "    dataset_name=DATASET_NAME,\n",
    ")\n",
    "print(f\"Deletion status: {dataset.message}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d48ef5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files URL: hf://datasets/embed-sft-ns/embed-sft-data\n"
     ]
    }
   ],
   "source": [
    "# Sanity check to validate dataset\n",
    "dataset_obj = nemo_client.datasets.retrieve(namespace=NMS_NAMESPACE, dataset_name=DATASET_NAME)\n",
    "\n",
    "print(\"Files URL:\", dataset_obj.files_url)\n",
    "assert dataset_obj.files_url == f\"hf://datasets/{repo_id}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42733208",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"step-2\"></a>\n",
    "## 2. Embedding Model SFT with NeMo Customizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8361225d",
   "metadata": {},
   "source": [
    "### 2.1 Create a Customization Configuration\n",
    "\n",
    "A customization configuration defines the model, hardware, and training settings for fine-tuning jobs.\n",
    "\n",
    "**Off-the-Shelf vs Custom Configurations:**\n",
    "- **Off-the-shelf configs** (e.g., `llama-3.2-1b-embed@v1.0.0+A100`) are pre-built and ready to use. To use one, you would reference it by name instead of creating a new config.\n",
    "- **Custom configs** let you specify your own training parameters, hardware requirements, and model settings.\n",
    "\n",
    "**The `target` Parameter:** Specifies the base model checkpoint to fine-tune. We're using [llama-3_2-nv-embedqa-1b-v2](https://build.nvidia.com/nvidia/llama-3_2-nv-embedqa-1b-v2), a multilingual embedding model trained for text question-answering retrieval tasks.\n",
    "\n",
    "The following code creates a custom configuration named `llama-embed-sft-config@v1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63c2750a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created config: llama-embed-sft-config@v1\n"
     ]
    }
   ],
   "source": [
    "SFT_CONFIG_NAME = \"llama-embed-sft-config@v1\"\n",
    "\n",
    "try:\n",
    "    sft_config = nemo_client.customization.configs.create(\n",
    "        name=SFT_CONFIG_NAME,\n",
    "        namespace=NMS_NAMESPACE,\n",
    "        description=\"Configuration for Llama 3.2 1B Embedding on A100 GPUs\",\n",
    "        target=f\"{BASE_MODEL}@{BASE_MODEL_VERSION}\",\n",
    "        training_options=[\n",
    "            {\n",
    "                \"training_type\": \"sft\",\n",
    "                \"finetuning_type\": \"all_weights\",\n",
    "                \"num_gpus\": 1,\n",
    "                \"num_nodes\": 1,\n",
    "                \"micro_batch_size\": 8,\n",
    "                \"tensor_parallel_size\": 1,\n",
    "                \"pipeline_parallel_size\": 1,\n",
    "                \"use_sequence_parallel\": False\n",
    "            }\n",
    "        ],\n",
    "        training_precision=\"bf16\",\n",
    "        max_seq_length=2048\n",
    "    )\n",
    "    print(f\"Created config: {sft_config.name}\")\n",
    "except APIStatusError as e:\n",
    "    if e.status_code == 409:\n",
    "        print(f\"Config {SFT_CONFIG_NAME} already exists (409 Conflict)\")\n",
    "    else:\n",
    "        print(f\"API error {e.status_code}: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1bbbc8",
   "metadata": {},
   "source": [
    "### 2.2 Start the Training Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fb6b97",
   "metadata": {},
   "source": [
    "Start the training job by calling `nemo_client.customization.jobs.create()` method.\n",
    "The following code sets the training parameters and starts the job.\n",
    "\n",
    "> **The training job will take approximately 45 minutes to complete.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58ead098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created customization job: cust-MZopzmY1UjbPcM5oZAqTwc\n",
      "Status: created\n",
      "Job Details:  CustomizationJob(config='embed-sft-ns/llama-embed-sft-config@v1', dataset='embed-sft-ns/embed-sft-data', hyperparameters=Hyperparameters(finetuning_type='all_weights', adam_beta1=0.9, adam_beta2=0.99, batch_size=256, distillation=None, dpo=None, epochs=1, learning_rate=5e-06, log_every_n_steps=10, lora=None, max_steps=-1, min_learning_rate=None, optimizer='adamw_with_cosine_annealing', seed=42, sequence_packing_enabled=False, sft=None, training_type='sft', val_check_interval=None, warmup_steps=200, weight_decay=None), id='cust-MZopzmY1UjbPcM5oZAqTwc', config_snapshot=CustomizationConfigJobValue(base_model='nvidia/llama-3.2-nv-embedqa-1b-v2', max_seq_length=2048, precision='bf16', training_option=CustomizationTrainingOption(finetuning_type='all_weights', micro_batch_size=8, num_gpus=1, training_type='sft', data_parallel_size=1, expert_model_parallel_size=None, num_nodes=1, pipeline_parallel_size=1, tensor_parallel_size=1, use_sequence_parallel=False), dataset_schema=None, prompt_template='{prompt} {completion}'), created_at=datetime.datetime(2025, 11, 4, 23, 48, 29, 530088), custom_fields={}, dataset_parameters=None, description=None, integrations=None, namespace='default', output_model='embed-sft-ns/fullweight_sft_embedding@cust-MZopzmY1UjbPcM5oZAqTwc', ownership=None, project=None, status='created', status_details=CustomizationStatusDetails(created_at=datetime.datetime(2025, 11, 4, 23, 48, 30, 195806), status=None, updated_at=datetime.datetime(2025, 11, 4, 23, 48, 30, 195806), best_epoch=None, elapsed_time=0.0, epochs_completed=0, metrics=None, percentage_done=0.0, status_logs=[StatusLog(updated_at=datetime.datetime(2025, 11, 4, 23, 48, 30, 195806), detail=None, message='created')], steps_completed=0, steps_per_epoch=None, train_loss=None, val_loss=None), updated_at=datetime.datetime(2025, 11, 4, 23, 48, 29, 530090), warnings=None)\n"
     ]
    }
   ],
   "source": [
    "# If WANDB_API_KEY is set, we send it in the request header, which will report the training metrics to Weights & Biases (WandB).\n",
    "if WANDB_API_KEY:\n",
    "    client_with_wandb = nemo_client.with_options(default_headers={\"wandb-api-key\": WANDB_API_KEY})\n",
    "else:\n",
    "    client_with_wandb = nemo_client\n",
    "\n",
    "customization = client_with_wandb.customization.jobs.create(\n",
    "    name=\"llama-3.2-1b-embed-sft\",\n",
    "    config=f\"{NMS_NAMESPACE}/{sft_config.name}\",\n",
    "    dataset={\n",
    "        \"namespace\": NMS_NAMESPACE,\n",
    "        \"name\": DATASET_NAME, \n",
    "    },\n",
    "    hyperparameters={\n",
    "        \"training_type\": \"sft\",\n",
    "        \"finetuning_type\": \"all_weights\",\n",
    "        \"epochs\": 1,\n",
    "        \"batch_size\": 256,\n",
    "        \"learning_rate\": 0.000005,\n",
    "    },\n",
    "    output_model=f\"{NMS_NAMESPACE}/{OUTPUT_MODEL_NAME_EMBEDDING}\"\n",
    ")\n",
    "print(f\"Created customization job: {customization.id}\")\n",
    "print(f\"Status: {customization.status}\")\n",
    "print(\"Job Details: \", customization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2312ab5-b8f2-4bc5-b19b-9cd432080601",
   "metadata": {},
   "source": [
    "> **Tip**: If you specified a WANDB API KEY, you can observe the run under the project \"nvidia-nemo-customizer\" with its Run name as your customization job ID reported above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b693b9b",
   "metadata": {},
   "source": [
    "The following code sets variables for storing the customized model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef85adce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the Customized Model:  embed-sft-ns/fullweight_sft_embedding@cust-MZopzmY1UjbPcM5oZAqTwc\n"
     ]
    }
   ],
   "source": [
    "CUSTOMIZED_MODEL = customization.output_model\n",
    "\n",
    "# Once training is completed, this will be the name of the model that will be used to send inference queries\n",
    "print(\"Name of the Customized Model: \", CUSTOMIZED_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c283a",
   "metadata": {},
   "source": [
    "**Tips**:\n",
    "* If you configured the NeMo Customizer microservice with your own [Weights & Biases (WandB)](https://wandb.ai/) API key, you can find the training graphs and logs in your WandB account, \"nvidia-nemo-customizer\" project. Your run ID is similar to your job id : `customization.id`.\n",
    "  \n",
    "* To cancel a job that you scheduled incorrectly, run the following code.\n",
    "```python\n",
    "nemo_client.customization.jobs.cancel(job_id=customization.id)\n",
    "```\n",
    "\n",
    "* To delete a model for a job that was incorrectly scheduled, use the following code\n",
    "```python\n",
    "# CUSTOMIZED_MODEL.split('/')[1] extracts just the model name from `namespace/model_name` \n",
    "model = nemo_client.models.delete(namespace=NMS_NAMESPACE, model_name=CUSTOMIZED_MODEL.split('/')[1])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7437a1c8",
   "metadata": {},
   "source": [
    "### 2.2 Get Job Status\n",
    "\n",
    "Retrieve the job status by using the `nemo_client.customization.jobs.status()` method. The following code retrieves the current status and progress of the fine-tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6551d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage done: 0.0\n",
      "Job Status: {\n",
      "  \"created_at\": \"2025-11-04 23:48:30.195806\",\n",
      "  \"status\": \"pending\",\n",
      "  \"updated_at\": \"2025-11-04 23:48:30.195806\",\n",
      "  \"best_epoch\": null,\n",
      "  \"elapsed_time\": 0.0,\n",
      "  \"epochs_completed\": 0,\n",
      "  \"metrics\": null,\n",
      "  \"percentage_done\": 0.0,\n",
      "  \"status_logs\": [\n",
      "    {\n",
      "      \"updated_at\": \"2025-11-04 23:48:30.195806\",\n",
      "      \"detail\": null,\n",
      "      \"message\": \"created\"\n",
      "    },\n",
      "    {\n",
      "      \"updated_at\": \"2025-11-04 23:48:30.195806\",\n",
      "      \"detail\": \"The training job is pending\",\n",
      "      \"message\": \"TrainingJobPending\"\n",
      "    }\n",
      "  ],\n",
      "  \"steps_completed\": 0,\n",
      "  \"steps_per_epoch\": null,\n",
      "  \"train_loss\": null,\n",
      "  \"val_loss\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Get job status\n",
    "job_status = nemo_client.customization.jobs.status(job_id=customization.id)\n",
    "\n",
    "print(\"Percentage done:\", job_status.percentage_done)\n",
    "print(\"Job Status:\", json.dumps(job_status.model_dump(), indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f89d109",
   "metadata": {},
   "source": [
    "The following cell defines a method for polling until the job completes.\n",
    "\n",
    "**NOTE**: The progress bar is linked to the number of epochs completed. If training 1 epoch as an example (as the default above), it will go from 0% to 100% in a single jump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cf24916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: running after 5.17 seconds. Progress: 0.0%\n",
      "Job status: running after 10.27 seconds. Progress: 0.0%\n",
      "Job status: running after 15.42 seconds. Progress: 0.0%\n",
      "Job status: running after 20.51 seconds. Progress: 0.0%\n",
      "Job status: running after 25.55 seconds. Progress: 0.0%\n",
      "Job status: running after 30.58 seconds. Progress: 0.0%\n",
      "Job status: running after 35.62 seconds. Progress: 0.0%\n",
      "Job status: running after 40.72 seconds. Progress: 0.0%\n",
      "Job status: running after 45.84 seconds. Progress: 0.0%\n",
      "Job status: running after 50.87 seconds. Progress: 0.0%\n",
      "Job status: running after 55.93 seconds. Progress: 0.0%\n",
      "Job status: running after 61.00 seconds. Progress: 0.0%\n",
      "Job status: running after 66.08 seconds. Progress: 0.0%\n",
      "Job status: running after 71.27 seconds. Progress: 0.0%\n",
      "Job status: running after 76.33 seconds. Progress: 0.0%\n",
      "Job status: running after 81.45 seconds. Progress: 0.0%\n",
      "Job status: running after 86.53 seconds. Progress: 0.0%\n",
      "Job status: running after 91.66 seconds. Progress: 0.0%\n",
      "Job status: running after 96.70 seconds. Progress: 0.0%\n",
      "Job status: running after 101.77 seconds. Progress: 0.0%\n",
      "Job status: running after 106.88 seconds. Progress: 0.0%\n",
      "Job status: running after 111.96 seconds. Progress: 0.0%\n",
      "Job status: running after 116.99 seconds. Progress: 0.0%\n",
      "Job status: running after 122.07 seconds. Progress: 0.0%\n",
      "Job status: running after 127.29 seconds. Progress: 0.0%\n",
      "Job status: running after 132.42 seconds. Progress: 0.0%\n",
      "Job status: running after 137.51 seconds. Progress: 0.0%\n",
      "Job status: running after 142.65 seconds. Progress: 0.0%\n",
      "Job status: running after 147.71 seconds. Progress: 0.0%\n",
      "Job status: running after 152.86 seconds. Progress: 0.0%\n",
      "Job status: running after 157.92 seconds. Progress: 0.0%\n",
      "Job status: running after 163.03 seconds. Progress: 0.0%\n",
      "Job status: running after 168.24 seconds. Progress: 0.0%\n",
      "Job status: running after 173.32 seconds. Progress: 0.0%\n",
      "Job status: running after 178.44 seconds. Progress: 0.0%\n",
      "Job status: running after 183.54 seconds. Progress: 0.0%\n",
      "Job status: running after 188.56 seconds. Progress: 0.0%\n",
      "Job status: running after 193.61 seconds. Progress: 0.0%\n",
      "Job status: running after 198.73 seconds. Progress: 0.0%\n",
      "Job status: running after 203.76 seconds. Progress: 0.0%\n",
      "Job status: running after 208.94 seconds. Progress: 0.0%\n",
      "Job status: running after 214.08 seconds. Progress: 0.0%\n",
      "Job status: running after 219.15 seconds. Progress: 0.0%\n",
      "Job status: running after 224.29 seconds. Progress: 0.0%\n",
      "Job status: running after 229.37 seconds. Progress: 0.0%\n",
      "Job status: running after 234.53 seconds. Progress: 0.0%\n",
      "Job status: running after 239.63 seconds. Progress: 0.0%\n",
      "Job status: running after 244.69 seconds. Progress: 0.0%\n",
      "Job status: running after 249.72 seconds. Progress: 0.0%\n",
      "Job status: running after 254.80 seconds. Progress: 0.0%\n",
      "Job status: running after 259.86 seconds. Progress: 0.0%\n",
      "Job status: running after 264.95 seconds. Progress: 0.0%\n",
      "Job status: running after 270.15 seconds. Progress: 0.0%\n",
      "Job status: running after 275.18 seconds. Progress: 0.0%\n",
      "Job status: running after 280.26 seconds. Progress: 0.0%\n",
      "Job status: running after 285.30 seconds. Progress: 0.0%\n",
      "Job status: running after 290.33 seconds. Progress: 0.0%\n",
      "Job status: running after 295.41 seconds. Progress: 0.0%\n",
      "Job status: running after 300.48 seconds. Progress: 0.0%\n",
      "Job status: running after 305.52 seconds. Progress: 0.0%\n",
      "Job status: running after 310.68 seconds. Progress: 0.0%\n",
      "Job status: running after 315.82 seconds. Progress: 0.0%\n",
      "Job status: running after 320.86 seconds. Progress: 0.0%\n",
      "Job status: running after 325.94 seconds. Progress: 0.0%\n",
      "Job status: running after 331.13 seconds. Progress: 0.0%\n",
      "Job status: running after 336.23 seconds. Progress: 0.0%\n",
      "Job status: running after 341.28 seconds. Progress: 0.0%\n",
      "Job status: running after 346.43 seconds. Progress: 0.0%\n",
      "Job status: running after 351.58 seconds. Progress: 0.0%\n",
      "Job status: running after 356.65 seconds. Progress: 0.0%\n",
      "Job status: running after 361.69 seconds. Progress: 0.0%\n",
      "Job status: running after 366.73 seconds. Progress: 0.0%\n",
      "Job status: running after 371.85 seconds. Progress: 0.0%\n",
      "Job status: running after 377.00 seconds. Progress: 0.0%\n",
      "Job status: running after 382.12 seconds. Progress: 0.0%\n",
      "Job status: running after 387.15 seconds. Progress: 0.0%\n",
      "Job status: running after 392.23 seconds. Progress: 0.0%\n",
      "Job status: running after 397.36 seconds. Progress: 0.0%\n",
      "Job status: running after 402.43 seconds. Progress: 0.0%\n",
      "Job status: running after 407.47 seconds. Progress: 0.0%\n",
      "Job status: running after 412.51 seconds. Progress: 0.0%\n",
      "Job status: running after 417.59 seconds. Progress: 0.0%\n",
      "Job status: running after 422.63 seconds. Progress: 0.0%\n",
      "Job status: running after 427.68 seconds. Progress: 0.0%\n",
      "Job status: running after 432.94 seconds. Progress: 0.0%\n",
      "Job status: running after 438.06 seconds. Progress: 0.0%\n",
      "Job status: running after 443.18 seconds. Progress: 0.0%\n",
      "Job status: running after 448.23 seconds. Progress: 0.0%\n",
      "Job status: running after 453.38 seconds. Progress: 0.0%\n",
      "Job status: running after 458.40 seconds. Progress: 0.0%\n",
      "Job status: running after 463.62 seconds. Progress: 0.0%\n",
      "Job status: running after 468.71 seconds. Progress: 0.0%\n",
      "Job status: running after 473.85 seconds. Progress: 0.0%\n",
      "Job status: running after 478.96 seconds. Progress: 0.0%\n",
      "Job status: running after 484.02 seconds. Progress: 0.0%\n",
      "Job status: running after 489.14 seconds. Progress: 41.49%\n",
      "Job status: running after 494.17 seconds. Progress: 41.49%\n",
      "Job status: running after 499.32 seconds. Progress: 41.49%\n",
      "Job status: running after 504.58 seconds. Progress: 41.49%\n",
      "Job status: running after 509.71 seconds. Progress: 41.49%\n",
      "Job status: running after 514.81 seconds. Progress: 41.49%\n",
      "Job status: running after 519.91 seconds. Progress: 41.49%\n",
      "Job status: running after 525.16 seconds. Progress: 41.49%\n",
      "Job status: running after 530.22 seconds. Progress: 41.49%\n",
      "Job status: running after 535.45 seconds. Progress: 41.49%\n",
      "Job status: running after 540.57 seconds. Progress: 41.49%\n",
      "Job status: running after 545.72 seconds. Progress: 41.49%\n",
      "Job status: running after 550.86 seconds. Progress: 41.49%\n",
      "Job status: running after 555.96 seconds. Progress: 41.49%\n",
      "Job status: running after 561.05 seconds. Progress: 41.49%\n",
      "Job status: running after 566.13 seconds. Progress: 41.49%\n",
      "Job status: running after 571.22 seconds. Progress: 41.49%\n",
      "Job status: running after 576.34 seconds. Progress: 41.49%\n",
      "Job status: running after 581.45 seconds. Progress: 41.49%\n",
      "Job status: running after 586.60 seconds. Progress: 41.49%\n",
      "Job status: running after 591.66 seconds. Progress: 41.49%\n",
      "Job status: running after 596.72 seconds. Progress: 41.49%\n",
      "Job status: running after 601.77 seconds. Progress: 41.49%\n",
      "Job status: running after 606.89 seconds. Progress: 41.49%\n",
      "Job status: running after 612.05 seconds. Progress: 41.49%\n",
      "Job status: running after 617.13 seconds. Progress: 41.49%\n",
      "Job status: running after 622.23 seconds. Progress: 41.49%\n",
      "Job status: running after 627.35 seconds. Progress: 41.49%\n",
      "Job status: running after 632.42 seconds. Progress: 41.49%\n",
      "Job status: running after 637.50 seconds. Progress: 41.49%\n",
      "Job status: running after 642.54 seconds. Progress: 41.49%\n",
      "Job status: running after 647.59 seconds. Progress: 41.49%\n",
      "Job status: running after 652.72 seconds. Progress: 41.49%\n",
      "Job status: running after 657.84 seconds. Progress: 41.49%\n",
      "Job status: running after 662.94 seconds. Progress: 41.49%\n",
      "Job status: running after 668.08 seconds. Progress: 41.49%\n",
      "Job status: running after 673.22 seconds. Progress: 41.49%\n",
      "Job status: running after 678.33 seconds. Progress: 41.49%\n",
      "Job status: running after 683.37 seconds. Progress: 41.49%\n",
      "Job status: running after 688.55 seconds. Progress: 41.49%\n",
      "Job status: running after 693.66 seconds. Progress: 41.49%\n",
      "Job status: running after 698.91 seconds. Progress: 41.49%\n",
      "Job status: running after 703.96 seconds. Progress: 41.49%\n",
      "Job status: running after 709.04 seconds. Progress: 41.49%\n",
      "Job status: running after 714.17 seconds. Progress: 41.49%\n",
      "Job status: running after 719.30 seconds. Progress: 41.49%\n",
      "Job status: running after 724.41 seconds. Progress: 41.49%\n",
      "Job status: running after 729.47 seconds. Progress: 41.49%\n",
      "Job status: running after 734.59 seconds. Progress: 41.49%\n",
      "Job status: running after 739.70 seconds. Progress: 41.49%\n",
      "Job status: running after 744.74 seconds. Progress: 41.49%\n",
      "Job status: running after 749.81 seconds. Progress: 41.49%\n",
      "Job status: running after 754.86 seconds. Progress: 41.49%\n",
      "Job status: running after 759.91 seconds. Progress: 41.49%\n",
      "Job status: running after 764.95 seconds. Progress: 41.49%\n",
      "Job status: running after 770.07 seconds. Progress: 82.99%\n",
      "Job status: running after 775.33 seconds. Progress: 82.99%\n",
      "Job status: running after 780.37 seconds. Progress: 82.99%\n",
      "Job status: running after 785.42 seconds. Progress: 82.99%\n",
      "Job status: running after 790.48 seconds. Progress: 82.99%\n",
      "Job status: running after 795.70 seconds. Progress: 82.99%\n",
      "Job status: running after 800.83 seconds. Progress: 82.99%\n",
      "Job status: running after 806.06 seconds. Progress: 82.99%\n",
      "Job status: running after 811.15 seconds. Progress: 82.99%\n",
      "Job status: running after 816.19 seconds. Progress: 82.99%\n",
      "Job status: running after 821.28 seconds. Progress: 82.99%\n",
      "Job status: running after 826.42 seconds. Progress: 82.99%\n",
      "Job status: running after 831.54 seconds. Progress: 82.99%\n",
      "Job status: running after 836.64 seconds. Progress: 82.99%\n",
      "Job status: running after 841.77 seconds. Progress: 82.99%\n",
      "Job status: running after 846.84 seconds. Progress: 82.99%\n",
      "Job status: running after 851.87 seconds. Progress: 82.99%\n",
      "Job status: running after 856.91 seconds. Progress: 82.99%\n",
      "Job status: running after 862.02 seconds. Progress: 82.99%\n",
      "Job status: running after 867.15 seconds. Progress: 82.99%\n",
      "Job status: running after 872.24 seconds. Progress: 82.99%\n",
      "Job status: running after 877.49 seconds. Progress: 82.99%\n",
      "Job status: running after 882.61 seconds. Progress: 82.99%\n",
      "Job status: running after 887.82 seconds. Progress: 82.99%\n",
      "Job status: running after 892.90 seconds. Progress: 99.17%\n",
      "Job status: running after 898.01 seconds. Progress: 99.17%\n",
      "Job status: running after 903.15 seconds. Progress: 99.17%\n",
      "Job status: running after 908.27 seconds. Progress: 99.17%\n",
      "Job status: running after 913.30 seconds. Progress: 99.17%\n",
      "Job status: running after 918.39 seconds. Progress: 99.17%\n",
      "Job status: running after 923.50 seconds. Progress: 99.17%\n",
      "Job status: running after 928.57 seconds. Progress: 99.17%\n",
      "Job status: running after 933.65 seconds. Progress: 99.59%\n",
      "Job status: running after 938.70 seconds. Progress: 99.59%\n",
      "Job status: running after 943.90 seconds. Progress: 99.59%\n",
      "Job status: running after 949.01 seconds. Progress: 100.0%\n",
      "Job status: running after 954.04 seconds. Progress: 100.0%\n",
      "Job status: running after 959.16 seconds. Progress: 100.0%\n",
      "Job status: running after 964.19 seconds. Progress: 100.0%\n",
      "Job status: running after 969.27 seconds. Progress: 100.0%\n",
      "Job status: running after 974.33 seconds. Progress: 100.0%\n",
      "Job status: running after 979.38 seconds. Progress: 100.0%\n",
      "Job status: running after 984.51 seconds. Progress: 100.0%\n",
      "Job status: running after 989.72 seconds. Progress: 100.0%\n",
      "Job status: running after 994.85 seconds. Progress: 100.0%\n",
      "Job status: running after 999.88 seconds. Progress: 100.0%\n",
      "Job status: running after 1004.97 seconds. Progress: 100.0%\n",
      "Job status: running after 1010.01 seconds. Progress: 100.0%\n",
      "Job status: running after 1015.05 seconds. Progress: 100.0%\n",
      "Job status: running after 1020.22 seconds. Progress: 100.0%\n",
      "Job status: running after 1025.31 seconds. Progress: 100.0%\n",
      "Job status: running after 1030.38 seconds. Progress: 100.0%\n",
      "Job status: running after 1035.60 seconds. Progress: 100.0%\n",
      "Job status: running after 1040.65 seconds. Progress: 100.0%\n",
      "Job status: running after 1045.68 seconds. Progress: 100.0%\n",
      "Job status: running after 1050.73 seconds. Progress: 100.0%\n",
      "Job status: running after 1055.77 seconds. Progress: 100.0%\n",
      "Job status: running after 1060.94 seconds. Progress: 100.0%\n",
      "Job status: running after 1066.18 seconds. Progress: 100.0%\n",
      "Job status: running after 1071.37 seconds. Progress: 100.0%\n",
      "Job status: running after 1076.41 seconds. Progress: 100.0%\n",
      "Job status: running after 1081.48 seconds. Progress: 100.0%\n",
      "Job status: running after 1086.73 seconds. Progress: 100.0%\n",
      "Job status: running after 1091.86 seconds. Progress: 100.0%\n",
      "Job status: running after 1096.90 seconds. Progress: 100.0%\n",
      "Job status: running after 1102.02 seconds. Progress: 100.0%\n",
      "Job status: running after 1107.24 seconds. Progress: 100.0%\n",
      "Job status: running after 1112.39 seconds. Progress: 100.0%\n",
      "Job status: running after 1117.57 seconds. Progress: 100.0%\n",
      "Job status: running after 1122.70 seconds. Progress: 100.0%\n",
      "Job status: running after 1127.95 seconds. Progress: 100.0%\n",
      "Job status: running after 1133.10 seconds. Progress: 100.0%\n",
      "Job status: running after 1138.19 seconds. Progress: 100.0%\n",
      "Job status: running after 1143.35 seconds. Progress: 100.0%\n",
      "Job status: completed after 1148.37 seconds. Progress: 100%\n",
      "\n",
      "\u2705 Customization job completed successfully!\n",
      "Fine-tuned model saved as: embed-sft-ns/fullweight_sft_embedding@cust-MZopzmY1UjbPcM5oZAqTwc\n"
     ]
    }
   ],
   "source": [
    "# Add wait for the customization job to complete\n",
    "\n",
    "\n",
    "def wait_job(nemo_client, job_id: str, polling_interval: int = 10, timeout: int = 6000):\n",
    "    \"\"\"Helper for waiting an eval job using SDK.\"\"\"\n",
    "    start_time = time()\n",
    "    job = nemo_client.customization.jobs.retrieve(job_id=job_id)\n",
    "    status = job.status\n",
    "\n",
    "    while status in [\"pending\", \"created\", \"running\"]:\n",
    "        # Check for timeout\n",
    "        if time() - start_time > timeout:\n",
    "            raise RuntimeError(f\"Took more than {timeout} seconds.\")\n",
    "\n",
    "        # Sleep before polling again\n",
    "        sleep(polling_interval)\n",
    "\n",
    "        # Fetch updated status and progress\n",
    "        job = nemo_client.customization.jobs.retrieve(job_id=job_id)\n",
    "        status = job.status\n",
    "        progress = 0.0\n",
    "        if status == \"running\" and job.status_details:\n",
    "            progress = job.status_details.percentage_done or 0.0\n",
    "        elif status == \"completed\":\n",
    "            progress = 100\n",
    "\n",
    "        print(f\"Job status: {status} after {time() - start_time:.2f} seconds. Progress: {progress}%\")\n",
    "\n",
    "    # Check final status after exiting loop\n",
    "    if status == \"failed\":\n",
    "        print(f\"Job failed after {time() - start_time:.2f} seconds.\")\n",
    "        raise RuntimeError(f\"Job {job_id} failed.\")\n",
    "\n",
    "    return job\n",
    "\n",
    "job = wait_job(nemo_client, customization.id, polling_interval=5, timeout=2400)\n",
    "\n",
    "# Only sleep if job completed successfully\n",
    "if job.status == \"completed\":\n",
    "    print(\"\\n\u2705 Customization job completed successfully!\")\n",
    "    print(f\"Fine-tuned model saved as: {CUSTOMIZED_MODEL}\")\n",
    "    # Wait for 1 minute, to ensure any artifacts are saved\n",
    "    sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b296ac76",
   "metadata": {},
   "source": [
    "### 2.3 Validate Availability of Custom Model\n",
    "The following NeMo Entity Store API should display the model when the training job is complete.\n",
    "The list below shows all models filtered by your namespace and sorted by the latest first.\n",
    "For more information about this API, see the [NeMo Entity Store API reference](https://docs.nvidia.com/nemo/microservices/latest/api/entity-store.html).\n",
    "With the following code, you can find all customized models, including the one trained in the previous cells.\n",
    "Look for the `name` fields in the output, which should match your `CUSTOMIZED_MODEL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4aa8eda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 models in namespace embed-sft-ns:\n",
      "\n",
      "Model: fullweight_sft_embedding@cust-MZopzmY1UjbPcM5oZAqTwc\n",
      "  Namespace: embed-sft-ns\n",
      "  Base Model: nvidia/llama-3.2-nv-embedqa-1b-v2\n",
      "  Created: 2025-11-04 23:48:30.276652\n",
      "  Fine-tuning Type: all_weights\n",
      "\n",
      "Model: fullweight_sft_embedding\n",
      "  Namespace: embed-sft-ns\n",
      "  Base Model: None\n",
      "  Created: 2025-11-04 23:48:19.586736\n"
     ]
    }
   ],
   "source": [
    "# List models with filters\n",
    "models_page = nemo_client.models.list(\n",
    "    filter={\"namespace\": NMS_NAMESPACE},\n",
    "    sort=\"-created_at\"\n",
    ")\n",
    "\n",
    "# Print models information\n",
    "print(f\"Found {len(models_page.data)} models in namespace {NMS_NAMESPACE}:\")\n",
    "for model in models_page.data:\n",
    "    print(f\"\\nModel: {model.name}\")\n",
    "    print(f\"  Namespace: {model.namespace}\")\n",
    "    print(f\"  Base Model: {model.base_model}\")\n",
    "    print(f\"  Created: {model.created_at}\")\n",
    "    if model.peft:\n",
    "        print(f\"  Fine-tuning Type: {model.peft.finetuning_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57c8d4f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"step-3\"></a>\n",
    "## Step 3: Deploy the Custom Model with NeMo Deployment Management Service (DMS)\n",
    "\n",
    "Once the model is supervised finetuned, it can be deployed as a service with NeMo DMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc00e16c",
   "metadata": {},
   "source": [
    "### 3.1 Create a Deployment Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68ff770",
   "metadata": {},
   "source": [
    "**Method of Deployment** To make your fine-tuned model available for inference we deploy that model as a NIM (NVIDIA Inference Microservice) that accepts embedding requests via API calls.\n",
    "\n",
    "**Deployment Management Service (DMS)** handles the deployment process. It retrieves the fine-tuned weights from the Entity Store and launches a NIM container configured for your model.\n",
    "\n",
    "The following cell creates a deployment configuration that specifies the NIM image, GPU requirements, and model settings. Deployment configurations can be reused across multiple model deployments.\n",
    "\n",
    "> **Note:** The Embedding NIM does not support LoRA adapters, so `disable_lora_support=True` must be set in the deployment configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "475731a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying embed-sft-ns/fullweight_sft_embedding@cust-MZopzmY1UjbPcM5oZAqTwc with DMS.\n",
      "Deployment config created: llama-embed-sft-deploy-config\n"
     ]
    }
   ],
   "source": [
    "print(f\"Deploying {CUSTOMIZED_MODEL} with DMS.\")\n",
    "\n",
    "deployment_config = nemo_client.deployment.configs.create(\n",
    "    name=\"llama-embed-sft-deploy-config\",\n",
    "    namespace=NMS_NAMESPACE,\n",
    "    model=CUSTOMIZED_MODEL,\n",
    "    nim_deployment={\n",
    "        \"image_name\": BASE_MODEL_IMAGE_NAME_EMBEDDING,\n",
    "        \"image_tag\": BASE_MODEL_IMAGE_TAG_EMBEDDING,\n",
    "        \"gpu\": 1,\n",
    "        \"disable_lora_support\": True,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"Deployment config created: {deployment_config.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0563b35f",
   "metadata": {},
   "source": [
    "### 3.2 Deploy the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ddd7b2",
   "metadata": {},
   "source": [
    "The following cell creates a Model Deployment for the SFT embedding model so we can send queries to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58358f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model deployment created: llama-embed-sft-deploy\n"
     ]
    }
   ],
   "source": [
    "DEPLOYMENT_NAME = \"llama-embed-sft-deploy\"\n",
    "\n",
    "deployment = nemo_client.deployment.model_deployments.create(\n",
    "    name=DEPLOYMENT_NAME,\n",
    "    namespace=NMS_NAMESPACE,\n",
    "    config=f\"{NMS_NAMESPACE}/{deployment_config.name}\"\n",
    ")\n",
    "\n",
    "print(f\"Model deployment created: {deployment.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c50abf",
   "metadata": {},
   "source": [
    "### 3.3 Check Status of Deployment\n",
    "\n",
    "> **It will take about 10 minutes the first time a model is deployed. This is because it pulls the container image the first time, and it typically much faster in subsequent deployments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d8cfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring deployment status for llama-embed-sft-deploy...\n",
      "Deployment: llama-embed-sft-deploy | Status: pending after 0.01 seconds"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment: llama-embed-sft-deploy | Status: ready after 70.17 secondsds\n",
      "\u2705 Deployment completed successfully!\n"
     ]
    }
   ],
   "source": [
    "def wait_deployment(nemo_client, deployment_id: str, namespace: str, polling_interval: int = 10, timeout: int = 6000):\n",
    "    \"\"\"Helper for waiting for a deployment to complete using SDK.\"\"\"\n",
    "    from time import time, sleep\n",
    "    \n",
    "    start_time = time()\n",
    "    print(f\"Monitoring deployment status for {deployment_id}...\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # Check for timeout\n",
    "            if time() - start_time > timeout:\n",
    "                raise RuntimeError(f\"Deployment took more than {timeout} seconds.\")\n",
    "            \n",
    "            # Get deployment status\n",
    "            deployment = nemo_client.deployment.model_deployments.retrieve(\n",
    "                deployment_name=deployment_id,\n",
    "                namespace=namespace\n",
    "            )\n",
    "            \n",
    "            status = deployment.status_details.status\n",
    "            \n",
    "            print(f\"\\rDeployment: {deployment_id} | Status: {status} after {time() - start_time:.2f} seconds\", end=\"\", flush=True)\n",
    "            \n",
    "            # Check if deployment is complete\n",
    "            if status == 'ready':\n",
    "                print(\"\\n\u2705 Deployment completed successfully!\")\n",
    "                break\n",
    "            elif status in ['failed', 'cancelled']:\n",
    "                print(f\"\\n\u274c Deployment {status}\")\n",
    "                raise RuntimeError(f\"Deployment {deployment_id} {status}.\")\n",
    "            \n",
    "            sleep(polling_interval)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nStopped by user\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            if \"timeout\" in str(e) or \"RuntimeError\" in str(type(e).__name__):\n",
    "                raise\n",
    "            print(f\"\\nError: {e}\")\n",
    "            sleep(30)\n",
    "    \n",
    "    return deployment\n",
    "\n",
    "\n",
    "# DEPLOYMENT_ID = \"llama-embed-sft-deploy\"\n",
    "deployment = wait_deployment(nemo_client, deployment.name, NMS_NAMESPACE, polling_interval=10, timeout=2400)\n",
    "# Sleep for 10 seconds before running inference to avoid race condition on model inference in next cell\n",
    "sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d0c8cc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"step-4\"></a>\n",
    "## Step 4: Run inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d4940b",
   "metadata": {},
   "source": [
    "### 4.1 Send a request using OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9157c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INFERENCE TEST: Single Query\n",
      "================================================================================\n",
      "\n",
      "\ud83d\udd0d Query: 'What is the population of Pittsburgh?'\n",
      "\ud83d\udccd Model: embed-sft-ns/fullweight_sft_embedding\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Embeddings inference successful!\n",
      "Model: embed-sft-ns/fullweight_sft_embedding\n",
      "Input type: query\n",
      "Embedding dimensions: 2048\n",
      "First 5 values: [0.023131361231207848, 0.018074970692396164, 0.028078202158212662, 0.008604136295616627, 0.029157375916838646]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_embeddings(input_text, model_name, input_type=\"query\"):\n",
    "    \"\"\"\n",
    "    Create embeddings using OpenAI client\n",
    "    \n",
    "    Args:\n",
    "        input_text (str or list): Text to embed\n",
    "        model_name (str): Model name to use\n",
    "        input_type (str): Either \"query\" or \"passage\"\n",
    "    \"\"\"\n",
    "    # Initialize OpenAI client with NIM endpoint\n",
    "    client = OpenAI(\n",
    "        base_url=f\"{NIM_URL}/v1\",\n",
    "        api_key=\"None\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        if isinstance(input_text, str):\n",
    "            input_text = [input_text]\n",
    "            \n",
    "        # Create embeddings\n",
    "        response = client.embeddings.create(\n",
    "            input=input_text,\n",
    "            model=model_name,\n",
    "            extra_body={\"input_type\": input_type}\n",
    "        )\n",
    "        \n",
    "        print(\"\u2705 Embeddings inference successful!\")\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Input type: {input_type}\")\n",
    "        print(f\"Embedding dimensions: {len(response.data[0].embedding)}\")\n",
    "        print(f\"First 5 values: {response.data[0].embedding[:5]}\")\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Embeddings inference failed: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Quick test\n",
    "print(\"=\" * 80)\n",
    "print(\"INFERENCE TEST: Single Query\")\n",
    "print(\"=\" * 80)\n",
    "test_query = \"What is the population of Pittsburgh?\"\n",
    "print(f\"\\n\ud83d\udd0d Query: '{test_query}'\")\n",
    "print(f\"\ud83d\udccd Model: {NMS_NAMESPACE}/{OUTPUT_MODEL_NAME_EMBEDDING}\")\n",
    "print(\"\\n\" + \"-\" * 80 + \"\\n\")\n",
    "\n",
    "_ = get_embeddings(\n",
    "    test_query, \n",
    "    f\"{NMS_NAMESPACE}/{OUTPUT_MODEL_NAME_EMBEDDING}\",\n",
    "    input_type=\"query\"\n",
    ")\n",
    "\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc131fc",
   "metadata": {},
   "source": [
    "### 4.2 Example similarity calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c50f11",
   "metadata": {},
   "source": [
    "For a sanity test, the following code calculates the cosine embedding similarity between a query, positive text, and a negative text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df70ada4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query paper:\n",
      "  The Neuroscience of Spontaneous Thought: An Evolving, Interdisciplinary Field\n",
      "\n",
      "Related paper (positive):\n",
      "  Hippocampal Replay Is Not a Simple Function of Experience\n",
      "\n",
      "Unrelated paper (negative):\n",
      "  An alternative to the dark matter paradigm: relativistic MOND gravitation\n",
      "\n",
      "\u2705 Embeddings inference successful!\n",
      "Model: embed-sft-ns/fullweight_sft_embedding\n",
      "Input type: query\n",
      "Embedding dimensions: 2048\n",
      "First 5 values: [0.010658088140189648, 0.01798108033835888, 0.018701737746596336, 0.02370860055088997, 0.007486638613045216]\n",
      "\n",
      "\u2705 Embeddings inference successful!\n",
      "Model: embed-sft-ns/fullweight_sft_embedding\n",
      "Input type: passage\n",
      "Embedding dimensions: 2048\n",
      "First 5 values: [0.0011829029535874724, 0.0027695184107869864, -0.001614622538909316, -0.0012941394234076142, -0.0011520263506099582]\n",
      "\n",
      "Cosine similarity results:\n",
      "  Query to related paper:   0.3064\n",
      "  Query to unrelated paper: 0.1877\n",
      "  Difference: 0.1187\n",
      "\n",
      "\u2705 The model correctly ranked the related paper higher.\n"
     ]
    }
   ],
   "source": [
    "test_data = {\n",
    "    \"query\": \"The Neuroscience of Spontaneous Thought: An Evolving, Interdisciplinary Field\", \n",
    "    \"pos_doc\": \"Hippocampal Replay Is Not a Simple Function of Experience\", \n",
    "    \"neg_doc\": [\"An alternative to the dark matter paradigm: relativistic MOND gravitation\"]\n",
    "}\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Calculate cosine similarity between two vectors\"\"\"\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    \n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "\n",
    "# Test similarity calculation with scientific papers\n",
    "print(\"Query paper:\")\n",
    "print(f\"  {test_data['query']}\")\n",
    "print(\"\\nRelated paper (positive):\")\n",
    "print(f\"  {test_data['pos_doc']}\")\n",
    "print(\"\\nUnrelated paper (negative):\")\n",
    "print(f\"  {test_data['neg_doc'][0]}\\n\")\n",
    "\n",
    "# Get query embedding\n",
    "query_response = get_embeddings(\n",
    "    test_data[\"query\"],\n",
    "    f\"{NMS_NAMESPACE}/{OUTPUT_MODEL_NAME_EMBEDDING}\",\n",
    "    input_type=\"query\"\n",
    ")\n",
    "print()\n",
    "# Get both positive and negative document embeddings in one request\n",
    "doc_response = get_embeddings(\n",
    "    [test_data[\"pos_doc\"], test_data[\"neg_doc\"][0]],\n",
    "    f\"{NMS_NAMESPACE}/{OUTPUT_MODEL_NAME_EMBEDDING}\",\n",
    "    input_type=\"passage\"\n",
    ")\n",
    "\n",
    "# Calculate cosine similarities\n",
    "if query_response and doc_response:\n",
    "    query_pos_similarity = cosine_similarity(query_response.data[0].embedding, doc_response.data[0].embedding)\n",
    "    query_neg_similarity = cosine_similarity(query_response.data[0].embedding, doc_response.data[1].embedding)\n",
    "    \n",
    "    print(\"\\nCosine similarity results:\")\n",
    "    print(f\"  Query to related paper:   {query_pos_similarity:.4f}\")\n",
    "    print(f\"  Query to unrelated paper: {query_neg_similarity:.4f}\")\n",
    "    print(f\"  Difference: {query_pos_similarity - query_neg_similarity:.4f}\")\n",
    "    \n",
    "    if query_pos_similarity > query_neg_similarity:\n",
    "        print(f\"\\n\u2705 The model correctly ranked the related paper higher.\")\n",
    "    else:\n",
    "        print(f\"\\nWarning: Unrelated paper has higher similarity.\")\n",
    "else:\n",
    "    print(\"Could not calculate similarities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde995c8",
   "metadata": {},
   "source": [
    "The query should be far closer (higher cosine similarity) to the positive doc than the negative doc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1823b99b",
   "metadata": {},
   "source": [
    "### 4.3 Take Note of Your Deployment Name\n",
    "Take note of your custom model deployment name, as you will use it to run evaluation in the subsequent notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2558ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of your deployment is: embed-sft-ns/fullweight_sft_embedding\n"
     ]
    }
   ],
   "source": [
    "print(f\"Name of your deployment is: {NMS_NAMESPACE}/{OUTPUT_MODEL_NAME_EMBEDDING}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390861e1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "\u2705 **Completed in this notebook:**\n",
    "- Uploaded training data to NeMo Data Store\n",
    "- Fine-tuned the `nvidia/llama-3.2-nv-embedqa-1b-v2` embedding model on scientific literature titles\n",
    "- Deployed the fine-tuned model as a NIM\n",
    "- Ran basic inference test with similarity calculations\n",
    "\n",
    "**Continue to [3_evaluation.ipynb](./3_evaluation.ipynb)** to:\n",
    "- Evaluate your fine-tuned model on the BEIR Scidocs benchmark\n",
    "- Compare performance metrics (recall, NDCG) against baseline\n",
    "- Quantify the improvement from fine-tuning on domain-specific data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}