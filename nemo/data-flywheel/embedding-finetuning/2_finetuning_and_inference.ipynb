{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d4d1645",
   "metadata": {},
   "source": [
    "# Part II: Supervised Fine-tuning Using NeMo Customizer\n",
    "\n",
    "This notebook covers the following:\n",
    "\n",
    "0. [Prerequisites: Configurations, Health Checks, and Namespaces](#step-0)\n",
    "1. [Upload Data to NeMo Datastore](#step-1)\n",
    "2. [SFT Customization with NeMo Customizer](#step-2)\n",
    "3. [Model Deployment with Deployment Management Service](#step-3)\n",
    "4. [Running Inference on the Customized Model with NVIDIA NIM](#step-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99b27c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from nemo_microservices import NeMoMicroservices, APIStatusError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7fa32c",
   "metadata": {},
   "source": [
    "<a id=\"step-0\"></a>\n",
    "## Prerequisites: Configurations, Health Checks, and Namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5209bd",
   "metadata": {},
   "source": [
    "Before you proceed, make sure that you completed the first notebook on data preparation to obtain the assets required to follow along."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833396b2",
   "metadata": {},
   "source": [
    "### Configure NeMo Microservices Endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388844e3",
   "metadata": {},
   "source": [
    "This section includes importing required configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e944c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "\n",
    "# Initialize NeMo Microservices SDK client\n",
    "nemo_client = NeMoMicroservices(\n",
    "    base_url=NEMO_URL,\n",
    "    inference_base_url=NIM_URL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cdc79c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Store endpoint: http://data-store.test\n",
      "Entity Store, Customizer, Evaluator endpoint: http://nemo.test\n",
      "NIM endpoint: http://nim.test\n",
      "Namespace: embed-sft-ns\n",
      "Base Model for Customization: nvidia/llama-3.2-nv-embedqa-1b@v2\n",
      "Retriever NIM Image: nvcr.io/nim/nvidia/llama-3.2-nv-embedqa-1b-v2:1.6.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data Store endpoint: {NDS_URL}\")\n",
    "print(f\"Entity Store, Customizer, Evaluator endpoint: {NEMO_URL}\")\n",
    "print(f\"NIM endpoint: {NIM_URL}\")\n",
    "print(f\"Namespace: {NMS_NAMESPACE}\")\n",
    "print(f\"Base Model for Customization: {BASE_MODEL}@{BASE_MODEL_VERSION}\")\n",
    "print(f\"Retriever NIM Image: {BASE_MODEL_IMAGE_NAME_EMBEDDING}:{BASE_MODEL_IMAGE_TAG_EMBEDDING}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c474ff21",
   "metadata": {},
   "source": [
    "### Configure Path to Prepared Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c6edad",
   "metadata": {},
   "source": [
    "The following code sets the paths to the prepared dataset files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f26e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where data preparation notebook saved finetuning and evaluation data\n",
    "DATA_ROOT = os.path.join(os.getcwd(), \"data/specter_10pct\")\n",
    "CUSTOMIZATION_DATA_ROOT = os.path.join(DATA_ROOT, \"training\")\n",
    "VALIDATION_DATA_ROOT = os.path.join(DATA_ROOT, \"validation\")\n",
    "\n",
    "# Sanity checks\n",
    "train_fp = f\"{CUSTOMIZATION_DATA_ROOT}/training.jsonl\"\n",
    "assert os.path.exists(train_fp), f\"The training data at '{train_fp}' does not exist. Please ensure that the data was prepared successfully.\"\n",
    "\n",
    "val_fp = f\"{VALIDATION_DATA_ROOT}/validation.jsonl\"\n",
    "assert os.path.exists(val_fp), f\"The validation data at '{val_fp}' does not exist. Please ensure that the data was prepared successfully.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa58ea2",
   "metadata": {},
   "source": [
    "### Resource Organization Using Namespace\n",
    "\n",
    "You can use a [namespace](https://docs.nvidia.com/nemo/microservices/latest/manage-entities/namespaces/index.html) to isolate and organize the artifacts in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeb6461",
   "metadata": {},
   "source": [
    "#### Create Namespace\n",
    "\n",
    "Both Data Store and Entity Store use namespaces. The following code creates namespaces for the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abca8b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created namespace in Entity Store: embed-sft-ns\n",
      "Data Store namespace creation response: <Response [201]>\n"
     ]
    }
   ],
   "source": [
    "def create_namespaces(nemo_client, ds_host, namespace):\n",
    "    # Create namespace in Entity Store\n",
    "    try:\n",
    "        namespace_obj = nemo_client.namespaces.create(id=namespace)\n",
    "        print(f\"Created namespace in Entity Store: {namespace_obj.id}\")\n",
    "    except Exception as e:\n",
    "        # Handle if namespace already exists\n",
    "        if \"409\" in str(e) or \"422\" in str(e):\n",
    "            print(f\"Namespace {namespace} already exists in Entity Store\")\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # Create namespace in Data Store (still using requests as SDK doesn't cover Data Store)\n",
    "    nds_url = f\"{ds_host}/v1/datastore/namespaces\"\n",
    "    resp = requests.post(nds_url, data={\"namespace\": namespace})\n",
    "    assert resp.status_code in (200, 201, 409, 422), \\\n",
    "        f\"Unexpected response from Data Store during namespace creation: {resp.status_code}\"\n",
    "    print(f\"Data Store namespace creation response: {resp}\")\n",
    "\n",
    "create_namespaces(nemo_client=nemo_client, ds_host=NDS_URL, namespace=NMS_NAMESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d87a8dd",
   "metadata": {},
   "source": [
    "#### Verify Namespaces\n",
    "\n",
    "The following [Data Store API](https://docs.nvidia.com/nemo/microservices/latest/api/datastore.html) and [Entity Store API](https://docs.nvidia.com/nemo/microservices/latest/api/entity-store.html) list the namespace created in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ab35e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Store - Status Code: 201\n",
      "Response JSON: {'namespace': 'embed-sft-ns', 'created_at': '2025-07-31T21:36:44Z', 'updated_at': '2025-07-31T21:36:44Z'}\n",
      "\n",
      "Entity Store - Namespace: embed-sft-ns\n",
      "Created at: 2025-07-31 21:36:44.165622\n",
      "Description: None\n",
      "Project: None\n"
     ]
    }
   ],
   "source": [
    "# Verify Namespace in Data Store (using requests as SDK doesn't cover Data Store)\n",
    "response = requests.get(f\"{NDS_URL}/v1/datastore/namespaces/{NMS_NAMESPACE}\")\n",
    "print(f\"Data Store - Status Code: {response.status_code}\\nResponse JSON: {response.json()}\")\n",
    "\n",
    "# Verify Namespace in Entity Store\n",
    "namespace_obj = nemo_client.namespaces.retrieve(namespace_id=NMS_NAMESPACE)\n",
    "print(f\"\\nEntity Store - Namespace: {namespace_obj.id}\")\n",
    "print(f\"Created at: {namespace_obj.created_at}\")\n",
    "print(f\"Description: {namespace_obj.description}\")\n",
    "print(f\"Project: {namespace_obj.project}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e47d752-a0c3-4d42-a7a5-aae3ab1483de",
   "metadata": {},
   "source": [
    "> **Tip**: To delete a namespace, you can use the following code -\n",
    "\n",
    "```python\n",
    "nemo_client.namespaces.delete(\n",
    "    namespace_id=NMS_NAMESPACE, \n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642b82f5",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"step-1\"></a>\n",
    "## Step 1: Upload Data to NeMo Data Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bef2c33",
   "metadata": {},
   "source": [
    "The NeMo Data Store supports data management using the Hugging Face `HfApi` Client. \n",
    "\n",
    "**Note that this step does not interact with Hugging Face at all, it just uses the client library to interact with NeMo Data Store.** This is in comparison to the previous notebook, where we used the `load_dataset` API to download the dataset from Hugging Face's repository.\n",
    "\n",
    "More information can be found in [documentation](https://docs.nvidia.com/nemo/microservices/latest/manage-entities/tutorials/manage-dataset-files.html#set-up-hugging-face-client-with-nemo-data-store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69acea26",
   "metadata": {},
   "source": [
    "### 1.1 Create Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cace07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = f\"{NMS_NAMESPACE}/{DATASET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a6705b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepoUrl('datasets/embed-sft-ns/embed-sft-data', endpoint='http://data-store.test/v1/hf', repo_type='dataset', repo_id='embed-sft-ns/embed-sft-data')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "hf_api = HfApi(endpoint=f\"{NDS_URL}/v1/hf\", token=\"\")\n",
    "\n",
    "\n",
    "# Create repo\n",
    "hf_api.create_repo(\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd8a073",
   "metadata": {},
   "source": [
    "`Tip:` To delete a repo, you may use the following method\n",
    "\n",
    "```python\n",
    "hf_api.delete_repo(\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff2bd86",
   "metadata": {},
   "source": [
    "### 1.2 Upload Dataset Files to NeMo Data Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25655162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44aac3e6aef4e12b5d95742da9a809b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training.jsonl:   0%|          | 0.00/15.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32e35456f854e68bd811da8d6593458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation.jsonl:   0%|          | 0.00/882k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='', commit_message='Upload validation/validation.jsonl with huggingface_hub', commit_description='', oid='5c2e00ed0cb93e19ffcb910f449ab22df865257f', pr_url=None, repo_url=RepoUrl('', endpoint='https://huggingface.co', repo_type='model', repo_id=''), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_api.upload_file(\n",
    "    path_or_fileobj=train_fp,\n",
    "    path_in_repo=\"training/training.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")\n",
    "\n",
    "hf_api.upload_file(\n",
    "    path_or_fileobj=val_fp,\n",
    "    path_in_repo=\"validation/validation.jsonl\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcedd8b",
   "metadata": {},
   "source": [
    "### 1.3 Register the Dataset with NeMo Entity Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45771ad",
   "metadata": {},
   "source": [
    "To use a dataset for operations such as evaluations and customizations, register a dataset using the `nemo_client.datasets.create()` method.\n",
    "Register the dataset to refer to it by its namespace and name afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db62956c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset: embed-sft-ns/embed-sft-data\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "dataset = nemo_client.datasets.create(\n",
    "    name=DATASET_NAME,\n",
    "    namespace=NMS_NAMESPACE,\n",
    "    description=\"Embedding SFT Dataset\",\n",
    "    files_url=f\"hf://datasets/{NMS_NAMESPACE}/{DATASET_NAME}\",\n",
    "    project=\"embedding_sft\",\n",
    ")\n",
    "print(f\"Created dataset: {dataset.namespace}/{dataset.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465de09",
   "metadata": {},
   "source": [
    "`Tip:` If you'd like to delete a dataset, you may use the following -\n",
    "\n",
    "```python\n",
    "# Delete dataset\n",
    "dataset = nemo_client.datasets.delete(\n",
    "    namespace=NMS_NAMESPACE,\n",
    "    dataset_name=DATASET_NAME,\n",
    ")\n",
    "print(f\"Deletion status: {dataset.message}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d48ef5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files URL: hf://datasets/embed-sft-ns/embed-sft-data\n"
     ]
    }
   ],
   "source": [
    "# Sanity check to validate dataset\n",
    "dataset_obj = nemo_client.datasets.retrieve(namespace=NMS_NAMESPACE, dataset_name=DATASET_NAME)\n",
    "\n",
    "print(\"Files URL:\", dataset_obj.files_url)\n",
    "assert dataset_obj.files_url == f\"hf://datasets/{repo_id}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42733208",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"step-2\"></a>\n",
    "## 2. Embedding Model SFT with NeMo Customizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8361225d",
   "metadata": {},
   "source": [
    "### 2.1 Create a Customization Configuration\n",
    "\n",
    "This allows you to create a template for repeatable experiments with a certain set of configurations. Note that there are default configs available that can be used off-the-shelf (ex: `llama-3.2-1b-embed@v1.0.0+A100`). \n",
    "\n",
    "\n",
    "[llama-3_2-nv-embedqa-1b-v2](https://build.nvidia.com/nvidia/llama-3_2-nv-embedqa-1b-v2) is used as the starting point for further finetuning (see `target`). Note that it is already a great baseline model applicable for a wide variety of multilingual and cross-lingual text question-answering retrieval tasks. \n",
    "\n",
    "\n",
    "The next step demonstrates creating a customization config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63c2750a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created config: llama-embed-sft-config@v1\n"
     ]
    }
   ],
   "source": [
    "SFT_CONFIG_NAME = \"llama-embed-sft-config@v1\"\n",
    "\n",
    "try:\n",
    "    sft_config = nemo_client.customization.configs.create(\n",
    "        name=SFT_CONFIG_NAME,\n",
    "        namespace=NMS_NAMESPACE,\n",
    "        description=\"Configuration for Llama 3.2 1B Embedding on A100 GPUs\",\n",
    "        target=f\"{BASE_MODEL}@{BASE_MODEL_VERSION}\",\n",
    "        training_options=[\n",
    "            {\n",
    "                \"training_type\": \"sft\",\n",
    "                \"finetuning_type\": \"all_weights\",\n",
    "                \"num_gpus\": 1,\n",
    "                \"num_nodes\": 1,\n",
    "                \"micro_batch_size\": 8,\n",
    "                \"tensor_parallel_size\": 1,\n",
    "                \"pipeline_parallel_size\": 1,\n",
    "                \"use_sequence_parallel\": False\n",
    "            }\n",
    "        ],\n",
    "        training_precision=\"bf16\",\n",
    "        max_seq_length=2048\n",
    "    )\n",
    "    print(f\"Created config: {sft_config.name}\")\n",
    "except APIStatusError as e:\n",
    "    if e.status_code == 409:\n",
    "        print(f\"Config {SFT_CONFIG_NAME} already exists (409 Conflict)\")\n",
    "    else:\n",
    "        print(f\"API error {e.status_code}: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1bbbc8",
   "metadata": {},
   "source": [
    "### 2.2 Start the Training Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fb6b97",
   "metadata": {},
   "source": [
    "Start the training job by calling `nemo_client.customization.jobs.create()` method.\n",
    "The following code sets the training parameters and starts the job.\n",
    "\n",
    "> **The training job will take approximately 45 minutes to complete.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58ead098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created customization job: cust-YDoc9CnUpVudgSXUKFBWxa\n",
      "Status: created\n",
      "Job Details:  CustomizationJob(config='embed-sft-ns/llama-embed-sft-config@v1', dataset='embed-sft-ns/embed-sft-data', hyperparameters=Hyperparameters(finetuning_type='all_weights', batch_size=256, distillation=None, dpo=None, epochs=1, learning_rate=5e-06, log_every_n_steps=None, lora=None, sequence_packing_enabled=False, sft=None, training_type='sft', val_check_interval=None, weight_decay=None), id='cust-YDoc9CnUpVudgSXUKFBWxa', config_snapshot=CustomizationConfigJobValue(base_model='nvidia/llama-3.2-nv-embedqa-1b-v2', max_seq_length=2048, precision='bf16', training_option=CustomizationTrainingOption(finetuning_type='all_weights', micro_batch_size=8, num_gpus=1, training_type='sft', data_parallel_size=1, num_nodes=1, pipeline_parallel_size=1, tensor_parallel_size=1, use_sequence_parallel=False), dataset_schema=None, prompt_template='{prompt} {completion}'), created_at=datetime.datetime(2025, 7, 31, 22, 56, 27, 651940), dataset_parameters=None, description=None, integrations=[WandBIntegration(wandb=WandBIntegrationData(entity=None, notes=None, project='nvidia-nemo-customizer', tags=None), type='wandb')], namespace='default', output_model='embed-sft-ns/fullweight_sft_embedding@cust-YDoc9CnUpVudgSXUKFBWxa', ownership=None, project=None, status='created', status_details=CustomizationStatusDetails(created_at=datetime.datetime(2025, 7, 31, 22, 56, 28, 559257), status=None, updated_at=datetime.datetime(2025, 7, 31, 22, 56, 28, 559257), best_epoch=None, elapsed_time=0.0, epochs_completed=0, metrics=None, percentage_done=0.0, status_logs=[StatusLog(updated_at=datetime.datetime(2025, 7, 31, 22, 56, 28, 559257), detail=None, message='created')], steps_completed=0, steps_per_epoch=None, train_loss=None, val_loss=None), updated_at=datetime.datetime(2025, 7, 31, 22, 56, 27, 651943), warnings=None)\n"
     ]
    }
   ],
   "source": [
    "# If WANDB_API_KEY is set, we send it in the request header, which will report the training metrics to Weights & Biases (WandB).\n",
    "if WANDB_API_KEY:\n",
    "    client_with_wandb = nemo_client.with_options(default_headers={\"wandb-api-key\": WANDB_API_KEY})\n",
    "else:\n",
    "    client_with_wandb = nemo_client\n",
    "\n",
    "customization = client_with_wandb.customization.jobs.create(\n",
    "    name=\"llama-3.2-1b-embed-sft\",\n",
    "    config=f\"{NMS_NAMESPACE}/{sft_config.name}\",\n",
    "    dataset={\n",
    "        \"namespace\": NMS_NAMESPACE,\n",
    "        \"name\": DATASET_NAME, \n",
    "    },\n",
    "    hyperparameters={\n",
    "        \"training_type\": \"sft\",\n",
    "        \"finetuning_type\": \"all_weights\",\n",
    "        \"epochs\": 1,\n",
    "        \"batch_size\": 256,\n",
    "        \"learning_rate\": 0.000005,\n",
    "    },\n",
    "    output_model=f\"{NMS_NAMESPACE}/{OUTPUT_MODEL_NAME_EMBEDDING}\"\n",
    ")\n",
    "print(f\"Created customization job: {customization.id}\")\n",
    "print(f\"Status: {customization.status}\")\n",
    "print(\"Job Details: \", customization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2312ab5-b8f2-4bc5-b19b-9cd432080601",
   "metadata": {},
   "source": [
    "> **Tip**: If you specified a WANDB API KEY, you can observe the run under the project \"nvidia-nemo-customizer\" with its Run name as your customization job ID reported above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b693b9b",
   "metadata": {},
   "source": [
    "The following code sets variables for storing the customized model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef85adce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the Customized Model:  embed-sft-ns/fullweight_sft_embedding@cust-YDoc9CnUpVudgSXUKFBWxa\n"
     ]
    }
   ],
   "source": [
    "CUSTOMIZED_MODEL = customization.output_model\n",
    "\n",
    "# Once training is completed, this will be the name of the model that will be used to send inference queries\n",
    "print(\"Name of the Customized Model: \", CUSTOMIZED_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c283a",
   "metadata": {},
   "source": [
    "**Tips**:\n",
    "* If you configured the NeMo Customizer microservice with your own [Weights & Biases (WandB)](https://wandb.ai/) API key, you can find the training graphs and logs in your WandB account, \"nvidia-nemo-customizer\" project. Your run ID is similar to your job id : `customization.id`.\n",
    "  \n",
    "* To cancel a job that you scheduled incorrectly, run the following code.\n",
    "```python\n",
    "nemo_client.customization.jobs.cancel(job_id=customization.id)\n",
    "```\n",
    "\n",
    "* To delete a model for a job that was incorrectly scheduled, use the following code\n",
    "```python\n",
    "# CUSTOMIZED_MODEL.split('/')[1] extracts just the model name from `namespace/model_name` \n",
    "model = nemo_client.models.delete(namespace=NMS_NAMESPACE, model_name=CUSTOMIZED_MODEL.split('/')[1])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7437a1c8",
   "metadata": {},
   "source": [
    "### 2.2 Get Job Status\n",
    "\n",
    "Get the job status by using the `nemo_client.customization.jobs.status()` method.\n",
    "The following code sets the job ID and sends the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6551d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage done: 0.0\n",
      "Job Status: {\n",
      "  \"created_at\": \"2025-07-31 21:37:15.984051\",\n",
      "  \"status\": \"pending\",\n",
      "  \"updated_at\": \"2025-07-31 21:37:15.984051\",\n",
      "  \"best_epoch\": null,\n",
      "  \"elapsed_time\": 0.0,\n",
      "  \"epochs_completed\": 0,\n",
      "  \"metrics\": null,\n",
      "  \"percentage_done\": 0.0,\n",
      "  \"status_logs\": [\n",
      "    {\n",
      "      \"updated_at\": \"2025-07-31 21:37:15.984051\",\n",
      "      \"detail\": null,\n",
      "      \"message\": \"created\"\n",
      "    },\n",
      "    {\n",
      "      \"updated_at\": \"2025-07-31 21:37:15.984051\",\n",
      "      \"detail\": \"The training job is pending\",\n",
      "      \"message\": \"TrainingJobPending\"\n",
      "    }\n",
      "  ],\n",
      "  \"steps_completed\": 0,\n",
      "  \"steps_per_epoch\": null,\n",
      "  \"train_loss\": null,\n",
      "  \"val_loss\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Get job status\n",
    "job_status = nemo_client.customization.jobs.status(job_id=customization.id)\n",
    "\n",
    "print(\"Percentage done:\", job_status.percentage_done)\n",
    "print(\"Job Status:\", json.dumps(job_status.model_dump(), indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f89d109",
   "metadata": {},
   "source": [
    "The following cell defines a method for polling until the job completes.\n",
    "\n",
    "**NOTE**: The progress bar is linked to the number of epochs completed. If training 1 epoch as an example (as the default above), it will go from 0% to 100% in a single jump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cf24916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: running after 5.05 seconds. Progress: 0.0%\n",
      "Job status: running after 10.08 seconds. Progress: 0.0%\n",
      "Job status: running after 15.11 seconds. Progress: 0.0%\n",
      "Job status: running after 20.13 seconds. Progress: 0.0%\n",
      "Job status: running after 25.16 seconds. Progress: 0.0%\n",
      "Job status: running after 30.19 seconds. Progress: 0.0%\n",
      "Job status: running after 35.22 seconds. Progress: 0.0%\n",
      "Job status: running after 40.24 seconds. Progress: 0.0%\n",
      "Job status: running after 45.27 seconds. Progress: 0.0%\n",
      "Job status: running after 50.29 seconds. Progress: 0.0%\n",
      "Job status: running after 55.38 seconds. Progress: 0.0%\n",
      "Job status: running after 60.40 seconds. Progress: 0.0%\n",
      "Job status: running after 65.43 seconds. Progress: 0.0%\n",
      "Job status: running after 70.79 seconds. Progress: 0.0%\n",
      "Job status: running after 75.82 seconds. Progress: 0.0%\n",
      "Job status: running after 80.86 seconds. Progress: 0.0%\n",
      "Job status: running after 86.09 seconds. Progress: 0.0%\n",
      "Job status: running after 91.11 seconds. Progress: 0.0%\n",
      "Job status: running after 96.14 seconds. Progress: 0.0%\n",
      "Job status: running after 101.39 seconds. Progress: 0.0%\n",
      "Job status: running after 106.41 seconds. Progress: 0.0%\n",
      "Job status: running after 111.44 seconds. Progress: 0.0%\n",
      "Job status: running after 116.67 seconds. Progress: 0.0%\n",
      "Job status: running after 121.70 seconds. Progress: 0.0%\n",
      "Job status: running after 126.72 seconds. Progress: 0.0%\n",
      "Job status: running after 131.97 seconds. Progress: 0.0%\n",
      "Job status: running after 136.99 seconds. Progress: 0.0%\n",
      "Job status: running after 142.02 seconds. Progress: 0.0%\n",
      "Job status: running after 147.25 seconds. Progress: 0.0%\n",
      "Job status: running after 152.28 seconds. Progress: 0.0%\n",
      "Job status: running after 157.31 seconds. Progress: 0.0%\n",
      "Job status: running after 162.70 seconds. Progress: 0.0%\n",
      "Job status: running after 167.73 seconds. Progress: 0.0%\n",
      "Job status: running after 172.76 seconds. Progress: 0.0%\n",
      "Job status: running after 177.99 seconds. Progress: 0.0%\n",
      "Job status: running after 183.01 seconds. Progress: 0.0%\n",
      "Job status: running after 188.04 seconds. Progress: 0.0%\n",
      "Job status: running after 193.28 seconds. Progress: 0.0%\n",
      "Job status: running after 198.31 seconds. Progress: 0.0%\n",
      "Job status: running after 203.34 seconds. Progress: 0.0%\n",
      "Job status: running after 208.56 seconds. Progress: 0.0%\n",
      "Job status: running after 213.59 seconds. Progress: 0.0%\n",
      "Job status: running after 218.61 seconds. Progress: 0.0%\n",
      "Job status: running after 223.85 seconds. Progress: 0.0%\n",
      "Job status: running after 228.87 seconds. Progress: 0.0%\n",
      "Job status: running after 233.90 seconds. Progress: 0.0%\n",
      "Job status: running after 239.28 seconds. Progress: 0.0%\n",
      "Job status: running after 244.30 seconds. Progress: 0.0%\n",
      "Job status: running after 249.33 seconds. Progress: 0.0%\n",
      "Job status: running after 254.94 seconds. Progress: 0.0%\n",
      "Job status: running after 259.97 seconds. Progress: 0.0%\n",
      "Job status: running after 265.00 seconds. Progress: 0.0%\n",
      "Job status: running after 270.24 seconds. Progress: 0.0%\n",
      "Job status: running after 275.26 seconds. Progress: 0.0%\n",
      "Job status: running after 280.29 seconds. Progress: 0.0%\n",
      "Job status: running after 285.51 seconds. Progress: 0.0%\n",
      "Job status: running after 290.54 seconds. Progress: 0.0%\n",
      "Job status: running after 295.57 seconds. Progress: 0.0%\n",
      "Job status: running after 300.91 seconds. Progress: 0.0%\n",
      "Job status: running after 305.94 seconds. Progress: 0.0%\n",
      "Job status: running after 310.97 seconds. Progress: 0.0%\n",
      "Job status: running after 316.20 seconds. Progress: 0.0%\n",
      "Job status: running after 321.23 seconds. Progress: 0.0%\n",
      "Job status: running after 326.26 seconds. Progress: 0.0%\n",
      "Job status: running after 331.48 seconds. Progress: 0.0%\n",
      "Job status: running after 336.51 seconds. Progress: 0.0%\n",
      "Job status: running after 341.54 seconds. Progress: 0.0%\n",
      "Job status: running after 346.77 seconds. Progress: 0.0%\n",
      "Job status: running after 351.80 seconds. Progress: 0.0%\n",
      "Job status: running after 356.83 seconds. Progress: 0.0%\n",
      "Job status: running after 362.07 seconds. Progress: 0.0%\n",
      "Job status: running after 367.09 seconds. Progress: 0.0%\n",
      "Job status: running after 372.12 seconds. Progress: 0.0%\n",
      "Job status: running after 377.42 seconds. Progress: 0.0%\n",
      "Job status: running after 382.45 seconds. Progress: 0.0%\n",
      "Job status: running after 387.47 seconds. Progress: 0.0%\n",
      "Job status: running after 392.71 seconds. Progress: 0.0%\n",
      "Job status: running after 397.73 seconds. Progress: 0.0%\n",
      "Job status: running after 402.76 seconds. Progress: 0.0%\n",
      "Job status: running after 408.00 seconds. Progress: 0.0%\n",
      "Job status: running after 413.03 seconds. Progress: 0.0%\n",
      "Job status: running after 418.06 seconds. Progress: 0.0%\n",
      "Job status: running after 423.30 seconds. Progress: 0.0%\n",
      "Job status: running after 428.33 seconds. Progress: 0.0%\n",
      "Job status: running after 433.35 seconds. Progress: 0.0%\n",
      "Job status: running after 438.59 seconds. Progress: 0.0%\n",
      "Job status: running after 443.62 seconds. Progress: 0.0%\n",
      "Job status: running after 448.65 seconds. Progress: 0.0%\n",
      "Job status: running after 454.00 seconds. Progress: 0.0%\n",
      "Job status: running after 459.03 seconds. Progress: 0.0%\n",
      "Job status: running after 464.06 seconds. Progress: 0.0%\n",
      "Job status: running after 469.29 seconds. Progress: 0.0%\n",
      "Job status: running after 474.32 seconds. Progress: 0.0%\n",
      "Job status: running after 479.35 seconds. Progress: 0.0%\n",
      "Job status: running after 484.57 seconds. Progress: 0.0%\n",
      "Job status: running after 489.60 seconds. Progress: 0.0%\n",
      "Job status: running after 494.63 seconds. Progress: 0.0%\n",
      "Job status: running after 499.86 seconds. Progress: 0.0%\n",
      "Job status: running after 504.89 seconds. Progress: 0.0%\n",
      "Job status: running after 509.93 seconds. Progress: 0.0%\n",
      "Job status: running after 515.15 seconds. Progress: 0.0%\n",
      "Job status: running after 520.19 seconds. Progress: 0.0%\n",
      "Job status: running after 525.21 seconds. Progress: 0.0%\n",
      "Job status: running after 530.43 seconds. Progress: 0.0%\n",
      "Job status: running after 535.45 seconds. Progress: 0.0%\n",
      "Job status: running after 540.48 seconds. Progress: 0.0%\n",
      "Job status: running after 545.84 seconds. Progress: 0.0%\n",
      "Job status: running after 550.87 seconds. Progress: 0.0%\n",
      "Job status: running after 555.90 seconds. Progress: 0.0%\n",
      "Job status: running after 561.13 seconds. Progress: 0.0%\n",
      "Job status: running after 566.15 seconds. Progress: 0.0%\n",
      "Job status: running after 571.18 seconds. Progress: 0.0%\n",
      "Job status: running after 576.40 seconds. Progress: 0.0%\n",
      "Job status: running after 581.43 seconds. Progress: 0.0%\n",
      "Job status: running after 586.46 seconds. Progress: 0.0%\n",
      "Job status: running after 591.68 seconds. Progress: 0.0%\n",
      "Job status: running after 596.70 seconds. Progress: 0.0%\n",
      "Job status: running after 601.73 seconds. Progress: 0.0%\n",
      "Job status: running after 606.96 seconds. Progress: 0.0%\n",
      "Job status: running after 611.99 seconds. Progress: 0.0%\n",
      "Job status: running after 617.02 seconds. Progress: 0.0%\n",
      "Job status: running after 622.36 seconds. Progress: 0.0%\n",
      "Job status: running after 627.39 seconds. Progress: 0.0%\n",
      "Job status: running after 632.41 seconds. Progress: 0.0%\n",
      "Job status: running after 637.64 seconds. Progress: 0.0%\n",
      "Job status: running after 642.66 seconds. Progress: 0.0%\n",
      "Job status: running after 647.69 seconds. Progress: 0.0%\n",
      "Job status: running after 652.91 seconds. Progress: 0.0%\n",
      "Job status: running after 657.93 seconds. Progress: 0.0%\n",
      "Job status: running after 662.96 seconds. Progress: 0.0%\n",
      "Job status: running after 668.19 seconds. Progress: 0.0%\n",
      "Job status: running after 673.22 seconds. Progress: 0.0%\n",
      "Job status: running after 678.24 seconds. Progress: 0.0%\n",
      "Job status: running after 683.45 seconds. Progress: 0.0%\n",
      "Job status: running after 688.48 seconds. Progress: 0.0%\n",
      "Job status: running after 693.50 seconds. Progress: 0.0%\n",
      "Job status: running after 698.72 seconds. Progress: 0.0%\n",
      "Job status: running after 703.75 seconds. Progress: 100.0%\n",
      "Job status: running after 708.77 seconds. Progress: 100.0%\n",
      "Job status: running after 714.09 seconds. Progress: 100.0%\n",
      "Job status: running after 719.12 seconds. Progress: 100.0%\n",
      "Job status: running after 724.15 seconds. Progress: 100.0%\n",
      "Job status: running after 729.41 seconds. Progress: 100.0%\n",
      "Job status: running after 734.43 seconds. Progress: 100.0%\n",
      "Job status: running after 739.46 seconds. Progress: 100.0%\n",
      "Job status: running after 744.66 seconds. Progress: 100.0%\n",
      "Job status: running after 749.69 seconds. Progress: 100.0%\n",
      "Job status: running after 754.71 seconds. Progress: 100.0%\n",
      "Job status: running after 759.93 seconds. Progress: 100.0%\n",
      "Job status: running after 764.96 seconds. Progress: 100.0%\n",
      "Job status: running after 769.99 seconds. Progress: 100.0%\n",
      "Job status: running after 775.21 seconds. Progress: 100.0%\n",
      "Job status: running after 780.23 seconds. Progress: 100.0%\n",
      "Job status: running after 785.26 seconds. Progress: 100.0%\n",
      "Job status: running after 790.63 seconds. Progress: 100.0%\n",
      "Job status: running after 795.66 seconds. Progress: 100.0%\n",
      "Job status: running after 800.68 seconds. Progress: 100.0%\n",
      "Job status: running after 805.98 seconds. Progress: 100.0%\n",
      "Job status: running after 811.01 seconds. Progress: 100.0%\n",
      "Job status: running after 816.04 seconds. Progress: 100.0%\n",
      "Job status: running after 821.38 seconds. Progress: 100.0%\n",
      "Job status: completed after 826.41 seconds. Progress: 100%\n"
     ]
    }
   ],
   "source": [
    "# Add wait for the customization job to complete\n",
    "\n",
    "from time import sleep, time\n",
    "\n",
    "def wait_job(nemo_client, job_id: str, polling_interval: int = 10, timeout: int = 6000):\n",
    "    \"\"\"Helper for waiting an eval job using SDK.\"\"\"\n",
    "    start_time = time()\n",
    "    job = nemo_client.customization.jobs.retrieve(job_id=job_id)\n",
    "    status = job.status\n",
    "\n",
    "    while status in [\"pending\", \"created\", \"running\"]:\n",
    "        # Check for timeout\n",
    "        if time() - start_time > timeout:\n",
    "            raise RuntimeError(f\"Took more than {timeout} seconds.\")\n",
    "\n",
    "        # Sleep before polling again\n",
    "        sleep(polling_interval)\n",
    "\n",
    "        # Fetch updated status and progress\n",
    "        job = nemo_client.customization.jobs.retrieve(job_id=job_id)\n",
    "        status = job.status\n",
    "        progress = 0.0\n",
    "        if status == \"running\" and job.status_details:\n",
    "            progress = job.status_details.percentage_done or 0.0\n",
    "        elif status == \"completed\":\n",
    "            progress = 100\n",
    "\n",
    "        print(f\"Job status: {status} after {time() - start_time:.2f} seconds. Progress: {progress}%\")\n",
    "\n",
    "    # Check final status after exiting loop\n",
    "    if status == \"failed\":\n",
    "        print(f\"Job failed after {time() - start_time:.2f} seconds.\")\n",
    "        raise RuntimeError(f\"Job {job_id} failed.\")\n",
    "\n",
    "    return job\n",
    "\n",
    "job = wait_job(nemo_client, customization.id, polling_interval=5, timeout=2400)\n",
    "\n",
    "# Only sleep if job completed successfully\n",
    "if job.status == \"completed\":\n",
    "    # Wait for 1 minute, to ensure any artifacts are saved\n",
    "    sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b296ac76",
   "metadata": {},
   "source": [
    "### 2.3 Validate Availability of Custom Model\n",
    "The following NeMo Entity Store API should display the model when the training job is complete.\n",
    "The list below shows all models filtered by your namespace and sorted by the latest first.\n",
    "For more information about this API, see the [NeMo Entity Store API reference](https://docs.nvidia.com/nemo/microservices/latest/api/entity-store.html).\n",
    "With the following code, you can find all customized models, including the one trained in the previous cells.\n",
    "Look for the `name` fields in the output, which should match your `CUSTOMIZED_MODEL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aa8eda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 models in namespace embed-sft-ns:\n",
      "\n",
      "Model: fullweight_sft_embedding@cust-VrPUoNP7ynWTBu73cbfaFM\n",
      "  Namespace: embed-sft-ns\n",
      "  Base Model: nvidia/llama-3.2-nv-embedqa-1b-v2\n",
      "  Created: 2025-07-31 21:37:16.098585\n",
      "  Fine-tuning Type: all_weights\n"
     ]
    }
   ],
   "source": [
    "# List models with filters\n",
    "models_page = nemo_client.models.list(\n",
    "    filter={\"namespace\": NMS_NAMESPACE},\n",
    "    sort=\"-created_at\"\n",
    ")\n",
    "\n",
    "# Print models information\n",
    "print(f\"Found {len(models_page.data)} models in namespace {NMS_NAMESPACE}:\")\n",
    "for model in models_page.data:\n",
    "    print(f\"\\nModel: {model.name}\")\n",
    "    print(f\"  Namespace: {model.namespace}\")\n",
    "    print(f\"  Base Model: {model.base_model}\")\n",
    "    print(f\"  Created: {model.created_at}\")\n",
    "    if model.peft:\n",
    "        print(f\"  Fine-tuning Type: {model.peft.finetuning_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57c8d4f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"step-3\"></a>\n",
    "## Step 3: Deploy the Custom Model with NeMo Deployment Management Service (DMS)\n",
    "\n",
    "Once the model is supervised finetuned, it can be deployed as a service with NeMo DMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc00e16c",
   "metadata": {},
   "source": [
    "### 3.1 Create a Deployment Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68ff770",
   "metadata": {},
   "source": [
    "The following cell creates a deployment configuration. Configurations like these can serve as templates across multiple deployments.\n",
    "\n",
    "> **The Embedding NIM does not support LoRA adapters, so `disable_lora_support=True` must be set in the deployment configuration.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "475731a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying embed-sft-ns/fullweight_sft_embedding@cust-VrPUoNP7ynWTBu73cbfaFM with DMS.\n",
      "Deployment config created: llama-embed-sft-deploy-config\n"
     ]
    }
   ],
   "source": [
    "print(f\"Deploying {CUSTOMIZED_MODEL} with DMS.\")\n",
    "\n",
    "deployment_config = nemo_client.deployment.configs.create(\n",
    "    name=\"llama-embed-sft-deploy-config\",\n",
    "    namespace=NMS_NAMESPACE,\n",
    "    model=CUSTOMIZED_MODEL,\n",
    "    nim_deployment={\n",
    "        \"image_name\": BASE_MODEL_IMAGE_NAME_EMBEDDING,\n",
    "        \"image_tag\": BASE_MODEL_IMAGE_TAG_EMBEDDING,\n",
    "        \"gpu\": 1,\n",
    "        \"disable_lora_support\": True,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"Deployment config created: {deployment_config.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0563b35f",
   "metadata": {},
   "source": [
    "### 3.2 Deploy the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ddd7b2",
   "metadata": {},
   "source": [
    "The following cell creates a Model Deployment for the SFT embedding model so we can send queries to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58358f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model deployment created: llama-embed-sft-deploy\n"
     ]
    }
   ],
   "source": [
    "DEPLOYMENT_NAME = \"llama-embed-sft-deploy\"\n",
    "\n",
    "deployment = nemo_client.deployment.model_deployments.create(\n",
    "    name=DEPLOYMENT_NAME,\n",
    "    namespace=NMS_NAMESPACE,\n",
    "    config=f\"{NMS_NAMESPACE}/{deployment_config.name}\"\n",
    ")\n",
    "\n",
    "print(f\"Model deployment created: {deployment.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c50abf",
   "metadata": {},
   "source": [
    "### 3.3 Check Status of Deployment\n",
    "\n",
    "> **It will take about 10 minutes the first time a model is deployed. This is because it pulls the container image the first time, and it typically much faster in subsequent deployments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5d8cfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring deployment status for llama-embed-sft-deploy...\n",
      "Deployment: llama-embed-sft-deploy | Status: ready after 120.28 secondsds\n",
      "✅ Deployment completed successfully!\n"
     ]
    }
   ],
   "source": [
    "def wait_deployment(nemo_client, deployment_id: str, namespace: str, polling_interval: int = 10, timeout: int = 6000):\n",
    "    \"\"\"Helper for waiting for a deployment to complete using SDK.\"\"\"\n",
    "    from time import time, sleep\n",
    "    \n",
    "    start_time = time()\n",
    "    print(f\"Monitoring deployment status for {deployment_id}...\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # Check for timeout\n",
    "            if time() - start_time > timeout:\n",
    "                raise RuntimeError(f\"Deployment took more than {timeout} seconds.\")\n",
    "            \n",
    "            # Get deployment status\n",
    "            deployment = nemo_client.deployment.model_deployments.retrieve(\n",
    "                deployment_name=deployment_id,\n",
    "                namespace=namespace\n",
    "            )\n",
    "            \n",
    "            status = deployment.status_details.status\n",
    "            \n",
    "            print(f\"\\rDeployment: {deployment_id} | Status: {status} after {time() - start_time:.2f} seconds\", end=\"\", flush=True)\n",
    "            \n",
    "            # Check if deployment is complete\n",
    "            if status == 'ready':\n",
    "                print(\"\\n✅ Deployment completed successfully!\")\n",
    "                break\n",
    "            elif status in ['failed', 'cancelled']:\n",
    "                print(f\"\\n❌ Deployment {status}\")\n",
    "                raise RuntimeError(f\"Deployment {deployment_id} {status}.\")\n",
    "            \n",
    "            sleep(polling_interval)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nStopped by user\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            if \"timeout\" in str(e) or \"RuntimeError\" in str(type(e).__name__):\n",
    "                raise\n",
    "            print(f\"\\nError: {e}\")\n",
    "            sleep(30)\n",
    "    \n",
    "    return deployment\n",
    "\n",
    "\n",
    "# DEPLOYMENT_ID = \"llama-embed-sft-deploy\"\n",
    "deployment = wait_deployment(nemo_client, deployment.name, NMS_NAMESPACE, polling_interval=10, timeout=2400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d0c8cc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"step-4\"></a>\n",
    "## Step 4: Run inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d4940b",
   "metadata": {},
   "source": [
    "### 4.1 Send a request using OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9157c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embeddings inference successful!\n",
      "Model: embed-sft-ns/fullweight_sft_embedding\n",
      "Input type: query\n",
      "Embedding dimensions: 2048\n",
      "First 5 values: [0.01850244589149952, 0.02443564310669899, 0.019832126796245575, 0.007798167411237955, 0.026634424924850464]\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def get_embeddings(input_text, model_name, input_type=\"query\"):\n",
    "    \"\"\"\n",
    "    Create embeddings using OpenAI client\n",
    "    \n",
    "    Args:\n",
    "        input_text (str or list): Text to embed\n",
    "        model_name (str): Model name to use\n",
    "        input_type (str): Either \"query\" or \"passage\"\n",
    "    \"\"\"\n",
    "    # Initialize OpenAI client with NIM endpoint\n",
    "    client = OpenAI(\n",
    "        base_url=f\"{NIM_URL}/v1\",\n",
    "        api_key=\"None\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        if isinstance(input_text, str):\n",
    "            input_text = [input_text]\n",
    "            \n",
    "        # Create embeddings\n",
    "        response = client.embeddings.create(\n",
    "            input=input_text,\n",
    "            model=model_name,\n",
    "            extra_body={\"input_type\": input_type}\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Embeddings inference successful!\")\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Input type: {input_type}\")\n",
    "        print(f\"Embedding dimensions: {len(response.data[0].embedding)}\")\n",
    "        print(f\"First 5 values: {response.data[0].embedding[:5]}\")\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Embeddings inference failed: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Quick test\n",
    "_ = get_embeddings(\n",
    "    \"What is the population of Pittsburgh?\", \n",
    "    f\"{NMS_NAMESPACE}/{OUTPUT_MODEL_NAME_EMBEDDING}\",\n",
    "    input_type=\"query\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc131fc",
   "metadata": {},
   "source": [
    "### 4.2 Example similarity calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c50f11",
   "metadata": {},
   "source": [
    "For a sanity test, the following code calculates the cosine embedding similarity between a query, positive text, and a negative text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df70ada4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with scientific papers data\n",
      "✅ Embeddings inference successful!\n",
      "Model: embed-sft-ns/fullweight_sft_embedding\n",
      "Input type: query\n",
      "Embedding dimensions: 2048\n",
      "First 5 values: [0.0015183016657829285, 0.02104218676686287, 0.006827748846262693, 0.017222300171852112, 0.006073730532079935]\n",
      "✅ Embeddings inference successful!\n",
      "Model: embed-sft-ns/fullweight_sft_embedding\n",
      "Input type: passage\n",
      "Embedding dimensions: 2048\n",
      "First 5 values: [-0.006217789836227894, 0.0023527508601546288, -0.014856393449008465, -0.007038871292024851, -0.011863325722515583]\n",
      "\n",
      "COSINE SIMILARITY RESULTS\n",
      "Query ↔ Positive doc similarity: 0.4391\n",
      "Query ↔ Negative doc similarity: 0.2912\n",
      "✅ Positive document is more similar to query\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "test_data = {\n",
    "    \"query\": \"The Neuroscience of Spontaneous Thought: An Evolving, Interdisciplinary Field\", \n",
    "    \"pos_doc\": \"Hippocampal Replay Is Not a Simple Function of Experience\", \n",
    "    \"neg_doc\": [\"An alternative to the dark matter paradigm: relativistic MOND gravitation\"]\n",
    "    }\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Calculate cosine similarity between two vectors\"\"\"\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    \n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "\n",
    "# Calculate embeddings for query and passage documents\n",
    "print(\"Testing with scientific papers data\")\n",
    "\n",
    "# Get query embedding\n",
    "query_response = get_embeddings(\n",
    "    test_data[\"query\"],\n",
    "    f\"{NMS_NAMESPACE}/{OUTPUT_MODEL_NAME_EMBEDDING}\",\n",
    "    input_type=\"query\"\n",
    ")\n",
    "\n",
    "# Get both positive and negative document embeddings in one request\n",
    "doc_response = get_embeddings(\n",
    "    [test_data[\"pos_doc\"], test_data[\"neg_doc\"][0]],\n",
    "    f\"{NMS_NAMESPACE}/{OUTPUT_MODEL_NAME_EMBEDDING}\",\n",
    "    input_type=\"passage\"\n",
    ")\n",
    "\n",
    "# Calculate cosine similarities if all embeddings were successful\n",
    "if query_response and doc_response:\n",
    "    \n",
    "    # Calculate similarities\n",
    "    query_pos_similarity = cosine_similarity(query_response.data[0].embedding, doc_response.data[0].embedding)\n",
    "    query_neg_similarity = cosine_similarity(query_response.data[0].embedding, doc_response.data[1].embedding)\n",
    "    \n",
    "    print(\"\\nCOSINE SIMILARITY RESULTS\")\n",
    "    print(f\"Query ↔ Positive doc similarity: {query_pos_similarity:.4f}\")\n",
    "    print(f\"Query ↔ Negative doc similarity: {query_neg_similarity:.4f}\")\n",
    "    \n",
    "    if query_pos_similarity > query_neg_similarity:\n",
    "        print(\"✅ Positive document is more similar to query\")\n",
    "    else:\n",
    "        print(\"❌ Negative document is more similar to query\")\n",
    "else:\n",
    "    print(\"❌ Could not calculate similarities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde995c8",
   "metadata": {},
   "source": [
    "The query should be far closer (higher cosine similarity) to the positive doc than the negative doc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1823b99b",
   "metadata": {},
   "source": [
    "### 4.3 Take Note of Your Deployment Name\n",
    "Take note of your custom model deployment name, as you will use it to run evaluation in the subsequent notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2558ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of your deployment is: embed-sft-ns/fullweight_sft_embedding\n"
     ]
    }
   ],
   "source": [
    "print(f\"Name of your deployment is: {NMS_NAMESPACE}/{OUTPUT_MODEL_NAME_EMBEDDING}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
