{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09c22178",
   "metadata": {},
   "source": [
    "# üé® NeMo Data Designer: Synthetic Conversational Data with Person Details\n",
    "\n",
    "> ‚ö†Ô∏è **Warning**: NeMo Data Designer is currently in Early Release and is not recommended for production use.\n",
    "\n",
    "### üìö What you'll learn\n",
    "\n",
    "- This notebook demonstrates how to use the NeMo Data Designer to build a synthetic data generation pipeline step-by-step.\n",
    "\n",
    "- We will create multi-turn user-assistant dialogues tailored for fine-tuning language models, enhanced with realistic person details. \n",
    "\n",
    "- These datasets could be used for developing and enhancing conversational AI applications, including customer \\\n",
    "support chatbots, virtual assistants, and interactive learning systems.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "> üëã **IMPORTANT** ‚Äì¬†Environment Setup\n",
    ">\n",
    "> - If you haven't already, follow the instructions in the [README](../../../README.md) to install the necessary dependencies.\n",
    ">\n",
    "> - You may need to restart your notebook's kernel after setting up the environment.\n",
    "> - In this notebook, we assume you have a self-hosted instance of Data Designer up and running.\n",
    ">\n",
    "> - For deployment instructions, see the [Installation Options](https://docs.nvidia.com/nemo/microservices/latest/design-synthetic-data-from-scratch-or-seeds/index.html#installation-options) section of the [NeMo Data Designer documentation](https://docs.nvidia.com/nemo/microservices/latest/design-synthetic-data-from-scratch-or-seeds/index.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45075a8",
   "metadata": {},
   "source": [
    "### üì¶ Import the essentials\n",
    "\n",
    "- The `data_designer` module of `nemo_microservices` exposes Data Designer's high-level SDK.\n",
    "\n",
    "- The `essentials` module provides quick access to the most commonly used objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd210d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo_microservices.data_designer.essentials import (\n",
    "    CategorySamplerParams,\n",
    "    DataDesignerConfigBuilder,\n",
    "    InferenceParameters,\n",
    "    LLMJudgeColumnConfig,\n",
    "    LLMStructuredColumnConfig,\n",
    "    LLMTextColumnConfig,\n",
    "    ModelConfig,\n",
    "    NeMoDataDesignerClient,\n",
    "    SamplerColumnConfig,\n",
    "    SamplerType,\n",
    "    Score,\n",
    "    SubcategorySamplerParams\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e67dd05",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Initialize the NeMo Data Designer Client\n",
    "\n",
    "- `NeMoDataDesignerClient` is responsible for submitting generation requests to the microservice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d18ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEMO_MICROSERVICES_BASE_URL = \"http://localhost:8080\"\n",
    "\n",
    "data_designer_client = NeMoDataDesignerClient(base_url=NEMO_MICROSERVICES_BASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2830c677",
   "metadata": {},
   "source": [
    "### üéõÔ∏è Define model configurations\n",
    "\n",
    "- Each `ModelConfig` defines a model that can be used during the generation process.\n",
    "\n",
    "- The \"model alias\" is used to reference the model in the Data Designer config (as we will see below).\n",
    "\n",
    "- The \"model provider\" is the external service that hosts the model (see [the model config docs](https://docs.nvidia.com/nemo/microservices/latest/design-synthetic-data-from-scratch-or-seeds/configure-models.html) for more details).\n",
    "\n",
    "- By default, the microservice uses [build.nvidia.com](https://build.nvidia.com/models) as the model provider.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f97be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This name is set in the microservice deployment configuration.\n",
    "MODEL_PROVIDER = \"nvidiabuild\"\n",
    "\n",
    "# The model ID is from build.nvidia.com.\n",
    "MODEL_ID = \"nvidia/nvidia-nemotron-nano-9b-v2\"\n",
    "\n",
    "# We choose this alias to be descriptive for our use case.\n",
    "MODEL_ALIAS = \"nemotron-nano-v2\"\n",
    "\n",
    "# This sets reasoning to False for the nemotron-nano-v2 model.\n",
    "SYSTEM_PROMPT = \"/no_think\"\n",
    "\n",
    "model_configs = [\n",
    "    ModelConfig(\n",
    "        alias=MODEL_ALIAS,\n",
    "        model=MODEL_ID,\n",
    "        provider=MODEL_PROVIDER,\n",
    "        inference_parameters=InferenceParameters(\n",
    "            temperature=0.6,\n",
    "            top_p=0.95,\n",
    "            max_tokens=1024,\n",
    "        ),\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbd0e22",
   "metadata": {},
   "source": [
    "### üèóÔ∏è Initialize the Data Designer Config Builder\n",
    "\n",
    "- The Data Designer config defines the dataset schema and generation process.\n",
    "\n",
    "- The config builder provides an intuitive interface for building this configuration.\n",
    "\n",
    "- The list of model configs is provided to the builder at initialization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c51801",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_builder = DataDesignerConfigBuilder(model_configs=model_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd89a931",
   "metadata": {},
   "source": [
    "### Define Pydantic Models for Structured Outputs\n",
    "\n",
    "You can use Pydantic to define a structure for the messages that are produced by Data Designer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0d9313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Message(BaseModel):\n",
    "    \"\"\"A single message turn in the conversation.\"\"\"\n",
    "    role: Literal[\"user\", \"assistant\"] = Field(..., description=\"Which role is writing the message.\")\n",
    "    content: str = Field(..., description=\"Message contents.\")\n",
    "\n",
    "\n",
    "class ChatConversation(BaseModel):\n",
    "    \"\"\"A chat conversation between a specific user and an AI assistant.\n",
    "    * All conversations are initiated by the user role.\n",
    "    * The assistant role always responds to the user message.\n",
    "    * Turns alternate between user and assistant roles.\n",
    "    * The last message is always from the assistant role.\n",
    "    * Message content can be long or short.\n",
    "    * All assistant messages are faithful responses and must be answered fully.\n",
    "    \"\"\"\n",
    "    conversation: list[Message] = Field(..., description=\"List of all messages in the conversation.\")\n",
    "\n",
    "\n",
    "class UserToxicityScore(BaseModel):\n",
    "    \"\"\"Output format for user toxicity assessment.\n",
    "\n",
    "    Toxicity Scores:\n",
    "    None: No toxicity detected in user messages.\n",
    "    Mild: Slightly rude or sarcastic but not hateful or harmful.\n",
    "    Moderate: Some disrespectful or harassing language.\n",
    "    Severe: Overt hate, harassment, or harmful content.\n",
    "    \"\"\"\n",
    "    reasons: list[str] = Field(..., description=\"Reasoning for user toxicity score.\")\n",
    "    score: Literal[\"None\", \"Mild\", \"Moderate\", \"Severe\"] = Field(..., description=\"Level of toxicity observed in the user role responses.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ff2717",
   "metadata": {},
   "source": [
    "## üé≤ Adding Sampler Columns\n",
    "\n",
    "- Sampler columns offer non-LLM based generation of synthetic data.\n",
    "\n",
    "- They are particularly useful for **steering the diversity** of the generated data, as we demonstrate below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addb7ef4-ef77-4428-8d3d-9b0ceef1ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add domain column with subcategories for topics\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"domain\",\n",
    "        sampler_type=SamplerType.CATEGORY,\n",
    "        params=CategorySamplerParams(\n",
    "            values=[\"Tech Support\", \"Personal Finances\", \"Educational Guidance\"]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add topic subcategory\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"topic\",\n",
    "        sampler_type=SamplerType.SUBCATEGORY,\n",
    "        params=SubcategorySamplerParams(\n",
    "            category=\"domain\",\n",
    "            values={\n",
    "                \"Tech Support\": [\n",
    "                    \"Troubleshooting a Laptop\",\n",
    "                    \"Setting Up a Home Wi-Fi Network\",\n",
    "                    \"Installing Software Updates\",\n",
    "                ],\n",
    "                \"Personal Finances\": [\n",
    "                    \"Budgeting Advice\",\n",
    "                    \"Understanding Taxes\",\n",
    "                    \"Investment Strategies\",\n",
    "                ],\n",
    "                \"Educational Guidance\": [\n",
    "                    \"Choosing a College Major\",\n",
    "                    \"Effective Studying Techniques\",\n",
    "                    \"Learning a New Language\",\n",
    "                ],\n",
    "            },\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add complexity column\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"complexity\",\n",
    "        sampler_type=SamplerType.CATEGORY,\n",
    "        params=CategorySamplerParams(\n",
    "            values=[\"Basic\", \"Intermediate\", \"Advanced\"]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add conversation length column\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"conversation_length\",\n",
    "        sampler_type=SamplerType.CATEGORY,\n",
    "        params=CategorySamplerParams(\n",
    "            values=[2, 4, 6, 8]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add user mood column\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"user_mood\",\n",
    "        sampler_type=SamplerType.CATEGORY,\n",
    "        params=CategorySamplerParams(\n",
    "            values=[\"happy\", \"silly\", \"sarcastic\", \"combative\", \"disappointed\", \"toxic\"]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a34ba38",
   "metadata": {},
   "source": [
    "## ü¶ú Adding LLM Generated columns\n",
    "Now define the columns that the model will generate. These prompts instruct the LLM to produce the actual conversation: \n",
    "- a system prompt to guide how the AI assistant engages in the conversation with the user, \n",
    "- the conversation, and \n",
    "- finally, we generate a toxicity_label to assess user toxicity over the entire conversation.\n",
    "<br> \n",
    "\n",
    "### üí¨ü§ñ AI Assistant system prompt and conversation\n",
    "\n",
    "We generate a system prompt to base the AI assistant and then generate the entire conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06515490-4422-4d6f-bc1d-68b304c44518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate assistant system prompt\n",
    "config_builder.add_column(\n",
    "    LLMTextColumnConfig(\n",
    "        name=\"assistant_system_prompt\",\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "        prompt=(\"Write a reasonable system prompt for a helpful AI assistant with expertise in \"\n",
    "                \"{{domain}} and {{topic}}. The AI assistant must not engage in harmful behaviors.\"),\n",
    "        model_alias=MODEL_ALIAS,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Generate the user's task\n",
    "config_builder.add_column(\n",
    "    LLMTextColumnConfig(\n",
    "        name=\"user_task\",\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "        prompt=\"Define a simple task related to {{topic}} of {{complexity}} complexity for the user.\",\n",
    "        model_alias=MODEL_ALIAS,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Generate the conversation\n",
    "config_builder.add_column(\n",
    "    LLMStructuredColumnConfig(\n",
    "        name=\"conversation\",\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "        prompt=(\n",
    "            \"<task>\\n{{user_task}}\\n</task>\\n\\n\"\n",
    "            \"<system_prompt>{{assistant_system_prompt}}</system_prompt>\\n\\n\"\n",
    "            \"Generate a conversation between a user and an AI assistant with <system_prompt> about <task>.\\n\"\n",
    "            \"User is asking the assistant for advice and is in a {{user_mood}} mood.\\n\"\n",
    "            \"The conversation must be {{conversation_length}} messages in length.\\n\"\n",
    "            \"The conversation must come to a natural end in {{conversation_length}} messages and if the assistant is unable \"\n",
    "            \"to solve the user's needs by then, they should offer to continue the conversation later or redirect them to additional resources.\\n\"\n",
    "            \"The conversation must be realistic and natural, incorporating details from both the user's and assistant's profiles.\\n\"\n",
    "            \"The AI assistant role has the system prompt defined in <system_prompt>. All of its responses must conform to <system_prompt>:\\n\"\n",
    "        ),\n",
    "        output_format=ChatConversation,\n",
    "        model_alias=MODEL_ALIAS,\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ed0ed9",
   "metadata": {},
   "source": [
    "## üîç LLM-as-a-Judge: Toxicity Assessment\n",
    "\n",
    "When generating our synthetic dataset, we need to determine the quality of the generated dialogs. \\\n",
    "We use the LLM-as-a-Judge strategy to do this. \n",
    "\n",
    "To do so, we need to define the rubric that the LLM should use to assess generation quality along with a prompt \n",
    "that provides relavant instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8d945b-a7cb-4add-abc0-dac10a335076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toxicity Label for the entire conversation\n",
    "# Define Toxicity Rubric\n",
    "toxicity_rubric = Score(\n",
    "    name=\"Toxicity\",\n",
    "    description=\"Evaluation of harmful, harassing, or hateful language in conversations\",\n",
    "    options=\n",
    "        {\n",
    "            \"4\": \"No toxicity detected; conversation is respectful and appropriate.\",\n",
    "            \"3\": \"Mild toxicity; slightly rude or sarcastic but not hateful or harmful.\",\n",
    "            \"2\": \"Moderate toxicity; contains disrespectful or harassing language.\",\n",
    "            \"1\": \"Severe toxicity; contains overt hate, harassment, or harmful content.\",\n",
    "            \"0\": \"Extreme toxicity; contains dangerous, threatening, or abusive content.\"\n",
    "        }\n",
    "\n",
    ")\n",
    "\n",
    "TOXICITY_PROMPT_TEMPLATE = (\n",
    "    \"You are an expert in content moderation and digital communication ethics. \"\n",
    "    \"You are evaluating the toxicity level in user messages.\\n\"\n",
    "    \"Take a deep breath and carefully analyze the conversation provided. \\n\"\n",
    "    \"Use the rubric to score the level of toxicity in the USER'S messages only.\\n\"\n",
    "\n",
    "    \"Consider:\\n\"\n",
    "    \"- Focus primarily on harassment, hate, or harmful language\\n\"\n",
    "    \"- Evaluate the full context of the conversation\\n\"\n",
    "    \"- Be objective and consistent in your assessment\\n\"\n",
    "    \"- If any single message exhibits toxicity, it should influence the final score\\n\"\n",
    "\n",
    "    \"## CONVERSATION\\n\"\n",
    "    \"{{ conversation }}\"\n",
    ")\n",
    "\n",
    "config_builder.add_column(\n",
    "    LLMJudgeColumnConfig(\n",
    "        name=\"toxicity_evaluation\",\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "        prompt=TOXICITY_PROMPT_TEMPLATE,\n",
    "        scores=[toxicity_rubric],\n",
    "        model_alias=MODEL_ALIAS\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fc232e",
   "metadata": {},
   "source": [
    "### üîÅ Iteration is key ‚Äì¬†preview the dataset!\n",
    "\n",
    "1. Use the `preview` method to generate a sample of records quickly.\n",
    "\n",
    "2. Inspect the results for quality and format issues.\n",
    "\n",
    "3. Adjust column configurations, prompts, or parameters as needed.\n",
    "\n",
    "4. Re-run the preview until satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a44878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview a few records\n",
    "preview = data_designer_client.preview(config_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c2eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More previews\n",
    "preview.display_sample_record()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f65bf7",
   "metadata": {},
   "source": [
    "### üìä Analyze the generated data\n",
    "\n",
    "- Data Designer automatically generates a basic statistical analysis of the generated data.\n",
    "\n",
    "- This analysis is available via the `analysis` property of generation result objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5eed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the analysis as a table.\n",
    "preview.analysis.to_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc7075e",
   "metadata": {},
   "source": [
    "### üÜô Scale up!\n",
    "\n",
    "- Happy with your preview data?\n",
    "\n",
    "- Use the `create` method to submit larger Data Designer generation jobs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd7737",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_results = data_designer_client.create(config_builder, num_records=20)\n",
    "\n",
    "# This will block until the job is complete.\n",
    "job_results.wait_until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7cbea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the generated dataset as a pandas DataFrame.\n",
    "dataset = job_results.load_dataset()\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b688677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the analysis results into memory.\n",
    "analysis = job_results.load_analysis()\n",
    "\n",
    "analysis.to_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de7903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUTORIAL_OUTPUT_PATH = \"data-designer-tutorial-output\"\n",
    "\n",
    "# Download the job artifacts and save them to disk.\n",
    "job_results.download_artifacts(\n",
    "    output_path=TUTORIAL_OUTPUT_PATH,\n",
    "    artifacts_folder_name=\"artifacts-community-contributions-multi-turn-chat\",\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdg_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
