{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d576b85a",
   "metadata": {},
   "source": [
    "# üë®‚Äçüíª NeMo Data Designer: Text-to-SQL\n",
    "\n",
    "#### üìö What you'll learn\n",
    "\n",
    "- This notebook demonstrates how to use NeMo Data Designer to create a synthetic data generation pipeline for SQL code examples.\n",
    "\n",
    "- We'll build a system that generates SQL code based on natural language instructions, with varying complexity levels and industry focuses.\n",
    "\n",
    "<br>\n",
    "\n",
    "> üëã **IMPORTANT** ‚Äì¬†Environment Setup\n",
    ">\n",
    "> - If you haven't already, follow the instructions in the [README](../../../README.md) to install the necessary dependencies.\n",
    ">\n",
    "> - You may need to restart your notebook's kernel after setting up the environment.\n",
    "> - In this notebook, we assume you have a self-hosted instance of Data Designer up and running.\n",
    ">\n",
    "> - For deployment instructions, see the [Installation Options](https://docs.nvidia.com/nemo/microservices/latest/design-synthetic-data-from-scratch-or-seeds/index.html#installation-options) section of the [NeMo Data Designer documentation](https://docs.nvidia.com/nemo/microservices/latest/design-synthetic-data-from-scratch-or-seeds/index.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e085b967",
   "metadata": {},
   "source": [
    "### üì¶ Import the essentials\n",
    "\n",
    "- The `data_designer` module of `nemo_microservices` exposes Data Designer's high-level SDK.\n",
    "\n",
    "- The `essentials` module provides quick access to the most commonly used objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553c2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo_microservices.data_designer.essentials import (\n",
    "    CategorySamplerParams,\n",
    "    CodeLang,\n",
    "    CodeValidatorParams,\n",
    "    DataDesignerConfigBuilder,\n",
    "    InferenceParameters,\n",
    "    LLMCodeColumnConfig,\n",
    "    LLMJudgeColumnConfig,\n",
    "    LLMTextColumnConfig,\n",
    "    ModelConfig,\n",
    "    NeMoDataDesignerClient,\n",
    "    SamplerColumnConfig,\n",
    "    SamplerType,\n",
    "    Score,\n",
    "    SubcategorySamplerParams,\n",
    "    ValidationColumnConfig,\n",
    "    ValidatorType,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320003a5",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Initialize the NeMo Data Designer Client\n",
    "\n",
    "- `NeMoDataDesignerClient` is responsible for submitting generation requests to the microservice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e99d520",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEMO_MICROSERVICES_BASE_URL = \"http://localhost:8080\"\n",
    "\n",
    "data_designer_client = NeMoDataDesignerClient(base_url=NEMO_MICROSERVICES_BASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c577ae",
   "metadata": {},
   "source": [
    "### üéõÔ∏è Define model configurations\n",
    "\n",
    "- Each `ModelConfig` defines a model that can be used during the generation process.\n",
    "\n",
    "- The \"model alias\" is used to reference the model in the Data Designer config (as we will see below).\n",
    "\n",
    "- The \"model provider\" is the external service that hosts the model (see [the model config docs](https://docs.nvidia.com/nemo/microservices/latest/design-synthetic-data-from-scratch-or-seeds/configure-models.html) for more details).\n",
    "\n",
    "- By default, the microservice uses [build.nvidia.com](https://build.nvidia.com/models) as the model provider.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1950b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This name is set in the microservice deployment configuration.\n",
    "MODEL_PROVIDER = \"nvidiabuild\"\n",
    "\n",
    "# The model ID is from build.nvidia.com.\n",
    "MODEL_ID = \"nvidia/llama-3.3-nemotron-super-49b-v1\"\n",
    "\n",
    "# We choose this alias to be descriptive for our use case.\n",
    "MODEL_ALIAS = \"nemotron-super-49b-v1\"\n",
    "\n",
    "model_configs = [\n",
    "    ModelConfig(\n",
    "        alias=MODEL_ALIAS,\n",
    "        model=MODEL_ID,\n",
    "        provider=MODEL_PROVIDER,\n",
    "        inference_parameters=InferenceParameters(\n",
    "            temperature=0.6,\n",
    "            top_p=0.95,\n",
    "            max_tokens=1024,\n",
    "            timeout=300,\n",
    "        ),\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e330702",
   "metadata": {},
   "source": [
    "### üèóÔ∏è Initialize the Data Designer Config Builder\n",
    "\n",
    "- The Data Designer config defines the dataset schema and generation process.\n",
    "\n",
    "- The config builder provides an intuitive interface for building this configuration.\n",
    "\n",
    "- The list of model configs is provided to the builder at initialization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be026ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_builder = DataDesignerConfigBuilder(model_configs=model_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac72f62",
   "metadata": {},
   "source": [
    "## üé≤ Adding Sampler Columns\n",
    "\n",
    "- Sampler columns offer non-LLM based generation of synthetic data.\n",
    "\n",
    "- They are particularly useful for **steering the diversity** of the generated data, as we demonstrate below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc5ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add industry sector categories\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"industry_sector\",\n",
    "        sampler_type=SamplerType.CATEGORY,\n",
    "        params=CategorySamplerParams(\n",
    "            values=[\"Healthcare\", \"Finance\", \"Technology\"],\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add topic as a subcategory of industry_sector\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"topic\",\n",
    "        sampler_type=SamplerType.SUBCATEGORY,\n",
    "        params=SubcategorySamplerParams(\n",
    "            category=\"industry_sector\",\n",
    "            values={\n",
    "                \"Healthcare\": [\n",
    "                    \"Electronic Health Records (EHR) Systems\",\n",
    "                    \"Telemedicine Platforms\",\n",
    "                    \"AI-Powered Diagnostic Tools\",\n",
    "                ],\n",
    "                \"Finance\": [\n",
    "                    \"Fraud Detection Software\",\n",
    "                    \"Automated Trading Systems\",\n",
    "                    \"Personal Finance Apps\",\n",
    "                ],\n",
    "                \"Technology\": [\n",
    "                    \"Cloud Computing Platforms\",\n",
    "                    \"Artificial Intelligence and Machine Learning Platforms\",\n",
    "                    \"DevOps and CI/CD Tools\",\n",
    "                ],\n",
    "            },\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add SQL complexity with subcategory for SQL concepts\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"sql_complexity\",\n",
    "        sampler_type=SamplerType.CATEGORY,\n",
    "        params=CategorySamplerParams(\n",
    "            values=[\"Beginner\", \"Intermediate\", \"Advanced\"],\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add SQL concept as a subcategory of sql_complexity\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"sql_concept\",\n",
    "        sampler_type=SamplerType.SUBCATEGORY,\n",
    "        params=SubcategorySamplerParams(\n",
    "            category=\"sql_complexity\",\n",
    "            values={\n",
    "                \"Beginner\": [\n",
    "                    \"Basic SELECT Statements\",\n",
    "                    \"WHERE Clauses\",\n",
    "                    \"Basic JOINs\",\n",
    "                    \"INSERT, UPDATE, DELETE\",\n",
    "                ],\n",
    "                \"Intermediate\": [\n",
    "                    \"Aggregation Functions\",\n",
    "                    \"Multiple JOINs\",\n",
    "                    \"Subqueries\",\n",
    "                    \"Views\",\n",
    "                ],\n",
    "                \"Advanced\": [\n",
    "                    \"Window Functions\",\n",
    "                    \"Common Table Expressions (CTEs)\",\n",
    "                    \"Stored Procedures\",\n",
    "                    \"Query Optimization\",\n",
    "                ],\n",
    "            },\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add SQL task types\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"sql_task_type\",\n",
    "        sampler_type=SamplerType.CATEGORY,\n",
    "        params=CategorySamplerParams(\n",
    "            values=[\n",
    "                \"Data Retrieval\",\n",
    "                \"Data Manipulation\",\n",
    "                \"Analytics and Reporting\",\n",
    "                \"Data Transformation\",\n",
    "            ],\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add instruction phrases\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"instruction_phrase\",\n",
    "        sampler_type=SamplerType.CATEGORY,\n",
    "        params=CategorySamplerParams(\n",
    "            values=[\n",
    "                \"Write an SQL query that\",\n",
    "                \"Create an SQL statement to\",\n",
    "                \"Develop an SQL query to\",\n",
    "                \"Can you write SQL that\",\n",
    "                \"Formulate an SQL query that\",\n",
    "            ],\n",
    "        ),\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53082fe",
   "metadata": {},
   "source": [
    "## ü¶ú Define Generated Data Columns\n",
    "\n",
    "Now we'll set up the columns that will be generated by the LLMs, including the instruction, database context, and SQL implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a6f440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate instruction for the SQL query\n",
    "SQL_PROMPT_TEXT = (\n",
    "    \"Generate an instruction to create SQL code that solves a specific problem.\\n\"\n",
    "    \"Each instruction should begin with one of the following phrases: {{instruction_phrase}}.\\n\\n\"\n",
    "    \"Important Guidelines:\\n\"\n",
    "    \"* Industry Relevance: Ensure the instruction pertains to the {{industry_sector}} sector and {{topic}} topic.\\n\"\n",
    "    \"* SQL Complexity: Tailor the instruction to the {{sql_complexity}} level. Utilize relevant {{sql_concept}} \"\n",
    "    \"where appropriate to match the complexity level.\\n\"\n",
    "    \"* Task Type: The instruction should involve a {{sql_task_type}} task.\\n\"\n",
    "    \"* Clarity and Specificity: Make the problem statement clear and unambiguous. Provide sufficient context to \"\n",
    "    \"understand the requirements without being overly verbose.\\n\"\n",
    "    \"* Response Formatting: Do not include any markers such as ### Response ### in the instruction.\\n\"\n",
    ")\n",
    "\n",
    "config_builder.add_column(\n",
    "    LLMTextColumnConfig(\n",
    "        name=\"sql_prompt\",\n",
    "        model_alias=MODEL_ALIAS,\n",
    "        system_prompt=\"You are an expert at generating clear and specific SQL tasks.\",\n",
    "        prompt=SQL_PROMPT_TEXT,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Generate database context\n",
    "SQL_CONTEXT_TEXT = (\n",
    "    \"Generate the SQL for creating database tables that would be relevant for the following instruction:\\n\"\n",
    "    \"Instruction: {{sql_prompt}}\\n\\n\"\n",
    "    \"Important Guidelines:\\n\"\n",
    "    \"* Relevance: Ensure all tables are directly related to the {{industry_sector}} sector and {{topic}} topic.\\n\"\n",
    "    \"* Completeness: Include all essential columns with appropriate data types, primary/foreign keys, and necessary constraints.\\n\"\n",
    "    \"* Realism: Use realistic table structures typical for the specified industry.\\n\"\n",
    "    \"* Executable SQL: Provide complete CREATE TABLE statements that can be run without modification.\\n\"\n",
    "    \"* Consistency: Use consistent naming conventions (e.g., snake_case for table and column names).\\n\"\n",
    "    \"* Sample Data: Include INSERT statements with sample data that makes sense for the tables (at least 5-10 rows per table).\"\n",
    ")\n",
    "\n",
    "config_builder.add_column(\n",
    "    LLMCodeColumnConfig(\n",
    "        name=\"sql_context\",\n",
    "        model_alias=MODEL_ALIAS,\n",
    "        code_lang=CodeLang.SQL_ANSI,\n",
    "        system_prompt=(\n",
    "            \"You are an expert SQL database designer who creates clean, efficient, and \"\n",
    "            \"well-structured database schemas.\"\n",
    "        ),\n",
    "        prompt=SQL_CONTEXT_TEXT,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Generate the SQL code\n",
    "SQL_CODE_TEXT = (\n",
    "    \"Write SQL code for the following instruction based on the provided database context:\\n\"\n",
    "    \"Instruction: {{sql_prompt}}\\n\\n\"\n",
    "    \"Database Context:\\n\"\n",
    "    \"{{sql_context}}\\n\\n\"\n",
    "    \"Important Guidelines:\\n\"\n",
    "    \"* Code Quality: Your SQL should be clean, complete, self-contained and accurate.\\n\"\n",
    "    \"* Code Validity: Please ensure that your SQL code is executable and does not contain any errors.\\n\"\n",
    "    \"* Context: Base your query on the provided database context. Only reference tables and columns that \"\n",
    "    \"exist in the context.\\n\"\n",
    "    \"* Complexity & Concepts: The SQL should be written at a {{sql_complexity}} level, making use of \"\n",
    "    \"concepts such as {{sql_concept}}.\\n\"\n",
    "    \"* Task Type: Ensure your solution implements the appropriate {{sql_task_type}} operation.\\n\"\n",
    "    \"* Comments: Include brief comments explaining the key parts of your query.\\n\"\n",
    ")\n",
    "\n",
    "config_builder.add_column(\n",
    "    LLMCodeColumnConfig(\n",
    "        name=\"sql\",\n",
    "        model_alias=MODEL_ALIAS,\n",
    "        code_lang=CodeLang.SQL_ANSI,\n",
    "        system_prompt=\"You are an expert SQL programmer who writes clean, efficient, and well-structured queries.\",\n",
    "        prompt=SQL_CODE_TEXT,\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc70bf",
   "metadata": {},
   "source": [
    "## üîç Quality Assessment: LLM-as-a-Judge\n",
    "\n",
    "When generating our synthetic dataset, we need to determine the quality of the generated data \\\n",
    "We use the LLM-as-a-Judge strategy to do this.\n",
    "\n",
    "To do so, we need to define the rubric that the LLM should use to assess generation quality along with a prompt\n",
    "that provides relavant instructions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bf1759",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_TO_SQL_JUDGE_TEMPLATE = \"\"\"\\\n",
    "You are an expert in SQL with deep knowledge of relational modeling, query semantics,\n",
    "and performance tuning across common dialects (e.g., PostgreSQL, MySQL, SQLite, SQL Server).\n",
    "You think critically about correctness, readability, and efficiency.\n",
    "\n",
    "Use the SQL Query Quality Rubric below to score the **Generated SQL Query** based on the INSTRUCTIONS.\n",
    "\n",
    "#### INSTRUCTIONS\n",
    "The Generated SQL Query should be a valid response to the Natural Language Prompt below\n",
    "\n",
    "Natural Language Prompt:\n",
    "{{ sql_prompt }}\n",
    "\n",
    "Database Context:\n",
    "{{ sql_context }}\n",
    "\n",
    "Generated SQL Query\n",
    "{{ sql }}\n",
    "\"\"\"\n",
    "\n",
    "sql_scoring = [\n",
    "    Score(\n",
    "        name=\"Relevance\",\n",
    "        description=\"Adherence to INSTRUCTIONS and CONTEXT\",\n",
    "        options={\n",
    "            \"4\": \"Perfectly meets all specified requirements.\",\n",
    "            \"3\": \"Meets most requirements with minor deviations.\",\n",
    "            \"2\": \"Moderate deviation from the instructions.\",\n",
    "            \"1\": \"Significant deviations from the instructions.\",\n",
    "            \"0\": \"Does not adhere to the instructions.\",\n",
    "        },\n",
    "    ),\n",
    "    Score(\n",
    "        name=\"SQL Correctness\",\n",
    "        description=\"Syntax and semantic correctness; returns the intended result\",\n",
    "        options={\n",
    "            \"4\": \"Valid SQL with correct joins, filters, grouping/aggregation, and NULL handling; produces the intended result set under the stated/implicit dialect.\",\n",
    "            \"3\": \"Generally correct with minor issues (e.g., edge-case NULLs, minor grouping detail) but still likely yields the intended result.\",\n",
    "            \"2\": \"Partially correct; noticeable semantic mistakes (joins, grouping, filters) that may change results or fail in edge cases.\",\n",
    "            \"1\": \"Largely incorrect; major semantic or syntactic errors likely causing failure or wrong results.\",\n",
    "            \"0\": \"Invalid SQL or unrelated to the task; will not run or cannot produce a meaningful result.\",\n",
    "        },\n",
    "    ),\n",
    "    Score(\n",
    "        name=\"Readability\",\n",
    "        description=\"Formatting, clarity, and maintainability\",\n",
    "        options={\n",
    "            \"4\": \"Cleanly formatted (keywords/clauses consistently styled), clear structure (CTEs/subqueries where helpful), meaningful table/column aliases, and concise.\",\n",
    "            \"3\": \"Generally readable with consistent formatting and understandable aliases; could be organized slightly better.\",\n",
    "            \"2\": \"Somewhat readable but inconsistent formatting or confusing aliasing; structure is harder to follow.\",\n",
    "            \"1\": \"Poorly formatted and hard to read; unclear structure and aliasing.\",\n",
    "            \"0\": \"Unreadable or chaotic; no meaningful structure or styling.\",\n",
    "        },\n",
    "    ),\n",
    "    Score(\n",
    "        name=\"Efficiency\",\n",
    "        description=\"Query performance best practices\",\n",
    "        options={\n",
    "            \"4\": \"Uses sargable predicates, appropriate joins, selective filters early, avoids SELECT *, unnecessary DISTINCT, and wasteful subqueries; likely to use indexes effectively.\",\n",
    "            \"3\": \"Mostly efficient; minor opportunities for improvement (e.g., simplifying expressions, reducing data early).\",\n",
    "            \"2\": \"Moderate inefficiencies (e.g., non-sargable filters, unnecessary nested subqueries, broad SELECT *).\",\n",
    "            \"1\": \"Notably inefficient patterns likely causing large scans or poor plans.\",\n",
    "            \"0\": \"Highly inefficient; ignores basic best practices and likely to perform very poorly.\",\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Add an LLM judge to evaluate code quality\n",
    "config_builder.add_column(\n",
    "    LLMJudgeColumnConfig(\n",
    "        name=\"code_judge_result\",\n",
    "        model_alias=MODEL_ALIAS,\n",
    "        prompt=TEXT_TO_SQL_JUDGE_TEMPLATE,\n",
    "        scores=sql_scoring,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74581e0f",
   "metadata": {},
   "source": [
    "## ‚ö°Ô∏è Quality Assessment: Code Validation\n",
    "\n",
    "- Now we'll add validation for the initial code and generate analysis of any issues found.\n",
    "\n",
    "- NeMo Data Designer includes a built-in code validation feature that automatically checks the syntactic correctness and executable validity of \\\n",
    "  generated code snippets.\n",
    "\n",
    "- This helps ensure that outputs from language models are not only syntactically correct, but also able to run successfully in the \\\n",
    "  intended programming language environment.\n",
    "\n",
    "- Leveraging this validation step significantly increases dataset quality by promptly identifying invalid or non-functional code, \\\n",
    "  streamlining the process of generating reliable and production-ready data samples.\n",
    "\n",
    "- NeMo Data Designer supports validation for these languages\n",
    "\n",
    "  - Python (CodeLang.PYTHON)\n",
    "\n",
    "  - SQL dialects:\n",
    "\n",
    "    - ANSI SQL (CodeLang.SQL_ANSI)\n",
    "\n",
    "    - MySQL (CodeLang.SQL_MYSQL)\n",
    "\n",
    "    - PostgreSQL (CodeLang.SQL_POSTGRES)\n",
    "\n",
    "    - SQLite (CodeLang.SQL_SQLITE)\n",
    "\n",
    "    - T-SQL (CodeLang.SQL_TSQL)\n",
    "\n",
    "    - BigQuery (CodeLang.SQL_BIGQUERY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917f73fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_builder.add_column(\n",
    "    ValidationColumnConfig(\n",
    "        name=\"code_validity_result\",\n",
    "        validator_type=ValidatorType.CODE,\n",
    "        target_columns=[\"sql\"],\n",
    "        validator_params=CodeValidatorParams(\n",
    "            code_lang=CodeLang.SQL_ANSI,\n",
    "        ),\n",
    "        batch_size=100,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6143ad",
   "metadata": {},
   "source": [
    "### üîÅ Iteration is key ‚Äì¬†preview the dataset!\n",
    "\n",
    "1. Use the `preview` method to generate a sample of records quickly.\n",
    "\n",
    "2. Inspect the results for quality and format issues.\n",
    "\n",
    "3. Adjust column configurations, prompts, or parameters as needed.\n",
    "\n",
    "4. Re-run the preview until satisfied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca2cba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview a few records\n",
    "preview = data_designer_client.preview(config_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd5bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More previews\n",
    "preview.display_sample_record()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770dcebb",
   "metadata": {},
   "source": [
    "### üìä Analyze the generated data\n",
    "\n",
    "- Data Designer automatically generates a basic statistical analysis of the generated data.\n",
    "\n",
    "- This analysis is available via the `analysis` property of generation result objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c38751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the analysis as a table.\n",
    "preview.analysis.to_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c443e961",
   "metadata": {},
   "source": [
    "### üÜô Scale up!\n",
    "\n",
    "- Happy with your preview data?\n",
    "\n",
    "- Use the `create` method to submit larger Data Designer generation jobs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaf4104",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_results = data_designer_client.create(config_builder, num_records=20)\n",
    "\n",
    "# This will block until the job is complete.\n",
    "job_results.wait_until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f670392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the generated dataset as a pandas DataFrame.\n",
    "dataset = job_results.load_dataset()\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85251bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the analysis results into memory.\n",
    "analysis = job_results.load_analysis()\n",
    "\n",
    "analysis.to_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dddbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUTORIAL_OUTPUT_PATH = \"data-designer-tutorial-output\"\n",
    "\n",
    "# Download the job artifacts and save them to disk.\n",
    "job_results.download_artifacts(\n",
    "    output_path=TUTORIAL_OUTPUT_PATH,\n",
    "    artifacts_folder_name=\"artifacts-community-contributions-text-to-code-text-to-sql\",\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdg_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
