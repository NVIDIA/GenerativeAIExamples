{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8f02ab",
   "metadata": {},
   "source": [
    "# üé® NeMo Data Designer: Product Information Dataset Generator with Q&A\n",
    "\n",
    "> ‚ö†Ô∏è **Warning**: NeMo Data Designer is currently in Early Release and is not recommended for production use.\n",
    "\n",
    "#### üìö What you'll learn\n",
    "\n",
    "This notebook demonstrates how to use NeMo Data Designer to create a synthetic dataset of product information with corresponding questions and answers. \n",
    "\n",
    "<br>\n",
    "\n",
    "> üëã **IMPORTANT** ‚Äì¬†Environment Setup\n",
    ">\n",
    "> - If you haven't already, follow the instructions in the [README](../../../README.md) to install the necessary dependencies.\n",
    ">\n",
    "> - You may need to restart your notebook's kernel after setting up the environment.\n",
    "> - In this notebook, we assume you have a self-hosted instance of Data Designer up and running.\n",
    ">\n",
    "> - For deployment instructions, see the [Installation Options](https://docs.nvidia.com/nemo/microservices/latest/design-synthetic-data-from-scratch-or-seeds/index.html#installation-options) section of the [NeMo Data Designer documentation](https://docs.nvidia.com/nemo/microservices/latest/design-synthetic-data-from-scratch-or-seeds/index.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136d3c6f",
   "metadata": {},
   "source": [
    "### üì¶ Import the essentials\n",
    "\n",
    "- The `data_designer` module of `nemo_microservices` exposes Data Designer's high-level SDK.\n",
    "\n",
    "- The `essentials` module provides quick access to the most commonly used objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0914a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo_microservices.data_designer.essentials import (\n",
    "    BernoulliSamplerParams,\n",
    "    CategorySamplerParams,\n",
    "    DataDesignerConfigBuilder,\n",
    "    ExpressionColumnConfig,\n",
    "    InferenceParameters,\n",
    "    LLMJudgeColumnConfig,\n",
    "    LLMStructuredColumnConfig,\n",
    "    LLMTextColumnConfig,\n",
    "    ModelConfig,\n",
    "    NeMoDataDesignerClient,\n",
    "    SamplerColumnConfig,\n",
    "    SamplerType,\n",
    "    Score,\n",
    "    UniformSamplerParams,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c17dedd",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Initialize the NeMo Data Designer Client\n",
    "\n",
    "- `NeMoDataDesignerClient` is responsible for submitting generation requests to the microservice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe4b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEMO_MICROSERVICES_BASE_URL = \"http://localhost:8080\"\n",
    "\n",
    "data_designer_client = NeMoDataDesignerClient(base_url=NEMO_MICROSERVICES_BASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a0b816",
   "metadata": {},
   "source": [
    "### üéõÔ∏è Define model configurations\n",
    "\n",
    "- Each `ModelConfig` defines a model that can be used during the generation process.\n",
    "\n",
    "- The \"model alias\" is used to reference the model in the Data Designer config (as we will see below).\n",
    "\n",
    "- The \"model provider\" is the external service that hosts the model (see [the model config docs](https://docs.nvidia.com/nemo/microservices/latest/design-synthetic-data-from-scratch-or-seeds/configure-models.html) for more details).\n",
    "\n",
    "- By default, the microservice uses [build.nvidia.com](https://build.nvidia.com/models) as the model provider.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f699cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This name is set in the microservice deployment configuration.\n",
    "MODEL_PROVIDER = \"nvidiabuild\"\n",
    "\n",
    "# The model ID is from build.nvidia.com.\n",
    "MODEL_ID = \"nvidia/nvidia-nemotron-nano-9b-v2\"\n",
    "\n",
    "# We choose this alias to be descriptive for our use case.\n",
    "MODEL_ALIAS = \"nemotron-nano-v2\"\n",
    "\n",
    "# This sets reasoning to False for the nemotron-nano-v2 model.\n",
    "SYSTEM_PROMPT = \"/no_think\"\n",
    "\n",
    "model_configs = [\n",
    "    ModelConfig(\n",
    "        alias=MODEL_ALIAS,\n",
    "        model=MODEL_ID,\n",
    "        provider=MODEL_PROVIDER,\n",
    "        inference_parameters=InferenceParameters(\n",
    "            temperature=0.6,\n",
    "            top_p=0.95,\n",
    "            max_tokens=1024,\n",
    "        ),\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1d247a",
   "metadata": {},
   "source": [
    "### üèóÔ∏è Initialize the Data Designer Config Builder\n",
    "\n",
    "- The Data Designer config defines the dataset schema and generation process.\n",
    "\n",
    "- The config builder provides an intuitive interface for building this configuration.\n",
    "\n",
    "- The list of model configs is provided to the builder at initialization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1409dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_builder = DataDesignerConfigBuilder(model_configs=model_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedb3311",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Defining Data Structures\n",
    "\n",
    "Now we'll define the data models and evaluation rubrics for our product information dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc61c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from pydantic import BaseModel\n",
    "from pydantic import Field\n",
    "\n",
    "# Define product information structure\n",
    "class ProductInfo(BaseModel):\n",
    "  product_name: str = Field(..., description=\"A realistic product name for the market.\")\n",
    "  key_features: list[str] = Field(..., min_length=1, max_length=3, description=\"Key product features.\")\n",
    "  description: str = Field(..., description=\"A short, engaging description of what the product does, highlighting a unique but believable feature.\")\n",
    "  price_usd: float = Field(..., description=\"The stated price in USD.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed416ec",
   "metadata": {},
   "source": [
    "## üé≤ Adding Sampler Columns\n",
    "\n",
    "- Sampler columns offer non-LLM based generation of synthetic data.\n",
    "\n",
    "- They are particularly useful for **steering the diversity** of the generated data, as we demonstrate below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd01cc94-6268-4aac-9e69-a57ef8c9bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define product category options\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"category\",\n",
    "        sampler_type=SamplerType.CATEGORY,\n",
    "        params=CategorySamplerParams(values=[\n",
    "                \"Electronics\",\n",
    "                \"Clothing\",\n",
    "                \"Home Appliances\",\n",
    "                \"Groceries\",\n",
    "                \"Toiletries\",\n",
    "                \"Sports Equipment\",\n",
    "                \"Toys\",\n",
    "                \"Books\",\n",
    "                \"Pet Supplies\",\n",
    "                \"Tools & Home Improvement\",\n",
    "                \"Beauty\",\n",
    "                \"Health & Wellness\",\n",
    "                \"Outdoor Gear\",\n",
    "                \"Automotive\",\n",
    "                \"Jewelry\",\n",
    "                \"Watches\",\n",
    "                \"Office Supplies\",\n",
    "                \"Gifts\",\n",
    "                \"Arts & Crafts\",\n",
    "                \"Baby & Kids\",\n",
    "                \"Music\",\n",
    "                \"Video Games\",\n",
    "                \"Movies\",\n",
    "                \"Software\",\n",
    "                \"Tech Devices\",\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Define price range to seed realistic product types\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"price_tens_of_dollars\",\n",
    "        sampler_type=SamplerType.UNIFORM,\n",
    "        params=UniformSamplerParams(low=1, high=200),\n",
    "    )\n",
    ")\n",
    "\n",
    "config_builder.add_column(\n",
    "    ExpressionColumnConfig(\n",
    "        name=\"product_price\",\n",
    "        expr=\"{{ (price_tens_of_dollars * 10) - 0.01 | round(2) }}\",\n",
    "        dtype=\"float\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Generate first letter for product name to ensure diversity\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"first_letter\",\n",
    "        sampler_type=SamplerType.CATEGORY,\n",
    "        params=CategorySamplerParams(values=list(string.ascii_uppercase)),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Determine if this example will include hallucination\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"is_hallucination\",\n",
    "        sampler_type=SamplerType.BERNOULLI,\n",
    "        params=BernoulliSamplerParams(p=0.5),\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b2669",
   "metadata": {},
   "source": [
    "## ü¶ú LLM-generated columns\n",
    "\n",
    "- When prompting the LLM, we can use Jinja templating to reference other columns in the dataset.\n",
    "\n",
    "- As we see below, nested json fields can be accessed using dot notation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d59972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate product information\n",
    "config_builder.add_column(\n",
    "    LLMStructuredColumnConfig(\n",
    "        name=\"product_info\",\n",
    "        model_alias=MODEL_ALIAS,\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "        prompt=(\n",
    "            \"Generate a realistic product description for a product in the {{ category }} \"\n",
    "            \"category that costs {{ product_price }}.\\n\"\n",
    "            \"The name of the product MUST start with the letter {{ first_letter }}.\\n\"\n",
    "            ),\n",
    "        output_format=ProductInfo,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Generate user questions about the product\n",
    "config_builder.add_column(\n",
    "    LLMTextColumnConfig(\n",
    "        name=\"question\",\n",
    "        model_alias=MODEL_ALIAS,\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "        prompt=(\"Ask a question about the following product:\\n\\n {{ product_info }}\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Generate answers to the questions\n",
    "config_builder.add_column(\n",
    "    LLMTextColumnConfig(\n",
    "        name=\"answer\",\n",
    "        model_alias=MODEL_ALIAS,\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "        prompt=(\n",
    "            \"{%- if is_hallucination == 0 -%}\\n\"\n",
    "            \"<product_info>\\n\"\n",
    "            \"{{ product_info }}\\n\"\n",
    "            \"</product_info>\\n\"\n",
    "\n",
    "            \"{%- endif -%}\\n\"\n",
    "            \"User Question: {{ question }}\\n\"\n",
    "\n",
    "            \"Directly and succinctly answer the user's question.\\n\"\n",
    "            \"{%- if is_hallucination == 1 -%}\\n\"\n",
    "            \"Make up whatever information you need to in order to answer the user's request.\\n\"\n",
    "            \"{%- endif -%}\"\n",
    "            ),\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c9c108",
   "metadata": {},
   "source": [
    "## üîç Quality Assessment: LLM-as-a-Judge\n",
    "\n",
    "When generating our synthetic dataset, we need to determine the quality of the generated data \\\n",
    "We use the LLM-as-a-Judge strategy to do this. \n",
    "\n",
    "To do so, we need to define the rubric that the LLM should use to assess generation quality along with a prompt \n",
    "that provides relavant instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ab3e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation rubrics for answer quality\n",
    "CompletenessRubric = Score(\n",
    "    name=\"Completeness\",\n",
    "    description=\"Evaluation of AI assistant's thoroughness in addressing all aspects of the user's query.\",\n",
    "    options={\n",
    "        \"Complete\": \"The response thoroughly covers all key points requested in the question, providing sufficient detail to satisfy the user's information needs.\",\n",
    "        \"PartiallyComplete\": \"The response addresses the core question but omits certain important details or fails to elaborate on relevant aspects that were requested.\",\n",
    "        \"Incomplete\": \"The response significantly lacks necessary information, missing major components of what was asked and leaving the query largely unanswered.\",\n",
    "    }\n",
    ")\n",
    "\n",
    "AccuracyRubric = Score(\n",
    "    name=\"Accuracy\",\n",
    "    description=\"Evaluation of how factually correct the AI assistant's response is relative to the product information.\",\n",
    "    options={\n",
    "        \"Accurate\": \"The information provided aligns perfectly with the product specifications without introducing any misleading or incorrect details.\",\n",
    "        \"PartiallyAccurate\": \"While some information is correctly stated, the response contains minor factual errors or potentially misleading statements about the product.\",\n",
    "        \"Inaccurate\": \"The response presents significantly wrong information about the product, with claims that contradict the actual product details.\",\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate answer quality\n",
    "config_builder.add_column(\n",
    "    LLMJudgeColumnConfig(\n",
    "        name=\"llm_answer_metrics\",\n",
    "        model_alias=MODEL_ALIAS,\n",
    "        prompt=(\n",
    "            \"<product_info>\\n\"\n",
    "            \"{{ product_info }}\\n\"\n",
    "            \"</product_info>\\n\"\n",
    "\n",
    "            \"User Question: {{question }}\\n\"\n",
    "            \"AI Assistant Answer: {{ answer }}\\n\"\n",
    "\n",
    "            \"Judge the AI assistant's response to the user's question about the product described in <product_info>.\"\n",
    "        ),\n",
    "        scores=[CompletenessRubric, AccuracyRubric],\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Extract metric scores for easier analysis\n",
    "config_builder.add_column(\n",
    "    ExpressionColumnConfig(\n",
    "        name=\"completeness_result\",\n",
    "        expr=\"{{ llm_answer_metrics.completeness.score }}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "config_builder.add_column(\n",
    "    ExpressionColumnConfig(\n",
    "        name=\"accuracy_result\",\n",
    "        expr=\"{{ llm_answer_metrics.accuracy.score }}\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c605da",
   "metadata": {},
   "source": [
    "### üîÅ Iteration is key ‚Äì¬†preview the dataset!\n",
    "\n",
    "1. Use the `preview` method to generate a sample of records quickly.\n",
    "\n",
    "2. Inspect the results for quality and format issues.\n",
    "\n",
    "3. Adjust column configurations, prompts, or parameters as needed.\n",
    "\n",
    "4. Re-run the preview until satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9909090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview a few records\n",
    "preview = data_designer_client.preview(config_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28be08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More previews\n",
    "preview.display_sample_record()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d9e59d",
   "metadata": {},
   "source": [
    "### üìä Analyze the generated data\n",
    "\n",
    "- Data Designer automatically generates a basic statistical analysis of the generated data.\n",
    "\n",
    "- This analysis is available via the `analysis` property of generation result objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b257d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the analysis as a table.\n",
    "preview.analysis.to_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae79c08",
   "metadata": {},
   "source": [
    "### üÜô Scale up!\n",
    "\n",
    "- Happy with your preview data?\n",
    "\n",
    "- Use the `create` method to submit larger Data Designer generation jobs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374280bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_results = data_designer_client.create(config_builder, num_records=20)\n",
    "\n",
    "# This will block until the job is complete.\n",
    "job_results.wait_until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e7e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the generated dataset as a pandas DataFrame.\n",
    "dataset = job_results.load_dataset()\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245cb8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the analysis results into memory.\n",
    "analysis = job_results.load_analysis()\n",
    "\n",
    "analysis.to_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7336dd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUTORIAL_OUTPUT_PATH = \"data-designer-tutorial-output\"\n",
    "\n",
    "# Download the job artifacts and save them to disk.\n",
    "job_results.download_artifacts(\n",
    "    output_path=TUTORIAL_OUTPUT_PATH,\n",
    "    artifacts_folder_name=\"artifacts-community-contributions-qa-generation-product-question-answer-generator\",\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sdg_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
