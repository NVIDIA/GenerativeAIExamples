{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üé® NeMo Data Designer: Synthetic Reasoning Traces"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a9521867",
            "metadata": {},
            "source": [
                "> ‚ö†Ô∏è **Warning**: NeMo Data Designer is current in Early Release and is not recommended for production use.\n",
                ">\n",
                "> **Note**: In order to run this notebook, you must have the NeMo Data Designer microservice deployed locally via docker compose. See the [deployment guide](http://docs.nvidia.com/nemo/microservices/latest/set-up/deploy-as-microservices/data-designer/docker-compose.html) for more details.\n",
                ">\n",
                "> Alternatively, you can use the [NeMo Data Designer managed service](https://build.nvidia.com/nemo/data-designer). Please refer the [intro-tutorials](../../intro-tutorials/1-the-basics.ipynb) on how to connect to it. \n",
                ">\n",
                "> **Note**: If you are using the NeMo Data Designer managed service, you will only be able to launch preview jobs. You will not be able to launch jobs using the `create` method."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This notebook demonstrates how to use NeMo Data Designer to build a synthetic data generation pipeline tailored for reasoning tasks. Instead of creating multi-turn conversations, we will generate reasoning traces that can be utilized for training and fine-tuning language models with reinforcement learning techniques and invoking chain-of-thought processing.\n",
                "\n",
                "These synthetic reasoning traces can be used to enhance model performance in areas such as mathematics, coding, scientific reasoning, and other domains that benefit from structured reasoning."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ea340547",
            "metadata": {},
            "source": [
                "#### üíæ Install dependencies\n",
                "\n",
                "**IMPORTANT** üëâ If you haven't already, follow the instructions in the [README](../../README.md) to install the necessary dependencies. Note you may need to restart your kernel after setting up the environment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6b395aa4",
            "metadata": {},
            "outputs": [],
            "source": [
                "from nemo_microservices import NeMoMicroservices\n",
                "from nemo_microservices.beta.data_designer import (\n",
                "    DataDesignerConfigBuilder,\n",
                "    DataDesignerClient,\n",
                ")\n",
                "from nemo_microservices.beta.data_designer.config import columns as C\n",
                "from nemo_microservices.beta.data_designer.config import params as P"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "19048f79",
            "metadata": {},
            "source": [
                "### ‚öôÔ∏è Initialize the NeMo Data Designer Client\n",
                "\n",
                "- The data designer client is responsible for submitting generation requests to the Data Designer microservice.\n",
                "- In this notebook, we connect to a local deployment of data designer. You can deploy your own instance of data designer by following the deployment instructions [here](https://docs.nvidia.com/nemo/microservices/latest/set-up/deploy-as-microservices/data-designer/docker-compose.html).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "43880183",
            "metadata": {},
            "outputs": [],
            "source": [
                "data_designer_client = DataDesignerClient(client=NeMoMicroservices(base_url=\"http://localhost:8080\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "01fc96fb",
            "metadata": {},
            "source": [
                "### üèóÔ∏è Initialize the Data Designer Config Builder\n",
                "\n",
                "- The Data Designer config defines the dataset schema and generation process.\n",
                "\n",
                "- The config builder provides an intuitive interface for building this configuration.\n",
                "\n",
                "- You must provide a list of model configs to the builder at initialization.\n",
                "\n",
                "- This list contains the models you can choose from (via the `model_alias` argument) during the generation process.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1eacb024",
            "metadata": {},
            "outputs": [],
            "source": [
                "# We specify the endpoint of the model during deployment using the model_provider_registry.\n",
                "model_id = \"nvidia/nvidia-nemotron-nano-9b-v2\"\n",
                "model_alias = \"nemotron-nano-9b-v2\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b97f239f",
            "metadata": {},
            "outputs": [],
            "source": [
                "config_builder = DataDesignerConfigBuilder(\n",
                "    model_configs=[\n",
                "        P.ModelConfig(\n",
                "            alias=model_alias,\n",
                "            provider=\"nvidiabuild\",\n",
                "            model=model_id,\n",
                "            inference_parameters=P.InferenceParameters(\n",
                "                max_tokens=1024,\n",
                "                temperature=0.6,\n",
                "                top_p=0.95,\n",
                "            ),\n",
                "            is_reasoner=True\n",
                "        ),\n",
                "    ]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üå± Adding Categorical Seed Columns\n",
                "\n",
                "Define categorical seed columns that set the context for the generated empathic reasoning traces. For example, domain and theme determine the type of everyday scenario where empathy is crucial, while complexity guides the depth of emotional insight and detailed support."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a domain column that sets the context for empathic scenarios in everyday life.\n",
                "config_builder.add_column(\n",
                "    name=\"domain\",\n",
                "    type=\"category\",\n",
                "    params={\n",
                "        \"values\": [\n",
                "            \"Family Dynamics\",\n",
                "            \"Workplace Challenges\",\n",
                "            \"Friendship Moments\",\n",
                "            \"Community Interactions\",\n",
                "            \"Personal Well-being\",\n",
                "            \"Unexpected Encounters\"\n",
                "        ]\n",
                "    }\n",
                ")\n",
                "\n",
                "# Add theme subcategories for each domain\n",
                "config_builder.add_column(\n",
                "    name=\"theme\",\n",
                "    type=\"subcategory\",\n",
                "    params={\n",
                "        \"category\": \"domain\",\n",
                "        \"values\": {\n",
                "            \"Family Dynamics\": [\n",
                "                \"Parenting Dilemmas\",\n",
                "                \"Sibling Rivalries\"\n",
                "            ],\n",
                "            \"Workplace Challenges\": [\n",
                "                \"Communication Breakdowns\",\n",
                "                \"Leadership Dilemmas\"\n",
                "            ],\n",
                "            \"Friendship Moments\": [\n",
                "                \"Support & Understanding\",\n",
                "                \"Misunderstandings & Reconciliations\"\n",
                "            ],\n",
                "            \"Community Interactions\": [\n",
                "                \"Neighborhood Support\",\n",
                "                \"Cultural Celebrations\"\n",
                "            ],\n",
                "            \"Personal Well-being\": [\n",
                "                \"Mental Health\",\n",
                "                \"Self-care & Reflection\"\n",
                "            ],\n",
                "            \"Unexpected Encounters\": [\n",
                "                \"Serendipitous Meetings\",\n",
                "                \"Moments of Realization\"\n",
                "            ]\n",
                "        }\n",
                "    }\n",
                ")\n",
                "\n",
                "# Define a complexity column to guide the level of detail and challenge in the empathic scenarios.\n",
                "config_builder.add_column(\n",
                "    name=\"complexity\",\n",
                "    type=\"category\",\n",
                "    params={\n",
                "        \"values\": [\"Basic\", \"Intermediate\", \"Advanced\"]\n",
                "    }\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ‚ú® Adding Generated Data Columns\n",
                "\n",
                "Define the columns that the model will generate. These prompts instruct the LLM to produce the actual empathic reasoning trace and answer, following the specified format with <think> and <answer> tags.\n",
                "\n",
                "#### Empathic Reasoning Trace Generation\n",
                "\n",
                "This column is designed to generate clear, thoughtful reasoning traces that blend logical analysis with emotional insight for everyday situations where empathy is crucial. The generation prompt is tailored to:\n",
                "- Produce a structured explanation that highlights both the practical reasoning and the emotional dynamics at play.\n",
                "- Encourage a dual output: one part detailing the empathic thought process (enclosed within `<think>` tags) and another delivering a compassionate final answer (enclosed within `<answer>` tags).\n",
                "- Ensure that the generated content reflects deep understanding, compassion, and a balanced view of the challenges and emotions involved."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "special_system_instructions = \"\"\"\n",
                "You are an empathic reasoning agent. Your task is to generate realistic and compassionate reasoning traces for common day-to-day situations. Adopt a caring and supportive tone as you provide detailed insights into human experiences and emotions.\n",
                "- Focus on everyday scenarios where empathy, understanding, and emotional intelligence are key.\n",
                "- Consider various perspectives, emphasizing the emotional impact of actions and decisions.\n",
                "- Ensure your reasoning process is clear, structured, and heartfelt, reflecting deep care for the individuals involved.\n",
                "- Enclose your thoughtful reasoning process within <think>...</think> tags before providing the final JSON output.\n",
                "\"\"\"\n",
                "\n",
                "config_builder.add_column(\n",
                "    name=\"scenario\",\n",
                "    type=\"llm-text\",\n",
                "    model_alias=model_alias,\n",
                "    system_prompt=special_system_instructions,\n",
                "    prompt=(\n",
                "        \"Generate a clear and concise everyday scenario for the {{domain}} domain, theme {{theme}}, and complexity {{complexity}}, \"\n",
                "        \"where empathy and understanding play a crucial role. Focus on a situation that highlights emotional challenges or opportunities for compassionate support, and include a specific question or request for help that clearly outlines a problem or challenge needing resolution.\\n\\n\"\n",
                "        \"Guidelines:\\n\"\n",
                "        \"- Provide only the scenario statement without any additional metadata, solution steps, or internal commentary.\\n\"\n",
                "        \"- Use everyday language and incorporate realistic, practical context from an empathic perspective.\\n\"\n",
                "        \"- Ensure the scenario includes a clear follow-up question or request for assistance, making it apparent what the problem or challenge is.\\n\"\n",
                "        \"- Do not include any formatting tags or markers.\\n\\n\"\n",
                "        \"Examples:\\n\"\n",
                "        \"1. 'Imagine a situation where a friend is visibly upset after a long, challenging day. What might be causing their distress, and how could you offer support?'\\n\"\n",
                "        \"2. 'Consider a moment at a family dinner where a subtle conflict arises between members. What could be the underlying issue, and how might empathy help mend the situation?'\\n\"\n",
                "        \"3. 'Picture a colleague receiving unexpected criticism during a meeting. What are the potential emotional impacts, and what supportive response could be helpful?'\\n\"\n",
                "    )\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Empathic Reasoning Process Generation\n",
                "\n",
                "These columns generate and evaluate a detailed empathic reasoning trace for addressing everyday scenarios. The process emphasizes a compassionate, thoughtful approach that blends logical reasoning with emotional insight. The prompts instruct the model to include its internal thought process within <think>...</think> tags before providing the JSON output."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import List\n",
                "from pydantic import BaseModel, Field\n",
                "\n",
                "class Thought(BaseModel):\n",
                "    \"\"\"A single step in the structured empathic reasoning process.\n",
                "    This step captures an empathetic observation or insight that informs a thoughtful, compassionate approach to addressing everyday challenges.\n",
                "    \"\"\"\n",
                "    step_number: int = Field(..., ge=1, description=\"The order of the reasoning step, starting from 1.\")\n",
                "    content: str = Field(..., min_length=5, description=\"A detailed explanation of this reasoning step, incorporating both logical analysis and emotional insight.\")\n",
                "\n",
                "class ReasoningTrace(BaseModel):\n",
                "    \"\"\"A structured empathic reasoning trace for addressing a scenario.\n",
                "    This model records a step-by-step process that integrates logical analysis with emotional insight and empathy to arrive at a supportive final answer.\n",
                "    \"\"\"\n",
                "    reasoning: List[Thought] = Field(..., description=\"Step-by-step reasoning leading to the final answer, enriched with empathetic observations and practical insights.\")\n",
                "    answer: str = Field(..., description=\"The final answer derived from the empathic reasoning process, offering compassionate guidance or resolution.\")\n",
                "\n",
                "class Evaluation(BaseModel):\n",
                "    \"\"\"Output format for evaluating an empathic reasoning answer.\n",
                "    The evaluation assesses the response based on correctness, clarity, and completeness,\n",
                "    with feedback that emphasizes compassionate insight, clarity, and a holistic understanding of the scenario.\n",
                "    \"\"\"\n",
                "    correctness: float = Field(..., description=\"Overall correctness rating of the answer (0 to 1).\")\n",
                "    clarity: float = Field(..., description=\"Clarity rating of the reasoning, including the integration of empathic explanations (0 to 1).\")\n",
                "    completeness: float = Field(..., description=\"Completeness rating of the reasoning, assessing whether all practical and emotional aspects were considered (0 to 1).\")\n",
                "    feedback: str = Field(..., description=\"Detailed feedback on the reasoning trace and answer, with suggestions for enhancing empathetic and real-world applicability.\")\n",
                "\n",
                "class FinalEvaluation(Evaluation):\n",
                "    \"\"\"Extended evaluation model for final empathic reasoning traces.\n",
                "    This model adds criteria to assess visual structure and conciseness,\n",
                "    ensuring the final output is both clear and visually appealing.\n",
                "    \"\"\"\n",
                "    structure: float = Field(...,  description=\"Rating of the visual structure and formatting (0 to 1), assessing if reasoning steps and final answer are clearly delineated.\")\n",
                "    conciseness: float = Field(..., description=\"Rating of the conciseness of the reasoning trace (0 to 1), ensuring that extraneous verbosity is minimized.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config_builder.add_column(\n",
                "    name=\"initial_trace\",\n",
                "    type=\"llm-structured\",\n",
                "    model_alias=model_alias,\n",
                "    prompt=(\n",
                "        \"You are an empathic reasoning agent. Provide a detailed, step-by-step reasoning process that thoughtfully addresses the following scenario. \"\n",
                "        \"Begin by outlining your internal thought process, focusing on both logical considerations and emotional insights, enclosed within <think>...</think> tags. \"\n",
                "        \"Then, provide your final compassionate answer.\\n\\n\"\n",
                "        \"Scenario: {{scenario}}\\n\\n\"\n",
                "        \"Ensure that your response is structured and reflective of a supportive, empathetic approach.\"\n",
                "    ),\n",
                "    output_format=ReasoningTrace\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config_builder.add_column(\n",
                "    name=\"initial_trace_evaluation\",\n",
                "    type=\"llm-structured\",\n",
                "    model_alias=model_alias,\n",
                "    prompt=(\n",
                "        \"<initial_trace>{{initial_trace}}</initial_trace>\\n\\n\"\n",
                "        \"Now, analyze the provided empathic reasoning trace and final answer as if you were an insightful observer assessing both logical and compassionate approaches. \"\n",
                "        \"Evaluate the response with a focus on emotional insight, clarity, and holistic consideration.\\n\\n\"\n",
                "        \"Include your internal thought process within <think>...</think> tags before providing the JSON.\"\n",
                "    ),\n",
                "    output_format=Evaluation\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Final Empathic Reasoning Trace Generation and Evaluation\n",
                "\n",
                "These columns refine and evaluate the final empathic reasoning trace. The final trace is generated by reviewing the scenario, your initial empathic reasoning trace, and its evaluation. The process integrates improvements suggested by the evaluation and ensures that the final reasoning is compassionate, clear, and comprehensive. As always, include your internal thought process wrapped within <think>...</think> tags before providing the final JSON output."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config_builder.add_column(\n",
                "    name=\"final_trace\",\n",
                "    type=\"llm-structured\",\n",
                "    model_alias=model_alias,\n",
                "    prompt=(\n",
                "        \"Review the scenario, your initial empathic reasoning trace, and its evaluation:\\n\\n\"\n",
                "        \"Scenario: {{scenario}}\\n\\n\"\n",
                "        \"Initial Empathic Reasoning Trace:\\n{{initial_trace}}\\n\\n\"\n",
                "        \"Initial Trace Evaluation:\\n{{initial_trace_evaluation}}\\n\\n\"\n",
                "        \"From the perspective of an empathic reasoning agent, provide a refined final reasoning trace that addresses both the emotional and logical dimensions of the scenario. \"\n",
                "        \"Your final trace should be visually structured as follows:\\n\"\n",
                "        \"1. Present a numbered list of concise reasoning steps. Each step should be clear and free of unnecessary verbosity.\\n\"\n",
                "        \"2. Include a clearly separated section for the final answer, prefixed with a header (e.g., 'Final Answer:').\\n\"\n",
                "        \"3. Use visual markers or markdown formatting to enhance readability.\\n\"\n",
                "        \"Avoid adding extraneous details‚Äîfocus on clarity and conciseness.\\n\\n\"\n",
                "        \"Also, include your internal thought process wrapped within <think>...</think> tags. \"\n",
                "        \"Return only the final, visually structured reasoning trace.\"\n",
                "    ),\n",
                "    output_format=ReasoningTrace\n",
                ")\n",
                "\n",
                "config_builder.add_column(\n",
                "    name=\"final_trace_evaluation\",\n",
                "    type=\"llm-structured\",\n",
                "    model_alias=model_alias,\n",
                "    prompt=(\n",
                "        \"<final_trace>{{final_trace}}</final_trace>\\n\\n\"\n",
                "        \"Analyze the provided empathic reasoning trace and final answer from the viewpoint of an insightful observer. \"\n",
                "        \"Evaluate the response focusing on correctness, clarity, and completeness, as well as its visual structure and conciseness. \"\n",
                "        \"Assess whether the reasoning steps are clearly separated (e.g., numbered or bullet-pointed) and if the final answer is distinct and succinct.\\n\\n\"\n",
                "        \"Include your internal thought process within <think>...</think> tags before providing the JSON.\"\n",
                "    ),\n",
                "    output_format=FinalEvaluation\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üëÄ Generating a dataset preview\n",
                "\n",
                "- Preview mode allows you to quickly iterate on your data design.\n",
                "\n",
                "- Each preview generation call creates a sample for inspection, helping you verify prompts and instructions before running a larger batch job."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate a preview\n",
                "preview = data_designer_client.preview(config_builder, verbose_logging=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "preview.display_sample_record()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ü§î Like what you see?\n",
                "\n",
                "- Submit a batch workflow!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "job_results = data_designer_client.create(config_builder, num_records=20, wait_until_done=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check to see if the Workflow is still active.\n",
                "job_results.get_job_status()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset = job_results.load_dataset()\n",
                "dataset.head()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "sdg_venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
