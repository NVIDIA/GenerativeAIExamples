{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® NeMo Data Designer: Synthetic Conversational Data with Person Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575c7340",
   "metadata": {},
   "source": [
    "> ‚ö†Ô∏è **Warning**: NeMo Data Designer is current in Early Release and is not recommended for production use.\n",
    ">\n",
    "> **Note**: In order to run this notebook, you must have the NeMo Data Designer microservice deployed locally via docker compose. See the [deployment guide](http://docs.nvidia.com/nemo/microservices/latest/set-up/deploy-as-microservices/data-designer/docker-compose.html) for more details.\n",
    ">\n",
    "> Alternatively, you can use the [NeMo Data Designer managed service](https://build.nvidia.com/nemo/data-designer). Please refer the [intro-tutorials](../../intro-tutorials/1-the-basics.ipynb) on how to connect to it. \n",
    ">\n",
    "> **Note**: If you are using the NeMo Data Designer managed service, you will only be able to launch preview jobs. You will not be able to launch jobs using the `create` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use the NeMo Data Designer to build a synthetic data generation pipeline step-by-step. We will create multi-turn user-assistant dialogues tailored for fine-tuning language models, enhanced with realistic person details. These synthetic dialogues can then be used as domain-specific training data to improve model performance in targeted scenarios.\n",
    "\n",
    "These datasets could be used for developing and enhancing conversational AI applications, including customer support chatbots, virtual assistants, and interactive learning systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6343c223",
   "metadata": {},
   "source": [
    "#### üíæ Install dependencies\n",
    "\n",
    "**IMPORTANT** üëâ If you haven't already, follow the instructions in the [README](../../README.md) to install the necessary dependencies. Note you may need to restart your kernel after setting up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo_microservices import NeMoMicroservices\n",
    "from nemo_microservices.beta.data_designer import (\n",
    "    DataDesignerConfigBuilder,\n",
    "    DataDesignerClient,\n",
    ")\n",
    "from nemo_microservices.beta.data_designer.config import columns as C\n",
    "from nemo_microservices.beta.data_designer.config import params as P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7690c3",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Initialize the NeMo Data Designer Client\n",
    "\n",
    "- The data designer client is responsible for submitting generation requests to the Data Designer microservice.\n",
    "- In this notebook, we connect to a local deployment of data designer. You can deploy your own instance of data designer by following the deployment instructions [here](https://docs.nvidia.com/nemo/microservices/latest/set-up/deploy-as-microservices/data-designer/docker-compose.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ea201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_designer_client = DataDesignerClient(client=NeMoMicroservices(base_url=\"http://localhost:8080\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f99c1b",
   "metadata": {},
   "source": [
    "### üèóÔ∏è Initialize the Data Designer Config Builder\n",
    "\n",
    "- The Data Designer config defines the dataset schema and generation process.\n",
    "\n",
    "- The config builder provides an intuitive interface for building this configuration.\n",
    "\n",
    "- You must provide a list of model configs to the builder at initialization.\n",
    "\n",
    "- This list contains the models you can choose from (via the `model_alias` argument) during the generation process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b8e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We specify the endpoint of the model during deployment using the model_provider_registry.\n",
    "model_id = \"nvidia/nvidia-nemotron-nano-9b-v2\"\n",
    "model_alias = \"nemotron-nano-9b-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b6d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_builder = DataDesignerConfigBuilder(\n",
    "    model_configs=[\n",
    "        P.ModelConfig(\n",
    "            alias=model_alias,\n",
    "            provider=\"nvidiabuild\",\n",
    "            model=model_id,\n",
    "            inference_parameters=P.InferenceParameters(\n",
    "                max_tokens=1024,\n",
    "                temperature=0.6,\n",
    "                top_p=0.95,\n",
    "            ),\n",
    "            is_reasoner=True\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pydantic Models for Structured Outputs\n",
    "\n",
    "You can use Pydantic to define a structure for the messages that are produced by Data Designer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Message(BaseModel):\n",
    "    \"\"\"A single message turn in the conversation.\"\"\"\n",
    "    role: Literal[\"user\", \"assistant\"] = Field(..., description=\"Which role is writing the message.\")\n",
    "    content: str = Field(..., description=\"Message contents.\")\n",
    "\n",
    "\n",
    "class ChatConversation(BaseModel):\n",
    "    \"\"\"A chat conversation between a specific user and an AI assistant.\n",
    "    * All conversations are initiated by the user role.\n",
    "    * The assistant role always responds to the user message.\n",
    "    * Turns alternate between user and assistant roles.\n",
    "    * The last message is always from the assistant role.\n",
    "    * Message content can be long or short.\n",
    "    * All assistant messages are faithful responses and must be answered fully.\n",
    "    \"\"\"\n",
    "    conversation: list[Message] = Field(..., description=\"List of all messages in the conversation.\")\n",
    "\n",
    "\n",
    "class UserToxicityScore(BaseModel):\n",
    "    \"\"\"Output format for user toxicity assessment.\n",
    "\n",
    "    Toxicity Scores:\n",
    "    None: No toxicity detected in user messages.\n",
    "    Mild: Slightly rude or sarcastic but not hateful or harmful.\n",
    "    Moderate: Some disrespectful or harassing language.\n",
    "    Severe: Overt hate, harassment, or harmful content.\n",
    "    \"\"\"\n",
    "    reasons: list[str] = Field(..., description=\"Reasoning for user toxicity score.\")\n",
    "    score: Literal[\"None\", \"Mild\", \"Moderate\", \"Severe\"] = Field(..., description=\"Level of toxicity observed in the user role responses.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üå± Adding Categorical Seed Columns\n",
    "\n",
    "Define categorical seed columns that set the context for the generated dialogues. Domain, topic, complexity, conversation length, and user mood will influence the generated conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add domain column with subcategories for topics\n",
    "config_builder.add_column(\n",
    "    name=\"domain\",\n",
    "    type=\"category\",\n",
    "    params={\n",
    "        \"values\": [\"Tech Support\", \"Personal Finances\", \"Educational Guidance\"],\n",
    "        \"num_new_values_to_generate\": 5\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add topic subcategory\n",
    "config_builder.add_column(\n",
    "    name=\"topic\",\n",
    "    type=\"subcategory\",\n",
    "    params={\n",
    "        \"category\": \"domain\",\n",
    "        \"values\": {\n",
    "            \"Tech Support\": [\n",
    "                \"Troubleshooting a Laptop\",\n",
    "                \"Setting Up a Home Wi-Fi Network\",\n",
    "                \"Installing Software Updates\"\n",
    "            ],\n",
    "            \"Personal Finances\": [\n",
    "                \"Budgeting Advice\",\n",
    "                \"Understanding Taxes\",\n",
    "                \"Investment Strategies\"\n",
    "            ],\n",
    "            \"Educational Guidance\": [\n",
    "                \"Choosing a College Major\",\n",
    "                \"Effective Studying Techniques\",\n",
    "                \"Learning a New Language\"\n",
    "            ]\n",
    "        },\n",
    "        \"num_new_values_to_generate\": 2\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add complexity column\n",
    "config_builder.add_column(\n",
    "    name=\"complexity\",\n",
    "    type=\"category\",\n",
    "    params={\n",
    "        \"values\": [\"Basic\", \"Intermediate\", \"Advanced\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add conversation length column\n",
    "config_builder.add_column(\n",
    "    name=\"conversation_length\",\n",
    "    type=\"category\",\n",
    "    params={\n",
    "        \"values\": [2, 4, 6, 8]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add user mood column\n",
    "config_builder.add_column(\n",
    "    name=\"user_mood\",\n",
    "    type=\"category\",\n",
    "    params={\n",
    "        \"values\": [\"happy\", \"silly\", \"sarcastic\", \"combative\", \"disappointed\", \"toxic\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ú® Adding Generated Data Columns\n",
    "Now define the columns that the model will generate. These prompts instruct the LLM to produce the actual conversation: a system prompt to guide how the AI assistant engages in the conversation with the user, the conversation, and finally, we generate a toxicity_label to assess user toxicity over the entire conversation.\n",
    "\n",
    "#### üí¨ü§ñ AI Assistant system prompt and conversation\n",
    "\n",
    "We generate a system prompt to base the AI assistant and then generate the entire conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate assistant system prompt\n",
    "config_builder.add_column(\n",
    "    name=\"assistant_system_prompt\",\n",
    "    type=\"llm-text\",\n",
    "    model_alias=model_alias,\n",
    "    system_prompt=\"Keep this to a maximum of two sentences.\",\n",
    "    prompt=\"Write a reasonable system prompt for a helpful AI assistant with expertise in {{domain}} and {{topic}}. The AI assistant must not engage in harmful behaviors.\"\n",
    ")\n",
    "\n",
    "# Generate the user's task\n",
    "config_builder.add_column(\n",
    "    name=\"user_task\",\n",
    "    type=\"llm-text\",\n",
    "    model_alias=model_alias,\n",
    "    system_prompt=\"The task should be clear, focused on a single goal, and at most two sentences. Focus only on the task and don't provide only the task information.\",\n",
    "    prompt=\"Define a simple task related to {{topic}} of {{complexity}} complexity for the user.\"\n",
    ")\n",
    "\n",
    "\n",
    "# Generate the conversation\n",
    "config_builder.add_column(\n",
    "    name=\"conversation\",\n",
    "    type=\"llm-structured\",\n",
    "    model_alias=model_alias,\n",
    "    prompt=(\n",
    "        \"<task>\\n{{user_task}}\\n</task>\\n\\n\"\n",
    "\n",
    "        \"<system_prompt>{{assistant_system_prompt}}</system_prompt>\\n\\n\"\n",
    "\n",
    "        \"Generate a conversation between a user and an AI assistant with <system_prompt> about <task>.\\n\"\n",
    "        \"User is asking the assistant for advice and is in a {{user_mood}} mood.\\n\"\n",
    "        \"The conversation must be {{conversation_length}} messages in length.\\n\"\n",
    "        \"The conversation must come to a natural end in {{conversation_length}} messages and if the assistant is unable \"\n",
    "        \"to solve the user's needs by then, they should offer to continue the conversation later or redirect them to additional resources.\\n\"\n",
    "        \"The conversation must be realistic and natural, incorporating details from both the user's and assistant's profiles.\\n\"\n",
    "        \"The AI assistant role has the system prompt defined in <system_prompt>. All of its responses must conform to <system_prompt>:\\n\"\n",
    "    ),\n",
    "    output_format=ChatConversation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîç‚öñÔ∏è Assessment Column: Toxicity Label\n",
    "For the final step, we add a toxicity assessment column to classify the overall toxicity level of the user's messages across the entire conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Toxicity Label for the entire conversation\n",
    "# Define Toxicity Rubric\n",
    "toxicity_rubric = P.Rubric(\n",
    "    name=\"Toxicity\",\n",
    "    description=\"Evaluation of harmful, harassing, or hateful language in conversations\",\n",
    "    scoring={\n",
    "        \"4\": \"No toxicity detected; conversation is respectful and appropriate.\",\n",
    "        \"3\": \"Mild toxicity; slightly rude or sarcastic but not hateful or harmful.\",\n",
    "        \"2\": \"Moderate toxicity; contains disrespectful or harassing language.\",\n",
    "        \"1\": \"Severe toxicity; contains overt hate, harassment, or harmful content.\",\n",
    "        \"0\": \"Extreme toxicity; contains dangerous, threatening, or abusive content.\"\n",
    "    }\n",
    ")\n",
    "\n",
    "TOXICITY_PROMPT_TEMPLATE = \"\"\"\\\n",
    "You are an expert in content moderation and digital communication ethics. You are evaluating the toxicity level in user messages.\n",
    "Take a deep breath and carefully analyze the conversation provided. Use the rubric to score the level of toxicity in the USER'S messages only.\n",
    "\n",
    "Consider:\n",
    "- Focus primarily on harassment, hate, or harmful language\n",
    "- Evaluate the full context of the conversation\n",
    "- Be objective and consistent in your assessment\n",
    "- If any single message exhibits toxicity, it should influence the final score\n",
    "\n",
    "## CONVERSATION\n",
    "{{ conversation }}\n",
    "\"\"\"\n",
    "\n",
    "config_builder.add_column(\n",
    "    name=\"toxicity_evaluation\",\n",
    "    type='llm-judge',\n",
    "    model_alias=model_alias,\n",
    "    prompt=TOXICITY_PROMPT_TEMPLATE,\n",
    "    rubrics=[toxicity_rubric]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üëÄ Generating a dataset preview\n",
    "\n",
    "- Preview mode allows you to quickly iterate on your data design.\n",
    "\n",
    "- Each preview generation call creates 10 records for inspection, helping you verify prompts and instructions before running a larger batch job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a preview\n",
    "preview = data_designer_client.preview(config_builder, verbose_logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview.display_sample_record()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§î Like what you see?\n",
    "\n",
    "Submit a batch workflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Submit batch job\n",
    "job_results = data_designer_client.create(config_builder, num_records=20, wait_until_done=False)\n",
    "\n",
    "job_results.wait_until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c55c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = job_results.load_dataset()\n",
    "print(\"\\nGenerated dataset shape:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect first 10 records of the generated dataset\n",
    "dataset.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdg_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
