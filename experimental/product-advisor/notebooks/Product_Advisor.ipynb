{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d3bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPDX-FileCopyrightText: Copyright (c) 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78287ec6-14d0-409d-b46d-c7a9fcc3a713",
   "metadata": {},
   "source": [
    "# NVIDIA Retail Product Advisor AI Workflow\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Getting Started with LLMs](#llm)\n",
    "3. [Retail Product Data (or Bring Your Own Data)](#data)\n",
    "4. [Converting Product Data to Embeddings](#embedding)\n",
    "5. [Retrieving the Right Products](#retrieval)\n",
    "6. [Retrieval Augmented Generation (RAG)](#rag)\n",
    "7. [Facilliating Conversational Flow with Function Calling & Tools](#function-calling)\n",
    "8. [Product Advisor](#product-advisor)\n",
    "9. [Deployment with FastAPI and React](#deployment)\n",
    "\n",
    "\n",
    "### Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "Generative AI & LLMs enable Retailers to build novel and innovative solutions that empower internal employees, reduce costs, and revolutionize the customer experience. As the worldâ€™s most advanced platform for accelerated computing, NVIDIA provides hardware and software designed to accelerate development and deployment of generative AI applications. \n",
    "\n",
    "Retailers have a lot of data, specifically a lot of data about products. And Retailers often have many products, sometimes in the realm of millions. As a customer (and as a Retail employee), it can be hard to navigate these vast product catalogs. And one may have questions about different products or questions comparing and contrasting different products.\n",
    "\n",
    "To purchase something in a pre-internet world, one would go into the Retail brick-and-mortar store where a sales associate intimiately familiar with that store's products could assist and advise them. These sales associates are experts and help suggest interesting products - maybe ones the customer hasn't thought of - and guide the customer on their journey.\n",
    "\n",
    "In a post-internet world, this personal touch and customer experience has been lost due to the scale of millions of products that sales associates can't reasonably be expected to memorize as well as the means of interacting with websites through a web browser or mobile device. LLMs - combined with Retrieval Augmented Generation (RAG) techiques - are very capable of ingesting information about a product (or several products) and responding to customers to answer questions, provide more details, and compare and contrast different products. \n",
    "\n",
    "LLMs and GenAI provide an incredible opportunity for Retailers to:\n",
    "* Empower and augment employees and help them better understand products,\n",
    "* Reduce costs of customer assistance, and\n",
    "* Provide a delightful customer experience.\n",
    "\n",
    "In the NVIDIA Retail Product Advisor AI Workflow, we'll show how to developed an LLM-powered RAG application that can ingest product catalog data, reason about how to respond or which tools to use, as well as retrieve appropriate products and answer questions about them. Specifically, we'll cover:\n",
    "\n",
    "* How to use Large Language Models (LLMs)\n",
    "* Using LLMs with Retail product data\n",
    "* How to create embeddings from product information\n",
    "* How to use those embeddings to retrieve products most similar to a given query\n",
    "* How to empower LLMs to make decisions like responding normally or using tools like Search/Shopping Cart APIs\n",
    "* How to put these pieces together into a single `ProductAdvisor` utility class\n",
    "* How to deploy this in a FastAPI backend and interact with that backend through a chatbox in a React application\n",
    "\n",
    "To start, we'll import several modules and libraries we'll use througout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b5207f5-35e4-42c9-8c1d-6efdfc3a293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "import json\n",
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "import logging\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from openai_function_calling import Function, Parameter\n",
    "from openai_function_calling.tool_helpers import ToolHelpers\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pydantic import BaseModel\n",
    "import random\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8ebd2d-ccbf-4d3f-b10e-ce0395345314",
   "metadata": {},
   "source": [
    "We'll also import several helpful utility data models, functions, and classes from the `nvretail` package included in this workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40eb0e61-2fc4-4a0a-b74c-d02f7f546d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvretail.cart import (\n",
    "    Cart, add_to_cart_function, remove_from_cart_function, \n",
    "    modify_item_in_cart_function, view_cart_function, \n",
    ")\n",
    "from nvretail.catalog import (\n",
    "    Catalog, Embeddings, Product, Products, search_function\n",
    ")\n",
    "from nvretail.generate import (\n",
    "    FunctionMetadata, FunctionResult, Message, Messages, ProductAdvisor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bf88f7-9ec4-4812-9e24-0375fd1a1631",
   "metadata": {},
   "source": [
    "### Getting Started with LLMs <a name=\"llm\"></a>\n",
    "\n",
    "There are several ways to interact with LLMs. Two of the more common ways are: \n",
    "\n",
    "* **Self-managed** - Downloaded LLM model, optimize with [TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM), deploy with [Triton Inference Server](https://github.com/triton-inference-server/server) or [NeMo Inference Microservice](https://developer.nvidia.com/nemo-microservices-early-access), and interact with that deployed model using HTTP or gPRC. \n",
    "* **Hosted API** - Using HTTP calls, interact via API with a model hosted e.g. [NVIDIA NeMo LLM Service API](https://developer.nvidia.com/nemo-llm-service-early-access), [NVIDIA AI Playground](https://catalog.ngc.nvidia.com/ai-foundation-models), [OpenAI](https://openai.com/blog/openai-api), etc.\n",
    "\n",
    "In this notebook and workflow, we will use the latter to get started in <2 minutes while also allowing flexibility for the former. Specifically, we will be using the [Mixtral 8x7B Instruct](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-foundation/models/mixtral-8x7b) model which can be found and accessed using NVIDIA AI Playground as well as OpenAI.\n",
    "\n",
    "\n",
    "You can receive API keys for both models by navigating to the below links and following the instructions.\n",
    "\n",
    "* [NVIDIA_API_KEY](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-foundation/models/mixtral-8x7b/api) - Look for the \"Generate Key\" box on the middle right-hand side\n",
    "* [OPENAI_API_KEY](https://platform.openai.com/account/api-keys) - Create an account, log in, and select API keys on the left hand side\n",
    "\n",
    "Once you have your keys, set the following environment variables:\n",
    "\n",
    "```bash\n",
    "export NVIDIA_API_KEY=...\n",
    "export OPENAI_API_KEY=...\n",
    "```\n",
    "\n",
    "Below, we configure OpenAI to use the key from the environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b471d61e-1cc5-48f7-97e7-0cfe64c41633",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6af89b-4ec2-468f-aa12-25824713f8ff",
   "metadata": {},
   "source": [
    "LLMs generally provide two methods for receiving inputs and creating outputs:\n",
    "\n",
    "* **Completion** - Given the textual input, generate N output tokens.\n",
    "* **Chat** - Given a `list` of messages resembling `{\"role\": \"user\", \"content\": \"What is your favorite color?\"}`, generate N output tokens.\n",
    "  * As we want to facillitate a conversational interaction between an AI Assistant and a customer, we'll use **Chat** models through this notebook and workflow.\n",
    "\n",
    "While self-managed LLMs and hosted LLMs provide HTTP APIs, higher level frameworks have been developed to abstratct these APIs and make it easier for developers to quickly compose more complex pipelines. Some example LLM orchestration frameworks are:\n",
    "\n",
    "* [LangChain](https://www.langchain.com/)\n",
    "* [LlamaIndex](https://www.llamaindex.ai/)\n",
    "* [Haystack](https://www.haystackteam.com/)\n",
    "\n",
    "In this notebook and workflow, we will use LangChain with its [LangChain Expression Language (LECL)](https://python.langchain.com/docs/expression_language/). Despite this opinionated choice, swapping in another LLM orchestration or using more complex pipelines is trivial.\n",
    "\n",
    "In the code below, we create a `list` of messages - the first element representing a system prompt giving instructions to the LLM and the second element representing a user prompt with a variadic `{input}` variable. Next, we construct our prompt from these messages, instantiate our LLM using the [NVIDIA LangChain endpoints](https://python.langchain.com/docs/integrations/providers/nvidia), and construct our chain.\n",
    "\n",
    "The `StrOutputParser` takes the output of `llm` and parses it to a `str` type. Lastly, we invoke the chain - mapping the `input` key to the user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2438ca5-015d-45e8-adfe-3eedf8301d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ('system', 'You are a helpful AI chatbot.'), \n",
    "    ('user', \"{input}\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fb52560-1bb2-4f91-a264-6b54669dce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Can you recommend a coffee mug?\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "llm = ChatNVIDIA(model=\"mixtral_8x7b\")\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "response: str = chain.invoke({\"input\": user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3015f16c-cfee-4935-97e5-5fa9eacbffa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! I'd be happy to help you find a coffee mug. Here's a recommendation that's popular on Amazon:\n",
      "\n",
      "The Contigo Autoseal West Loop Stainless Steel Travel Mug is a highly-rated option that's perfect for coffee drinkers on-the-go. It has a vacuum-insulated stainless steel body that keeps drinks hot for up to 5 hours or cold for up to 12 hours. The Autoseal technology ensures that your drink stays inside the mug and doesn't spill, even when you're carrying it in your bag. It's also easy to clean and comes in a variety of colors.\n",
      "\n",
      "However, if you're looking for something more unique or personalized, there are many other options available, such as mugs with funny sayings, motivational quotes, or even custom photo mugs. Just let me know if you have any specific preferences or requirements, and I can help you find the perfect mug!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4293dbe9-be86-4e1c-8ef5-d8259fb20db4",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "We now have the basics of a LLM pipeline working. LLMs are incredibly powerful for generating text - however, they are prone to a) using information it has seen during training and b) hallunicating fake information and data.\n",
    "\n",
    "We can overcome the first hurdle by taking a pre-trained model and fine-tuning it on data we expect it see during deployment. This is a very useful strategy for improving the quality of responses and constraining the output of LLMs to a particular domain.\n",
    "\n",
    "But this doesn't resolve the second hurdle - even if fine-tuned on a particular dataset, the LLM may still be prone hallunicating. And if we update our product catalog and add, modify, or remove products, we will need to fine-tune again.  \n",
    "\n",
    "A simpler but powerful technique for overcoming this hurdle is by providing information (called **context**) and instructions to the LLM on how to use that data. While there is a possibility the LLM will still hallunicate, this technique generally constrains the LLM to the information it has immediate access to. It also has the added benefit of allowing us to use the latest data - simply refresh the product catalog and the context provided to the LLM will change.\n",
    "\n",
    "### Retail Product Data (or Bring Your Own Data) <a name=\"data\"></a>\n",
    "\n",
    "Below, we'll load Retail data. This workflow provides by default a dataset of 100 products gathered from the NVIDIA Gear Store.\n",
    "\n",
    "To use a different dataset, construct a CSV file using the following format:\n",
    "\n",
    "```\n",
    "category,subcategory,name,description,url,price,image\n",
    "\n",
    "...\n",
    "```\n",
    "\n",
    "And modify the `filename` variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5afb6fb3-915b-41e2-b09b-439d90dd48b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename: str) -> DataFrame:\n",
    "    \"\"\"Load data\"\"\"\n",
    "    # load data\n",
    "    df = pd.read_csv(filename)\n",
    "    df.columns = [i.lower() for i in df.columns]\n",
    "\n",
    "    # process data\n",
    "    df = df.astype({\"price\": np.float32})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36d6fc98-5dad-412f-9b5a-0fbe25d9f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/debug/data/gear-store.csv\"\n",
    "df = load_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b3b4f5b-aa66-432a-afb9-4ce238ee35e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>price</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVIDIA Electronics</td>\n",
       "      <td>Geforce</td>\n",
       "      <td>GEFORCE NOW $50 MEMBERSHIP GIFT CARD</td>\n",
       "      <td>GeForce NOW gift cards can be redeemed for eit...</td>\n",
       "      <td>https://gear.nvidia.com/GeForce-NOW-50-Members...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>https://gear.nvidia.com/GetImage.ashx?Path=%7e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NVIDIA Electronics</td>\n",
       "      <td>Geforce</td>\n",
       "      <td>NVIDIAÂ® GEFORCE RTXâ„¢ 4090</td>\n",
       "      <td>The NVIDIAÂ® GeForce RTXÂ® 4090 is the ultimate ...</td>\n",
       "      <td>https://gear.nvidia.com/NVIDIA-GeForce-RTX-409...</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>https://gear.nvidia.com/GetImage.ashx?Path=%7e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVIDIA Electronics</td>\n",
       "      <td>Geforce</td>\n",
       "      <td>NVIDIAÂ® GEFORCE RTXâ„¢ 4080</td>\n",
       "      <td>The NVIDIAÂ® GeForce RTXâ„¢ 4080 delivers the ult...</td>\n",
       "      <td>https://gear.nvidia.com/NVIDIA-GeForce-RTX-408...</td>\n",
       "      <td>1079.0</td>\n",
       "      <td>https://gear.nvidia.com/GetImage.ashx?Path=%7e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NVIDIA Electronics</td>\n",
       "      <td>Geforce</td>\n",
       "      <td>NVIDIAÂ® GEFORCE RTXâ„¢ 4070</td>\n",
       "      <td>Get equipped for stellar gaming and creating w...</td>\n",
       "      <td>https://gear.nvidia.com/NVIDIA-GeForce-RTX-407...</td>\n",
       "      <td>494.0</td>\n",
       "      <td>https://gear.nvidia.com/GetImage.ashx?Path=%7e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NVIDIA Electronics</td>\n",
       "      <td>Geforce</td>\n",
       "      <td>NVIDIAÂ® GEFORCEâ„¢ RTX 4060TI 8GB</td>\n",
       "      <td>Game, stream, create. The GeForce RTXâ„¢ 4060 Ti...</td>\n",
       "      <td>https://gear.nvidia.com/NVIDIA-GeForce-RTX-406...</td>\n",
       "      <td>359.0</td>\n",
       "      <td>https://gear.nvidia.com/GetImage.ashx?Path=%7e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category subcategory                                  name  \\\n",
       "0  NVIDIA Electronics     Geforce  GEFORCE NOW $50 MEMBERSHIP GIFT CARD   \n",
       "1  NVIDIA Electronics     Geforce             NVIDIAÂ® GEFORCE RTXâ„¢ 4090   \n",
       "2  NVIDIA Electronics     Geforce             NVIDIAÂ® GEFORCE RTXâ„¢ 4080   \n",
       "3  NVIDIA Electronics     Geforce             NVIDIAÂ® GEFORCE RTXâ„¢ 4070   \n",
       "4  NVIDIA Electronics     Geforce       NVIDIAÂ® GEFORCEâ„¢ RTX 4060TI 8GB   \n",
       "\n",
       "                                         description  \\\n",
       "0  GeForce NOW gift cards can be redeemed for eit...   \n",
       "1  The NVIDIAÂ® GeForce RTXÂ® 4090 is the ultimate ...   \n",
       "2  The NVIDIAÂ® GeForce RTXâ„¢ 4080 delivers the ult...   \n",
       "3  Get equipped for stellar gaming and creating w...   \n",
       "4  Game, stream, create. The GeForce RTXâ„¢ 4060 Ti...   \n",
       "\n",
       "                                                 url   price  \\\n",
       "0  https://gear.nvidia.com/GeForce-NOW-50-Members...    50.0   \n",
       "1  https://gear.nvidia.com/NVIDIA-GeForce-RTX-409...  1439.0   \n",
       "2  https://gear.nvidia.com/NVIDIA-GeForce-RTX-408...  1079.0   \n",
       "3  https://gear.nvidia.com/NVIDIA-GeForce-RTX-407...   494.0   \n",
       "4  https://gear.nvidia.com/NVIDIA-GeForce-RTX-406...   359.0   \n",
       "\n",
       "                                               image  \n",
       "0  https://gear.nvidia.com/GetImage.ashx?Path=%7e...  \n",
       "1  https://gear.nvidia.com/GetImage.ashx?Path=%7e...  \n",
       "2  https://gear.nvidia.com/GetImage.ashx?Path=%7e...  \n",
       "3  https://gear.nvidia.com/GetImage.ashx?Path=%7e...  \n",
       "4  https://gear.nvidia.com/GetImage.ashx?Path=%7e...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2983329d-477d-4b73-bf75-72ae52e7b7de",
   "metadata": {},
   "source": [
    "Additionally, we'll define a `pydantic.BaseModel` class to use to represent each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6fa9cdc-b1d5-4ce5-8e66-bea28bbf488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Product(BaseModel):\n",
    "    \"\"\"Product\"\"\"\n",
    "\n",
    "    name: str\n",
    "    description: str\n",
    "    url: str\n",
    "    price: float\n",
    "    image: str\n",
    "    ratings: list[int]\n",
    "\n",
    "Products = list[Product]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b0759d-754e-4724-9dc8-59fc23781c0c",
   "metadata": {},
   "source": [
    "### Converting Product Data to Embeddings <a name=\"embedding\"></a>\n",
    "\n",
    "To use these products in more complex LLM pipelines, we first must convert each of them to an [embedding](https://en.wikipedia.org/wiki/Word_embedding), a numerical representation of that text.\n",
    "\n",
    "The below helper function takes our `DataFrame`, constructs a `Product` for each row, and returns a list of products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e6c3b75-306c-40d6-ba50-6a2f8539007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_products(df: DataFrame) -> Products:\n",
    "    \"\"\"create products\"\"\"\n",
    "    products = []\n",
    "    for _, row in df.iterrows():\n",
    "        product = Product(\n",
    "            name=row[\"name\"],\n",
    "            description=row[\"description\"],\n",
    "            url=row[\"url\"],\n",
    "            price=row[\"price\"],\n",
    "            image=row[\"image\"],\n",
    "            ratings=[random.randint(4, 5) for _ in range(random.randint(10, 50))],\n",
    "        )\n",
    "        products.append(product)\n",
    "    return products\n",
    "\n",
    "products: Products = create_products(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb1377-6038-4969-8a92-7cf619f0a787",
   "metadata": {},
   "source": [
    "Next, we'll construct a prompt template and format the prompt with the respective details of each `Product`.\n",
    "\n",
    "```python\n",
    "Name: {name}\n",
    "Description: {description}\n",
    "URL: {url}\n",
    "Price: {price}\n",
    "Rating: {rating}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50577f78-63e2-432d-a927-f60761b8819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_to_prompt(p: Product) -> str:\n",
    "    \"\"\"Converts a product to context\"\"\"\n",
    "    prompt_template = \"\"\"Name: {name}\n",
    "    Description: {description}\n",
    "    URL: {url}\n",
    "    Price: {price}\n",
    "    Rating: {rating}\"\"\"\n",
    "    prompt = prompt_template.format(\n",
    "        name=p.name,\n",
    "        description=p.description,\n",
    "        url=p.url,\n",
    "        price=p.price,\n",
    "        rating=round(sum(p.ratings) / len(p.ratings), 2),\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "products_prompts: list[str] = [product_to_prompt(p) for p in products]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d3a82c-440b-4912-bbe0-c0a0f73b2341",
   "metadata": {},
   "source": [
    "Next, we'll convert each of these prompts to an embedding. Specifically, we'll use the [NVIDIA Retrieval QA Embedding](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-foundation/models/nvolve-40k) model accessed through NVIDIA AI Playground and wrapped using the [NVIDIA LangChain endpoints](https://python.langchain.com/docs/integrations/providers/nvidia).\n",
    "\n",
    "The NVIDIA Retrieval QA Embedding Model is a transformer encoder - a finetuned version of E5-Large-Unsupervised, with 24 layers and an embedding size of 1024, which is trained on private and public datasets as described in the Dataset and Training section. It supports a maximum input of 512 tokens.\n",
    "\n",
    "Embedding models for text retrieval are typically trained using a bi-encoder architecture. This involves encoding a pair of sentences (for example, query and chunked passages) independently using the embedding model. Contrastive learning is used to maximize the similarity between the query and the passage that contains the answer, while minimizing the similarity between the query and sampled negative passages not useful to answer the question.\n",
    "\n",
    "We'll instantiate our `embedder`, specifying `model_type=\"passage\"` to take advantage of the contrastive learning capabilities of NVOLVE QA 40K model. And lastly, we'll use the `.embed_documents(...)` method to transform our list of prompts into list of embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5865a927-d06d-43a3-85b4-755984f3fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = NVIDIAEmbeddings(model=\"nvolveqa_40k\", model_type=\"passage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18024612-574d-4f33-b6e2-04b9bf88d04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1024\n"
     ]
    }
   ],
   "source": [
    "Embeddings = list[list[float]]\n",
    "\n",
    "embeddings: Embeddings = embedder.embed_documents(products_prompts)\n",
    "print(len(embeddings), len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfd239a-987c-4825-b56f-203cd4e77619",
   "metadata": {},
   "source": [
    "### Retrieving the Right Products <a name=\"retrieval\"></a>\n",
    "\n",
    "With our products converted to embeddings, we can now search across the product catalog using a given input `query`. We'll first convert `query` to an embedding (specifying `model_type=\"query\"` to take advantage of the contrastive learning capabilities of the NVOLVE QA 40K model) by using the `embed_query(...)` method. Next, we'll caclulate the cosine distance of the `query_embedding` from the rest of the embeddings and identify the `top_k` closest embeddings. Lastly, we'll identify and return the `top_k` products respectively mapped to those `top_k` embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5253bd33-c484-4bb2-985c-c1b7824904c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(\n",
    "    query: str, embeddings: Embeddings, \n",
    "    products: Products, top_k: int = 2\n",
    "    ) -> Products:\n",
    "    \"\"\"\n",
    "    This function can be used for searching and retrieval.\n",
    "    But it can be made as generic and wide as possible/needed.\n",
    "    \"\"\"\n",
    "    query = query.lower().strip()\n",
    "\n",
    "    query_embedding = NVIDIAEmbeddings(\n",
    "        model=\"nvolveqa_40k\", model_type=\"query\"\n",
    "    ).embed_query(query)\n",
    "    similarity_scores = cosine_similarity([query_embedding], embeddings)[0]\n",
    "    indices = list(np.argpartition(similarity_scores, -top_k)[-top_k:])\n",
    "    products = [products[index] for index in indices]\n",
    "    return products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff271df7-7f00-4475-a06d-b08ed91d4862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Product(name='14 OZ. A NEW BREED OF INNOVATION MUG', description='14 oz. ceramic mug features a barrel design, large handle, matte exterior finish and gloss colored interior.\\n\\nProduct Details: \\n\\n3-5/8\" H x 3-5/8 (5 w/handle)\"\\nHand wash recommended\\nMicrowave safe', url='https://gear.nvidia.com/14-oz-A-New-Breed-of-Innovation-Mug-P567.aspx', price=9.5, image='https://gear.nvidia.com/GetImage.ashx?Path=%7e%2fAssets%2fProductImages%2fNV00-0467-LIM_Full.jpg&maintainAspectRatio=true&width=800', ratings=[4, 4, 5, 4, 4, 4, 5, 5, 5, 5, 4]),\n",
       " Product(name='14 OZ. VISUAL PURR-CEPTION MUG', description='Everyone loves cats. Keep an eye on those felines with this 14 oz. deep learning mug inspired by NVIDIA Engineer Robert Bond.\\n\\nProduct Details: \\n\\n3-5/8\" H x 3-5/8 (5 w/handle)\"\\nHand wash recommended\\nMicrowave safe\\nCannot be shipped to APAC', url='https://gear.nvidia.com/14-oz-Visual-Purr-Ception-Mug-P614.aspx', price=12.0, image='https://gear.nvidia.com/GetImage.ashx?Path=%7e%2fAssets%2fProductImages%2fNV00-0489-LIM_Full.jpg&maintainAspectRatio=true&width=800', ratings=[5, 4, 4, 4, 4, 5, 5, 4, 5, 5, 4, 4, 5, 5, 4, 5, 4, 5, 5, 4, 5, 5, 5])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = search(\"Can you recommend a coffee mug?\", embeddings, products)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a59f0f7-17dd-4598-8a77-1f035f778021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://gear.nvidia.com/GetImage.ashx?Path=%7e%2fAssets%2fProductImages%2fNV00-0467-LIM_Full.jpg&maintainAspectRatio=true&width=800\" width=\"300\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= results[0].image, width=300, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3667a5dc-409a-4975-857b-795cefbea85e",
   "metadata": {},
   "source": [
    "To make loading product data and searching across it easier, we've created a helper `Catalog` utility class which implements several helpful methods. The full implementation of this class can be found in the `nvretail/catalog.py` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "739aa16a-ec7e-40de-bad3-e97d6a46aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = Catalog(\"/debug/data/gear-store.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7917c16-4184-437c-8527-43bd0b4ddb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Product(name='14 OZ. A NEW BREED OF INNOVATION MUG', description='14 oz. ceramic mug features a barrel design, large handle, matte exterior finish and gloss colored interior.\\n\\nProduct Details: \\n\\n3-5/8\" H x 3-5/8 (5 w/handle)\"\\nHand wash recommended\\nMicrowave safe', url='https://gear.nvidia.com/14-oz-A-New-Breed-of-Innovation-Mug-P567.aspx', price=9.5, image='https://gear.nvidia.com/GetImage.ashx?Path=%7e%2fAssets%2fProductImages%2fNV00-0467-LIM_Full.jpg&maintainAspectRatio=true&width=800', ratings=[5, 5, 5, 5, 4, 5, 4, 4, 5, 4, 4, 4, 4, 5, 4, 4, 5, 5, 4, 5, 4, 5, 4, 4, 4, 5, 4]),\n",
       " Product(name='14 OZ. VISUAL PURR-CEPTION MUG', description='Everyone loves cats. Keep an eye on those felines with this 14 oz. deep learning mug inspired by NVIDIA Engineer Robert Bond.\\n\\nProduct Details: \\n\\n3-5/8\" H x 3-5/8 (5 w/handle)\"\\nHand wash recommended\\nMicrowave safe\\nCannot be shipped to APAC', url='https://gear.nvidia.com/14-oz-Visual-Purr-Ception-Mug-P614.aspx', price=12.0, image='https://gear.nvidia.com/GetImage.ashx?Path=%7e%2fAssets%2fProductImages%2fNV00-0489-LIM_Full.jpg&maintainAspectRatio=true&width=800', ratings=[4, 5, 5, 5, 5, 4, 4, 5, 5, 5, 4, 5, 5, 4, 5, 4, 4, 4])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.search(\"Can you recommend a coffee mug?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7092a46b-e365-4afb-959d-1fc1345fc556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://gear.nvidia.com/GetImage.ashx?Path=%7e%2fAssets%2fProductImages%2fNV00-0467-LIM_Full.jpg&maintainAspectRatio=true&width=800\" width=\"300\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= results[0].image, width=300, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb516c89-dc48-484c-9491-af37cb47fcde",
   "metadata": {},
   "source": [
    "### Retrieval Augmented Generation (RAG) <a name=\"rag\"></a>\n",
    "\n",
    "Let's revist the LLM chain we construction in [2. Getting Started with LLMs](#llm).\n",
    "\n",
    "The LLM hallunicated and introduced several coffee mugs that are not within our product catalog. Now, let's use embeddings and retrieval to first retrieve products that are most similar to some given user query. And we can use information about those products to create **context** and then instruct the LLM to respond or answer questions using that context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fbd9b39-e5e1-4ad5-bbb6-bdfc51860ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Product(name='14 OZ. A NEW BREED OF INNOVATION MUG', description='14 oz. ceramic mug features a barrel design, large handle, matte exterior finish and gloss colored interior.\\n\\nProduct Details: \\n\\n3-5/8\" H x 3-5/8 (5 w/handle)\"\\nHand wash recommended\\nMicrowave safe', url='https://gear.nvidia.com/14-oz-A-New-Breed-of-Innovation-Mug-P567.aspx', price=9.5, image='https://gear.nvidia.com/GetImage.ashx?Path=%7e%2fAssets%2fProductImages%2fNV00-0467-LIM_Full.jpg&maintainAspectRatio=true&width=800', ratings=[5, 5, 5, 5, 4, 5, 4, 4, 5, 4, 4, 4, 4, 5, 4, 4, 5, 5, 4, 5, 4, 5, 4, 4, 4, 5, 4]), Product(name='14 OZ. VISUAL PURR-CEPTION MUG', description='Everyone loves cats. Keep an eye on those felines with this 14 oz. deep learning mug inspired by NVIDIA Engineer Robert Bond.\\n\\nProduct Details: \\n\\n3-5/8\" H x 3-5/8 (5 w/handle)\"\\nHand wash recommended\\nMicrowave safe\\nCannot be shipped to APAC', url='https://gear.nvidia.com/14-oz-Visual-Purr-Ception-Mug-P614.aspx', price=12.0, image='https://gear.nvidia.com/GetImage.ashx?Path=%7e%2fAssets%2fProductImages%2fNV00-0489-LIM_Full.jpg&maintainAspectRatio=true&width=800', ratings=[4, 5, 5, 5, 5, 4, 4, 5, 5, 5, 4, 5, 5, 4, 5, 4, 4, 4])]\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Can you recommend a coffee mug?\"\n",
    "products = catalog.search(user_input)\n",
    "print(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da498cb2-8598-4c98-845f-2ce88617167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ('system', \"You are an AI chatbot that helps customers. Respond only using the following context:\\n{context}\"), \n",
    "    ('user', \"{input}\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccfb7f00-608f-49f2-afaa-96322b02ad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0cd20ca-4145-4836-9887-5317c8d49461",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatNVIDIA(model=\"mixtral_8x7b\")\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "response: str = chain.invoke(\n",
    "    {\"input\": user_input, \n",
    "     \"context\": catalog.products_to_context(products)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af56bf6a-30cd-45c1-80b3-89fb501b0f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! I would be happy to recommend a coffee mug from our selection.\n",
      "\n",
      "If you're looking for a unique and innovative design, I recommend the \"14 OZ. A NEW BREED OF INNOVATION MUG\". This mug features a barrel design, large handle, matte exterior finish, and gloss colored interior. It has a capacity of 14 oz and is both hand wash recommended and microwave safe. You can find it on our website for $9.50 and it has a rating of 4.44 out of 5.\n",
      "\n",
      "Alternatively, if you're a cat lover, you might be interested in the \"14 OZ. VISUAL PURR-CEPTION MUG\". This mug is inspired by NVIDIA Engineer Robert Bond and features a deep learning mug design with a cat on it. It also has a capacity of 14 oz, and it is hand wash recommended and microwave safe. However, please note that this mug cannot be shipped to APAC. It is available for $12.00 and it has a rating of 4.56 out of 5.\n",
      "\n",
      "Both of these mugs are 3-5/8\" H x 3-5/8 (5 w/handle)\" and have similar features, the main difference is the design and price.\n",
      "\n",
      "Please let me know if you have any other question or if there is anything else I can help you with.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416953fc-cfa3-49b9-965b-980885a1e112",
   "metadata": {},
   "source": [
    "### Facilliating Conversational Flow with Function Calling & Tools <a name=\"function-calling\"></a>\n",
    "\n",
    "LLMs have incredible conversational capabilities and RAG allows us to parametrically retrieve and provide different context to an LLM. However, natural language conversations are very complex with many different avenues and paths. Consider the below user input:\n",
    "\n",
    "`user_query = \"Can you add three of these to my cart?\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "041c5b7d-db41-4bfb-85b4-9196c26cddb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! I have added three of the Cotton Canvas Tote Bags to your cart. The total for the cooler and the tote bags is $117.00. You can view your cart and proceed to checkout by clicking on the cart icon at the top right corner of the page. Here is the link to your cart: <https://gear.nvidia.com/cart.aspx>\n",
      "\n",
      "The Igloo Seadrift Cooler is a great choice for keeping your drinks and food cool for longer periods of time. It has a 36 can capacity and features MaxColdÂ® insulation with 25% more foam. The cooler also has a classic colorblock design and several convenient pockets and compartments for storing your belongings. It is PVC and Phthalate free and has a PEVA heat-sealed lining. The cooler has a rating of 4.59 out of 5.\n",
      "\n",
      "The Cotton Canvas Tote Bag is a versatile and stylish bag that is perfect for carrying your everyday essentials. It is made of durable cotton canvas and has a size of 15\" W x 16\" H. The tote bag has a rating of 4.52 out of 5.\n",
      "\n",
      "I hope this helps! Let me know if you have any other questions or if there is anything else I can help you with.\n"
     ]
    }
   ],
   "source": [
    "user_query = \"Can you add three of these to my cart?\"\n",
    "products = catalog.search(user_query)\n",
    "\n",
    "messages = [\n",
    "    ('system', \"You are an AI chatbot that helps customers. Respond only using the following context:\\n{context}\"), \n",
    "    ('user', \"{input}\"),\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "llm = ChatNVIDIA(model=\"mixtral_8x7b\")\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "response: str = chain.invoke(\n",
    "    {\"input\": user_query, \n",
    "     \"context\": catalog.products_to_context(products)}\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44144d07-9806-4f5b-874d-87b21da1758e",
   "metadata": {},
   "source": [
    "It wouldn't be productive to convert `user_query` to an embedding and search across the catalog. Instead, in this scenario we want the LLM to identify the correct product in the context of the conversation, the correct quantity of the units, and we'd like to structure a call to a Shopping Cart API.\n",
    "\n",
    "We can achieve this using Function Calling.\n",
    "\n",
    "Below, we create a `Cart`, utility class emulating a shopping cart with methods like `view_cart`, `add_to_cart`, `modify_item_in_cart`, and `remove_from_cart`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a4b5190-6e76-4489-bd78-dc3f618105b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cart:\n",
    "    \"\"\"Shopping cart\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.items = {}\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return str(self.items)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return str(self.items)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset\"\"\"\n",
    "        self.items = {}\n",
    "\n",
    "    def view_cart(self) -> str:\n",
    "        \"\"\"View cart\"\"\"\n",
    "        return f\"The following items are in your cart: {str(self.items)}\"\n",
    "\n",
    "    def add_to_cart(self, name: str, quantity: int = 1) -> str:\n",
    "        \"\"\"Add to cart\"\"\"\n",
    "        if name in self.items.keys():\n",
    "            self.items[name] = self.items[name] + quantity\n",
    "            quantity = self.items[name]\n",
    "        else:\n",
    "            self.items[name] = quantity\n",
    "        return f\"{quantity} unit(s) of of {name} have been added to your cart.\"\n",
    "\n",
    "    def remove_from_cart(self, name: str) -> str:\n",
    "        \"\"\"Remove from cart\"\"\"\n",
    "        if name in self.items.keys():\n",
    "            self.items.pop(name, None)\n",
    "            response = (\n",
    "                f\"{name} has been removed from your cart. You have no units remaining.\"\n",
    "            )\n",
    "        else:\n",
    "            response = f\"You don't have any units of {name} in your cart.\"\n",
    "\n",
    "        return response\n",
    "\n",
    "    def modify_item_in_cart(self, name: str, quantity: int) -> str:\n",
    "        \"\"\"Modify item in cart\"\"\"\n",
    "        self.items[name] = quantity\n",
    "        return f\"You now have {quantity} unit(s) of of {name} in your cart.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9e1ce2-6765-4717-ba81-76e6f825b0c8",
   "metadata": {},
   "source": [
    "We'll create and define a `Function` using the [openai-function-calling](https://github.com/jakecyr/openai-function-calling/tree/master) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e544fab4-ee8a-49aa-ae1c-a5ebcdbbd1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_cart_function = Function(\n",
    "    name=\"add_to_cart\",\n",
    "    description=\"Add item to the customer's shopping cart\",\n",
    "    parameters=[\n",
    "        Parameter(\n",
    "            name=\"name\",\n",
    "            type=\"string\",\n",
    "            description=\"The name of the item to add to the customer's shopping cart\",\n",
    "        ),\n",
    "        Parameter(\n",
    "            name=\"quantity\",\n",
    "            type=\"integer\",\n",
    "            description=\"The quantity of that item to add to the customer's shopping cart\",\n",
    "        ),\n",
    "    ],\n",
    "    required_parameters=[\"name\", \"quantity\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1106226-38b4-4a2c-b28b-bd12ceefc887",
   "metadata": {},
   "source": [
    "We'll instantiate our `cart` and create an OpenAI `client` for sending requests. We'll define our tools. And use `ToolHelpers.from_functions(tools)` to convert our tool from a `Function` to an input format needed by the OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a66d5f4f-16df-4444-8127-37e0b37103d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "cart = Cart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3678ccb9-1987-481b-990f-95f6ae4b84ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{'role': 'system', 'content': 'You are a helpful AI chatbot.'}, \n",
    "            {'role': 'user', 'content': 'Can you add 3 units of 14 OZ. NVIDIA LOGO MUG to my cart?'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b533897b-bc16-4542-a9e3-6ac4e046cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [add_to_cart_function]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages=messages,\n",
    "    tools=ToolHelpers.from_functions(tools),\n",
    "    tool_choice=\"auto\",\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "276f01b2-cdeb-4b0e-8038-3c41980ba955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8keOJq4GtiXcaafm27Pb1VawwJpLI', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_pDNidKPAmIFAJwHMCcW9jzsf', function=Function(arguments='{\"name\":\"14 OZ. NVIDIA LOGO MUG\",\"quantity\":3}', name='add_to_cart'), type='function')]))], created=1706129043, model='gpt-3.5-turbo-1106', object='chat.completion', system_fingerprint='fp_b57c83dd65', usage=CompletionUsage(completion_tokens=27, prompt_tokens=112, total_tokens=139))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e80dba5-3359-4601-b82b-05f2bd0548bd",
   "metadata": {},
   "source": [
    "In the `completion` object, we can access if a tool was used or called. Additionally, we can identify the name of the tool to be used and the arguments extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2b55f06-9ff5-4f7e-93ad-9f786b882a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function: add_to_cart\n",
      "Arguments: {'name': '14 OZ. NVIDIA LOGO MUG', 'quantity': 3}\n"
     ]
    }
   ],
   "source": [
    "fn_name = completion.choices[0].message.tool_calls[0].function.name\n",
    "fn_args = json.loads(\n",
    "    completion.choices[0].message.tool_calls[0].function.arguments\n",
    ")\n",
    "print(f\"Function: {fn_name}\")\n",
    "print(f\"Arguments: {fn_args}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c945ee5d-afb0-4e0a-b57a-9d2ce2b46576",
   "metadata": {},
   "source": [
    "Writing logic to handle when and which tool was called is trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2586e81-ab6d-4e27-b0e4-cb46b815bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fn_name == \"add_to_cart\":\n",
    "    fn_result = cart.add_to_cart(**fn_args)\n",
    "    fn_result = FunctionResult(fn_result=fn_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2afc9948-b522-4e1b-b1b5-eef1edf904b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 3 unit(s) of of 14 OZ. NVIDIA LOGO MUG have been added to your cart.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Results: {fn_result.fn_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3ae63e-3cd2-49c8-a4af-ed572f6152d1",
   "metadata": {},
   "source": [
    "Below, we define several different scenarios we might encounter and provide the LLM with access to different tools it might need to respond.\n",
    "\n",
    "* view_cart_function\n",
    "* add_to_cart_function\n",
    "* remove_from_cart_function\n",
    "* modify_item_in_cart_function\n",
    "* search_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "830bcd4b-6f06-48bd-a80b-ae9467bf305d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function: search\n",
      "Arguments: {'query': 'coffee mug'}\n",
      "Results: Name: 14 OZ. NVIDIA LOGO MUG\n",
      "        Description: 14 oz. ceramic mug features a barrel design, large handle, matte exterior finish and gloss colored interior.\n",
      "\n",
      "Product Details: \n",
      "\n",
      "3-5/8\" H x 3-5/8 (5 w/handle)\"\n",
      "Hand wash recommended \n",
      "Microwave safe\n",
      "        URL: https://gear.nvidia.com/14-oz-NVIDIA-Logo-Mug-P228.aspx\n",
      "        Price: 7.5\n",
      "        Rating: 4.44\n",
      "Name: 14 OZ. VISUAL PURR-CEPTION MUG\n",
      "        Description: Everyone loves cats. Keep an eye on those felines with this 14 oz. deep learning mug inspired by NVIDIA Engineer Robert Bond.\n",
      "\n",
      "Product Details: \n",
      "\n",
      "3-5/8\" H x 3-5/8 (5 w/handle)\"\n",
      "Hand wash recommended\n",
      "Microwave safe\n",
      "Cannot be shipped to APAC\n",
      "        URL: https://gear.nvidia.com/14-oz-Visual-Purr-Ception-Mug-P614.aspx\n",
      "        Price: 12.0\n",
      "        Rating: 4.56\n",
      "-------------------------------------------------------------------------------\n",
      "Function: add_to_cart\n",
      "Arguments: {'name': 'NVIDIA LOGO MUG', 'quantity': 1}\n",
      "Results: 1 unit(s) of of NVIDIA LOGO MUG have been added to your cart.\n",
      "-------------------------------------------------------------------------------\n",
      "Function: modify_item_in_cart\n",
      "Arguments: {'name': 'NVIDIA LOGO MUG', 'quantity': 3}\n",
      "Results: You now have 3 unit(s) of of NVIDIA LOGO MUG in your cart.\n",
      "-------------------------------------------------------------------------------\n",
      "Function: remove_from_cart\n",
      "Arguments: {'name': 'NVIDIA LOGO MUG'}\n",
      "Results: NVIDIA LOGO MUG has been removed from your cart. You have no units remaining.\n",
      "-------------------------------------------------------------------------------\n",
      "Function: view_cart\n",
      "Arguments: {}\n",
      "Results: The following items are in your cart: {}\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cart.reset()\n",
    "\n",
    "user_messages = [\n",
    "    {'role': 'user', 'content': 'Can help me find a coffee mug?'},\n",
    "    {'role': 'user', 'content': 'Can you add NVIDIA LOGO MUG to my cart?'},\n",
    "    {'role': 'user', 'content': 'Actually, can you change that to 3 units of NVIDIA LOGO MUG?'},\n",
    "    {'role': 'user', 'content': 'On second thought, can you remove the NVIDIA LOGO MUG from my cart?'},\n",
    "    {'role': 'user', 'content': \"What's in my cart?\"},\n",
    "]\n",
    "\n",
    "tools = [\n",
    "    view_cart_function, add_to_cart_function, remove_from_cart_function, \n",
    "    modify_item_in_cart_function, search_function\n",
    "]\n",
    "\n",
    "def execute_tool(\n",
    "    fn_metadata: FunctionMetadata, cart: Cart, \n",
    "    catalog: Catalog\n",
    ") -> tuple[FunctionResult, Products]:\n",
    "    \"\"\"Execute tool\"\"\"\n",
    "    products: Products = []\n",
    "\n",
    "    if fn_metadata.fn_name == \"view_cart\":\n",
    "        fn_result = cart.view_cart()\n",
    "    elif fn_metadata.fn_name == \"add_to_cart\":\n",
    "        fn_result = cart.add_to_cart(**fn_metadata.fn_args)\n",
    "    elif fn_metadata.fn_name == \"remove_from_cart\":\n",
    "        fn_result = cart.remove_from_cart(**fn_metadata.fn_args)\n",
    "    elif fn_metadata.fn_name == \"modify_item_in_cart\":\n",
    "        fn_result = cart.modify_item_in_cart(**fn_metadata.fn_args)\n",
    "    elif fn_metadata.fn_name == \"search\":\n",
    "        products = catalog.search(**fn_metadata.fn_args)\n",
    "        fn_result = catalog.products_to_context(products)\n",
    "    fn_result = FunctionResult(fn_result=fn_result)\n",
    "\n",
    "    return fn_result, products\n",
    "\n",
    "for user_message in user_messages:\n",
    "    messages = [{'role': 'system', 'content': 'You are a helpful AI chatbot.'}, user_message]\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=messages,\n",
    "        tools=ToolHelpers.from_functions(tools),\n",
    "        tool_choice=\"auto\",\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    use_tool = (\n",
    "        completion.choices[0].finish_reason == \"tool_calls\"\n",
    "        or completion.choices[0].message.tool_calls\n",
    "    )\n",
    "    function_metadata = FunctionMetadata(\n",
    "            fn_name=completion.choices[0].message.tool_calls[0].function.name,\n",
    "            fn_args=json.loads(\n",
    "                completion.choices[0].message.tool_calls[0].function.arguments\n",
    "            ),\n",
    "    )\n",
    "    fn_result, products = execute_tool(function_metadata, cart, catalog)\n",
    "    print(f\"Function: {function_metadata.fn_name}\")\n",
    "    print(f\"Arguments: {function_metadata.fn_args}\")\n",
    "    print(f\"Results: {fn_result.fn_result}\")\n",
    "    print(\"-\" * 79)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b9d4a9-ca2e-4905-990e-ec06d40ba6e5",
   "metadata": {},
   "source": [
    "### Product Advisor <a name=\"product-advisor\"></a>\n",
    "\n",
    "Building upon the previous sections, let's put it all together. We've provided a helper `ProductAdvisor` utility class that takes several inputs and exposes `.chat(...)` method to make interacting with the Product Advisor easier. We also implement logic to use the results of our tools to inform how the LLM should respond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a24f683-d4a5-41bc-b7ea-d23ea50bcd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "cart = Cart()\n",
    "catalog = Catalog(\"/debug/data/gear-store.csv\")\n",
    "\n",
    "product_advisor = ProductAdvisor(client=client, cart=cart, catalog=catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "515b0152-cc7e-4eb8-909a-fce62a48bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "        Message(role=\"system\", content=\"You are an AI chatbot that helps customers answer questions about products.\"),\n",
    "        Message(role=\"user\", content=\"Hello!\"),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed2cae79-803a-4509-b35b-07b1d629e7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function: None\n",
      "Arguments: None\n",
      "Response: Hello! I'm glad you've reached out for assistance. I'm here to help answer any questions you have about our products. What can I help you with today?\n"
     ]
    }
   ],
   "source": [
    "# Should respond normally without calling a specific tool\n",
    "messages, fn_metadata, products = product_advisor.chat(messages)\n",
    "\n",
    "print(f\"Function: {fn_metadata.fn_name}\")\n",
    "print(f\"Arguments: {fn_metadata.fn_args}\")\n",
    "print(f\"Response: {messages[-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0aee60d2-4c1d-488c-8c86-b8a8f3917dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function: None\n",
      "Arguments: None\n",
      "Products: []\n",
      "Response: Hello! I'm glad you've reached out for assistance. I'm here to help answer any questions you have about our products. What can I help you with today?\n",
      "-------------------------------------------------------------------------------\n",
      "Function: search\n",
      "Arguments: {'query': 'coffee mug'}\n",
      "Products: ['14 OZ. NVIDIA LOGO MUG', '14 OZ. VISUAL PURR-CEPTION MUG']\n",
      "Response: Sure, I'd be happy to help you find a coffee mug! Here are two options that you might like:\n",
      "\n",
      "1. The 14 OZ. NVIDIA LOGO MUG is a 14 oz. ceramic mug with a barrel design, large handle, matte exterior finish, and gloss colored interior. It is hand wash recommended and microwave safe. This mug is priced at $7.50 and has a rating of 4.54 out of 5. You can find more information and purchase it here: <https://gear.nvidia.com/14-oz-NVIDIA-Logo-Mug-P228.aspx>\n",
      "2. The 14 OZ. VISUAL PURR-CEPTION MUG is a 14 oz. deep learning mug inspired by NVIDIA Engineer Robert Bond. It features a cute cat design and is hand wash recommended. Please note that this mug cannot be shipped to APAC. It is priced at $12.00 and has a rating of 4.4 out of 5. You can find more information and purchase it here: <https://gear.nvidia.com/14-oz-Visual-Purr-Ception-Mug-P614.aspx>\n",
      "\n",
      "I hope this helps you find the perfect coffee mug! Let me know if you have any other questions.\n",
      "-------------------------------------------------------------------------------\n",
      "Function: add_to_cart\n",
      "Arguments: {'name': 'NVIDIA LOGO MUG', 'quantity': 1}\n",
      "Products: []\n",
      "Response: Sure, I can help with that! It appears that 1 unit of the NVIDIA LOGO MUG has already been added to your cart. If you would like to add more, just let me know the quantity you would like to add. If you're ready to proceed to checkout, simply let me know and I can guide you through the process.\n",
      "-------------------------------------------------------------------------------\n",
      "Function: modify_item_in_cart\n",
      "Arguments: {'name': 'NVIDIA LOGO MUG', 'quantity': 3}\n",
      "Products: []\n",
      "Response: Of course! Your cart has been updated. You now have 3 units of NVIDIA LOGO MUG in your cart. If you have any other requests or need further assistance, please let me know.\n",
      "-------------------------------------------------------------------------------\n",
      "Function: view_cart\n",
      "Arguments: {}\n",
      "Products: []\n",
      "Response: It looks like there is 1 item in your cart:\n",
      "\n",
      "1. NVIDIA LOGO MUG (Quantity: 3)\n",
      "\n",
      "Is there anything else you would like to do, such as updating the quantity of an item, removing an item, or continuing to shop?\n",
      "-------------------------------------------------------------------------------\n",
      "Function: remove_from_cart\n",
      "Arguments: {'name': 'NVIDIA LOGO MUG'}\n",
      "Products: []\n",
      "Response: Of course! I have removed the NVIDIA LOGO MUG from your cart. You no longer have any units of this item in your cart. If you have any other requests or questions, feel free to ask!\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Let's test different scenarios that might trigger each of our tools\n",
    "user_messages = [\n",
    "    \"Hello!\",  # respond normally\n",
    "    'Can help me find a coffee mug?',  # search\n",
    "    'Can you add NVIDIA LOGO MUG to my cart?',  # add_to_cart\n",
    "    'Actually, can you change that to 3 units of NVIDIA LOGO MUG?',  # modify_item_in_cart\n",
    "    \"What's in my cart?\",  # view_cart\n",
    "    'On second thought, can you remove the NVIDIA LOGO MUG from my cart?',  # remove_from_cart\n",
    "]\n",
    "\n",
    "for user_message in user_messages:\n",
    "    messages = [\n",
    "        Message(role=\"system\", content=\"You are an AI chatbot that helps customers answer questions about products.\"),\n",
    "        Message(role=\"user\", content=user_message),\n",
    "    ]\n",
    "    messages, fn_metadata, products = product_advisor.chat(messages)\n",
    "\n",
    "    print(f\"Function: {fn_metadata.fn_name}\")\n",
    "    print(f\"Arguments: {fn_metadata.fn_args}\")\n",
    "    print(f\"Products: {[p.name for p in products]}\")\n",
    "    print(f\"Response: {messages[-1].content}\")\n",
    "    print(\"-\" * 79)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ece4a79-8f8e-478d-8126-eaa3ddf8d1a3",
   "metadata": {},
   "source": [
    "### Deployment with FastAPI and React <a name=\"deployment\"></a>\n",
    "\n",
    "Finally, we deploy the Product Advisor using a FastAPI backend and a React application frontend.\n",
    "\n",
    "```bash\n",
    "# build and run both services\n",
    "docker-compose build chatbot-service frontend-service\n",
    "docker-compose up -d chatbot-service frontend-service\n",
    "\n",
    "# inspect logs\n",
    "docker-compose logs -f chatbot-service\n",
    "docker-compose logs -f frontend-service\n",
    "```\n",
    "\n",
    "Navigate to [http://localhost:3000](http://localhost:3000) for the frontend.\n",
    "\n",
    "Navigate to [http://localhost:5001/docs](http://localhost:5001/docs) for documentation for the backend."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
