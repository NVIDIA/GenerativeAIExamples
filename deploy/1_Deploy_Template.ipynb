{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f4957c0-ed97-4ab5-baf8-dc91d75b2e6c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Let’s strive to create better notebooks for Blueprints. It doesn’t take much extra effort and it pays off greatly. This template provides NVIDIAian's standards so that we can all adopt better habits.  There are a few simple rules for writing effective notebooks:\n",
    "\n",
    "- Name your notebooks intutively.  If notebooks need to be executed in certain order, use numbers within the title.\n",
    "- Add clear yet concise explanations of what NVIDIA NIMs are used and what your code does, how it works, what are the most important results, and what conclusions were drawn.\n",
    "- Use the markdown cells effectively to describe what each code cell is doing. It’s not just the code that speaks; the text around it that says why this is essential, what the results signify, or why a specific coding approach was taken.\n",
    "\n",
    "Since there should a deployment notebook for every blueprint, this notebook serves as template for best practices.  Please make a copy of this notebook and modify content within the predetermined section headings as appropriate.    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e60cb36-f153-4991-a31f-702f11144446",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0f2acb-52d9-49dd-9676-2d58715786f5",
   "metadata": {},
   "source": [
    "> Describe what is achieved within notebook. This should be very brief but provide enough context to blueprint goal.\n",
    "> \n",
    "This notebook will deploy the AI virtual assistant for customer service NIM Agent Blueprint.  You will install the neccessary prerequisities, spin up the NVIDIA NeMo Retriever™ and NVIDIA NIM™ microservices on a single node, and download sample data.  Once deployed, you will have a fully functional reference UI as well as sample code which you can personalize Q&A responses based on structured and unstructured data, such as order history and product details. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8c7758-746f-4e00-8a28-cbdc463a7925",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    ">[Prerequisites](#Prerequisites)  \n",
    ">[Spin Up Blueprint](#Spin-Up-Blueprint)  \n",
    ">[Download Sample Data](#Download-Sample-Data)  \n",
    ">[Validate Deployment](#Validate-Deployment)  \n",
    ">[API Reference](#API-Reference)  \n",
    ">[Next Steps](#Next-Steps)  \n",
    ">[Shutting Down Blueprint](#Stopping-Services-and-Cleaning-Up)  \n",
    ">[Appendix](#Appendix)  \n",
    "________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6fcc47-fb41-4e54-9d30-4d17bc483779",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09678c9-8fbe-41d7-84ad-ce624bec582c",
   "metadata": {},
   "source": [
    "### Clone repository and install software"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0ded68-437d-4ad2-be82-b36ff6100b30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "1. **Clone** <name> Git repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197704e-b63c-42fc-be4b-4f3fb03acfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone ssh://git@gitlab-master.nvidia.com:12051/chat-labs/OpenSource/ai-virtual-assistant.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c2b89e-f8c3-458e-88a4-ecfac63a9916",
   "metadata": {},
   "source": [
    "2. Install **[Docker](https://docs.docker.com/engine/install/ubuntu/)**\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Tip:</b> Ensure the Docker Compose plugin version is 2.29.1 or higher.  Run docker compose version to confirm. Refer to Install the Compose plugin Docker documentation for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb8d198-db10-4529-b76b-14f0c5cf216d",
   "metadata": {},
   "source": [
    "3. Install **[NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installing-the-nvidia-container-toolkit)** to configure Docker for GPU-accelerated containers, for example Milvus, NVIDIA NIM.\n",
    " If you are using a system deployed with Brev you can skip this step since Brev systems come with NVIDIA Container Toolkit preinstalled. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220b33bb-eade-43ec-806a-1d1dcdc7e773",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> After installing the toolkit, follow the instructions in the Configure Docker section in the NVIDIA Container Toolkit documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8257c542-dc3d-49ba-8725-d7ae4ebbb14c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Tip:</b> Step 3 is considered optional since by default the blueprint uses the NVIDIA API Catalog hosted NIM API endpoints for LLM, embedding and reranking models.  But once you familiarize yourself with the blueprint, you will most likely want to deploy with NIMs on-prem so you can customize based upon your use case.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d26d7bf-0044-45c4-bace-18b63c41dd04",
   "metadata": {},
   "source": [
    "### Get a API Keys\n",
    "\n",
    "#### Let's start by logging into the NVIDIA Container Registry. \n",
    " \n",
    "The NVIDIA NGC API Key is a mandatory key that is required to use this blueprint. This is needed to log into the NVIDIA container registry, nvcr.io, and to pull secure container images used in this NVIDIA NIM Blueprint.\n",
    "Refer to [Generating NGC API Keys](https://docs.nvidia.com/ngc/gpu-cloud/ngc-user-guide/index.html#generating-api-key) in the NVIDIA NGC User Guide for more information.\n",
    "\n",
    "\n",
    "\n",
    "Authenticate with the NVIDIA Container Registry with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbe4bca-f542-4610-8424-0b97a57237db",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker login nvcr.io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1441d659-be45-422e-a732-530750286da7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> Use oauthtoken as the username and your API key as the password. The $oauthtoken username is a special name that indicates that you will authenticate with an API key and not a user name and password.After installing the toolkit, follow the instructions in the Configure Docker section in the NVIDIA Container Toolkit documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cec102b-21d3-441c-a1a8-e72dbfc6c6fd",
   "metadata": {},
   "source": [
    "#### Next, let's set the NVIDIA API Catalog key. \n",
    "\n",
    "This NVIDIA API Catalog key will be used to access cloud hosted models in API Catalog.\n",
    "\n",
    "You can use different model API endpoints with the same API key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd47fa8f-7b46-4188-aa77-73d57438058c",
   "metadata": {},
   "source": [
    "1. Navigate to **[NVIDIA API Catalog](https://build.nvidia.com/explore/discover)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b707189-4848-4ebc-ab4e-d55d7084bff5",
   "metadata": {},
   "source": [
    "2. Select a model, such as llama3-8b-instruct.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4217edc7-4689-4c91-8f32-59fe32d4240b",
   "metadata": {},
   "source": [
    "3. Select an **Input** option. The following example is of a model that offers a Docker option. Not all of the models offer this option, but all include a “Get API Key” link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fff83e0-cfee-4c77-910b-317f087df453",
   "metadata": {},
   "source": [
    "<img src=\"https://docscontent.nvidia.com/dims4/default/d6307a8/2147483647/strip/true/crop/1920x919+0+0/resize/2880x1378!/format/webp/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fsphinx%2F00000192-bfa6-da2c-a1f2-ffbf41aa0000%2Fnim%2Flarge-language-models%2Flatest%2F_images%2Fbuild_docker_tab.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1931c98c-4419-44e9-85d1-edb98c40d655",
   "metadata": {},
   "source": [
    "3. Click **Get API Key**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed353f53-1998-413c-9a64-1bcaad83913c",
   "metadata": {},
   "source": [
    "<img src=\"https://docscontent.nvidia.com/dims4/default/c6e2096/2147483647/strip/true/crop/1920x919+0+0/resize/2880x1378!/format/webp/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fsphinx%2F00000192-bfa6-da2c-a1f2-ffbf41aa0000%2Fnim%2Flarge-language-models%2Flatest%2F_images%2Fbuild_get_api_key.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5764837f-217c-43db-b48b-30ce34b6daf4",
   "metadata": {},
   "source": [
    "4. Select **\"Generate Key\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e5065b-0472-4947-a4b1-be13cace84d1",
   "metadata": {},
   "source": [
    "<img src=\"https://docscontent.nvidia.com/dims4/default/e7c4057/2147483647/strip/true/crop/1920x919+0+0/resize/2880x1378!/format/webp/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fsphinx%2F00000192-bfa6-da2c-a1f2-ffbf41aa0000%2Fnim%2Flarge-language-models%2Flatest%2F_images%2Fbuild_generate_key.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646b06b0-c691-4c0e-b288-19d3fa7ca109",
   "metadata": {},
   "source": [
    "5. **Copy your key** and store it in a secure place. Do not share it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8e6fdc-e035-44b9-87c8-3564f00b01ad",
   "metadata": {},
   "source": [
    "<img src=\"https://docscontent.nvidia.com/dims4/default/4b0710a/2147483647/strip/true/crop/1920x919+0+0/resize/2880x1378!/format/webp/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fsphinx%2F00000192-bfa6-da2c-a1f2-ffbf41aa0000%2Fnim%2Flarge-language-models%2Flatest%2F_images%2Fbuild_copy_key.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d68974-f114-4763-badb-9a158582f2e3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Tip:</b> The key begins with the letters nvapi-."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8edd67a-83b0-48fb-99bd-589c484cc761",
   "metadata": {},
   "source": [
    "6. Export the API Key as an environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc799586-6a85-4f18-bc3f-f3a778509606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "if not os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    nvidia_api_key = getpass.getpass(\"Enter your NVIDIA API key: \")\n",
    "    assert nvidia_api_key.startswith(\"nvapi-\"), f\"{nvidia_api_key[:5]}... is not a valid key\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvidia_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa7f3c4-d8c3-4b96-bb43-5c15c4c4918b",
   "metadata": {},
   "source": [
    "## Spin Up Blueprint\n",
    "Docker compose scripts are provided which spin up the microservices on a single node.  This docker-compose yaml file will start the agents as well as dependant microservices.  This may take up to **15 minutes** to complete.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd0ca5f-24c0-41a1-ab34-a4976239f1d9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Tip:</b> Refer to the deploy/compose/docker-compose.yaml for complete details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea67b59-4575-4289-ac12-c7c375155bf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!docker compose -f ai-virtual-assistant-main/deploy/compose/docker-compose.yaml up -d --build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e88f196-e021-4f91-ba04-7f823f348a34",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Tip:</b> If you would like to monitor progress, refer to https://docs.docker.com/reference/cli/docker/compose/logs/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976a7d5e-4b53-493e-aabd-13f7447a2ac0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> By default, the blueprint uses the NVIDIA API Catalog hosted endpoints for LLM, embedding and reranking models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430c6e5d-0804-45be-97cc-2c7b45bbb903",
   "metadata": {},
   "source": [
    "To validate the deployment of the blueprint, execute the following command to ensure the container are running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cf647f-0f0b-45e2-959b-d96b013169a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps --format \"table {{{{.ID}}}}\\t{{{{.Names}}}}\\t{{{{.Status}}}}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d90c358-f0e9-4607-8b88-32a44ffce74e",
   "metadata": {},
   "source": [
    "This command should produce similiar output in the following format:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f71f3651-f6d1-461b-bd3b-c370339e8ed3",
   "metadata": {},
   "source": [
    "CONTAINER ID   NAMES                       STATUS\n",
    "e6e1f6ebec3c   agent-playground            Up 3 hours\n",
    "b6a1853c4e81   agent-chain-server          Up 3 hours\n",
    "91487a937be1   analytics-server            Up 3 hours\n",
    "0112183489fe   unstructured-retriever      Up 3 hours\n",
    "9970bb569dbd   structured-retriever        Up 3 hours\n",
    "4ea1a3267a17   milvus-standalone           Up 3 hours\n",
    "c988dcdd67c3   postgres_container          Up 3 hours (healthy)\n",
    "3dc1c2262903   milvus-minio                Up 3 hours (healthy)\n",
    "eee52b7302fb   milvus-etcd                 Up 3 hours (healthy)\n",
    "907f5702f82b   compose-redis-1             Up 3 hours\n",
    "fcde431d44de   pgadmin_container           Up 3 hours\n",
    "f2ce39cf3027   compose-redis-commander-1   Up 3 hours (healthy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27c36ae-80a5-4213-9f37-3e76aff3201d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> The Nemo microservices are not listed since hosted endpoints are being used for LLM, embedding and reranking models.  Once you familiarize yourself with the blueprint and you want to deploy these NIM microservices locally, refer to the Appendix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2293d461-8cd1-48fb-bce7-dbf8515ea3f4",
   "metadata": {},
   "source": [
    "## Download Sample Data\n",
    "This blueprint comes with synthetic sample data representing a typical customer service function, including customer profiles, order histories (structured data). Next you will download technical product manuals (unstructured data) from the internet into data/manuals_pdf folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc3a2b6-8930-412d-8a6f-678fad2de97c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run this script to download the manuals listed in the specified txt file\n",
    "! ai-virtual-assistant-main/data/download.sh ai-virtual-assistant-main/data/list_manuals.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc415227-fb1d-49ea-bb38-7d6d1b3fc2fb",
   "metadata": {},
   "source": [
    "Verify the manuals have been downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d03ff8e-564b-440e-8d9f-8d3b2a7b752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls ai-virtual-assistant-main/data/manuals_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8e28fd-3b90-45bc-a02e-ff06ff322e44",
   "metadata": {},
   "source": [
    "## Data Ingestion\n",
    "\n",
    "Go to the notebooks folder inside the repo and run through the `ingest_data.ipynb` notebook.\n",
    "\n",
    "This notebook does the following: \n",
    "1. Uploades Unstructured Data (PDF) to Milvus DB. These are the PDFs we downloaded above which contain product information. \n",
    "2. Uploads Structured Data (CSV) Ingestion to Postgres DB. These CSV files contain information about the gear store (e.g. product names, category, prices) and previous orders (e.g. order ID, order date, return status)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d942805f-f317-48f8-9d74-51e125ba50b4",
   "metadata": {},
   "source": [
    "## Validate Deployment\n",
    "The blueprint includes a reference UI and an AI assistant (developed using the LangGraph framework) that leverages sub-agents to handle queries from both structured and unstructured data sources.  Let's make sure the API endpoint and UI is up and running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c632e589-9771-4468-a737-60bb297744b6",
   "metadata": {},
   "source": [
    "1. Create a new session using the create_session API at `http://<HOST-IP>:8081/docs#/default/create_session_create_session_get`\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> If you are using an environment deployed with Brev, make sure to expose the port 8081 on your Brev console. A HTTP URL will be generated for each public port, so open the link and append `/docs#/default/create_session_create_session_get` after the port number.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb89fb0-2976-4d99-991e-148dd132f819",
   "metadata": {},
   "source": [
    "2. To test queries, visit the UI at `http://<HOST-IP>:8090`\n",
    "\n",
    "Ensure you specify user_id and session_id in their respective fields. Use session_id from create_session response, and user_id from order.csv\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> Again, if you are using an environment deployed with Brev, make sure to expose port 8090 on your Brev console and use the HTTP URL created. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73a4212-3150-418e-9ac4-04f610a9fb59",
   "metadata": {},
   "source": [
    "3. After testing queries, end the session at `http://<HOST-IP>:8081/docs#/default/end_session_end_session_get`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d09d930-2be2-4b99-82d8-5411820b0a61",
   "metadata": {},
   "source": [
    "4. Explore the analytics server API at `http://<HOST-IP>:8082/docs#/`\n",
    "\n",
    "This server offers three APIs\n",
    "\n",
    "- `/sessions` - Lists all sessions from the last k hours\n",
    "- `/session/summary` - Provides summary and sentiment analysis for a given session's conversation\n",
    "- `/session/conversation`x\n",
    "-  - Offers sentiment analysis for individual queries and responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d774fc0-3b2c-4482-83c4-cbfa32851eae",
   "metadata": {},
   "source": [
    "## API Reference\n",
    "\n",
    "For detailed API references, please refer to the following locations in the Blueprint repository:\n",
    "- Summary & Conversation APIs:\n",
    "`./docs/api_references/analytics_server.json`\n",
    "\n",
    "- Generate API:\n",
    "`./docs/api_references/agent_server.json`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c24f9a7",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "Go to the Synthetic Data Generation notebook. This notebook demonstrates how to use the nemotron-4-340b-instruct model for synthetic data generation that is used in this blueprint. It uses the nvidia gear store data as a source of product data. Then, it then creates a sample customer set and a realistic order history based on the nvidia gear store data.\n",
    "You can follow a similar process to create your own data, which you can then upload to the knowledge base in the Data Ingestion notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23cdd4d-2f22-46c1-ab94-99847c1c7dbb",
   "metadata": {},
   "source": [
    "## Stopping Services and Cleaning Up\n",
    "\n",
    "To shut down the microservices, run the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b77f00-0fb3-4287-9503-9435f3da4b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker compose -f ai-virtual-assistant-release-1.0.0/deploy/compose/docker-compose.yaml down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7239d79e-d6a4-491c-bd7f-289e479078cc",
   "metadata": {},
   "source": [
    "## Appendix \n",
    "\n",
    "### Deploy NIM microservices locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb39e5c8-0b49-4661-9c60-0b4483095165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model directory to download model from NGC\n",
    "!mkdir -p ~/.cache/models\n",
    "!export MODEL_DIRECTORY=~/.cache/models/\n",
    "\n",
    "# export you ngc api key, note it's not nvidia_api_key from build.nvidia.com\n",
    "!export NGC_API_KEY=<ngc-api-key>\n",
    "!export USERID=\"$(id -u):$(id -g)\"\n",
    "\n",
    "# Export path where NIMs are hosted\n",
    "# LLM server path\n",
    "!export APP_LLM_SERVERURL=nemollm-inference:8000\n",
    "# Embedding server path\n",
    "!export APP_EMBEDDINGS_SERVERURL=nemollm-embedding:8000\n",
    "# Re-ranking model path\n",
    "!export APP_RANKING_SERVERURL=ranking-ms:8000\n",
    "\n",
    "!docker compose -f deploy/compose/docker-compose.yaml --profile local-nim up -d --build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f447017e-2fdc-4b33-b5ff-3ba6ccc8dd62",
   "metadata": {},
   "source": [
    "To validate, execute the following command to ensure the container are running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a53ce-bf27-4c2a-9e44-84539e9a5f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker ps --format \"table {{.ID}}\\t{{.Names}}\\t{{.Status}}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d17427-dad4-4ff6-81e2-4c4c0c60ecf9",
   "metadata": {},
   "source": [
    "This command should produce similiar output in the following format:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5b74980-ded1-4d21-9675-7000a2af6793",
   "metadata": {},
   "source": [
    "CONTAINER ID   NAMES                                   STATUS\n",
    "1dd42caad60e   agent-chain-server                      Up 55 minutes\n",
    "766acb5fb57c   agent-playground                        Up 55 minutes\n",
    "4c4d1136cd7a   structured-retriever                    Up 3 hours\n",
    "ff2f71eb9d75   unstructured-retriever                  Up 3 hours\n",
    "fd70635efcac   analytics-server                        Up 3 hours\n",
    "8fc99cf27945   nemo-retriever-ranking-microservice     Up 3 hours (healthy)\n",
    "d3853cc6b622   nemo-retriever-embedding-microservice   Up 3 hours (healthy)\n",
    "dcc22f20df1f   nemollm-inference-microservice          Up 3 hours (healthy)\n",
    "b4cfafffa57b   milvus-standalone                       Up 3 hours\n",
    "dfdaa5ff59be   postgres_container                      Up 3 hours (healthy)\n",
    "8787645d8b4f   milvus-minio                            Up 3 hours (healthy)\n",
    "caa2e19b030b   pgadmin_container                       Up 3 hours\n",
    "77b4fb45d600   milvus-etcd                             Up 3 hours (healthy)\n",
    "5be79d19281e   compose-redis-1                         Up 3 hours\n",
    "6a5353baa2d1   compose-redis-commander-1               Up 3 hours (healthy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88c1421-e582-4f09-9fee-522eb498a404",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> By default, GPU IDs 0-3 are for LLM, 4 for the embedding model, and 5 for the reranking model.\n",
    "    \n",
    ">To change the GPUs used for NIM deployment, set the following environment variables:\n",
    "\n",
    ">>**LLM_MS_GPU_ID**: Update this to specify the LLM GPU IDs (e.g., 0,1,2,3).\n",
    "\n",
    ">>**EMBEDDING_MS_GPU_ID**: Change this to set the embedding GPU ID.\n",
    ">>\n",
    ">>**RANKING_MS_GPU_ID**: Modify this to adjust the reranking LLM GPU ID."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
