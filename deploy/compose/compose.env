# Path where models will be stored
# NOTE: This should be an absolute path and not relative path
export MODEL_DIRECTORY="/home/ubuntu/model-cache"

# GPU id which nemo embedding ms will use
# export EMBEDDING_MS_GPU_ID=0

# To control which GPU the vector database uses, specify the device ID.
# export VECTORSTORE_GPU_DEVICE_ID=0

# GPU id which ranking ms will use (Make sure it is different from the one used for nim ms)
# export RANKING_MS_GPU_ID=1

# Fill this out if you dont have a GPU. Leave this empty if you have a local GPU
export NVIDIA_API_KEY=${NVIDIA_API_KEY}

# [OPTIONAL] the number of GPUs to make available to the inference server
# export INFERENCE_GPU_COUNT="all"

# [OPTIONAL] the base directory inside which all persistent volumes will be created
# export DOCKER_VOLUME_DIRECTORY="."


# name of the nemo embedding model
# Both arctic-embed-l & NV-Embed-QA are versions of e5-large-unsupervised
export APP_EMBEDDINGS_MODELNAME="NV-Embed-QA"
export EMBEDDING_MODEL_CKPT_NAME="snowflake-arctic-embed-l"
export EMBEDDING_MODEL_PATH="https://huggingface.co/Snowflake/snowflake-arctic-embed-l"

# name of the nemo re-rank model
export RANKING_MODEL_NAME="NV-Rerank-QA-Mistral-4B"
export RANKING_MODEL_CKPT_NAME="nv-rerank-qa-mistral-4b_v2"
export RANKING_MODEL_PATH="ohlfw0olaadg/ea-participants/nv-rerank-qa-mistral-4b:2"

# name of the nemo retriever pipeline one of ranked_hybrid or hybrid
NEMO_RETRIEVER_PIPELINE="ranked_hybrid"

# parameters for PGVector, update this when using PGVector Vector store
# export POSTGRES_PASSWORD=password
# export POSTGRES_USER=postgres
# export POSTGRES_DB=api

# Update this line when using an external PGVector Vector store
# export POSTGRES_HOST_IP=pgvector
# export POSTGRES_PORT_NUMBER=5432

### Riva Parameters:

# Riva Speech API URI: Riva Server IP address/hostname and port
export RIVA_API_URI=""

# [OPTIONAL] Riva Speech API Key
# If necessary, enter a key to access the Riva API
export RIVA_API_KEY=""

# [OPTIONAL] Riva Function ID
# If necessary, enter a function ID to access the Riva API
export RIVA_FUNCTION_ID=""

# TTS sample rate (Hz)
export TTS_SAMPLE_RATE=48000

# the config file for the OpenTelemetry collector
export OPENTELEMETRY_CONFIG_FILE="./configs/otel-collector-config.yaml"
# the config file for Jaeger
export JAEGER_CONFIG_FILE="./configs/jaeger.yaml"

# [OPTIONAL] Set the logging level for the chain server. Possible values are NOTSET, DEBUG, INFO, WARN, ERROR, CRITICAL.
export LOGLEVEL="INFO"

# User permissoin for containers
export DOCKER_USER=$(id -u):$(id -g)

# Download script path, this will be mounted at runtime
export DOWNLOAD_SCRIPT=$PWD/deploy/compose/download_model.sh
