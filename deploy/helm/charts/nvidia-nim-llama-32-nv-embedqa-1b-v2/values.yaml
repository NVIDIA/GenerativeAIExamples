## @section Deployment parameters
## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity
## @param affinity [object] [default: {}] Affinity settings for deployment.
affinity: {}

## @param containerSecurityContext [object] Sets privilege and access control settings for container (Only affects the main container, not pod-level)
containerSecurityContext: {}
  # seLinuxOptions: null
  # runAsUser: 1001
  # runAsGroup: 1001
  # runAsNonRoot: true
  # privileged: false
  # readOnlyRootFilesystem: false
  # allowPrivilegeEscalation: false
  # capabilities:
  #   drop:
  #     - ALL
  # seccompProfile:
  #   type: "RuntimeDefault"

## @param customCommand [array] Overrides command line options sent to the NIM with the array listed here.
## For advanced use if necessary only
customCommand: []

## @param customArgs [array] Overrides command line arguments of the NIM container with the array listed here.
## For advanced use if necessary only
customArgs: []

## @param envVars [object] Adds arbitrary environment variables to the main container using key-value pairs, for example NAME: value
envVars: {}

## @param extraVolumes [object] Adds arbitrary additional volumes to the deployment set definition
extraVolumes: {}
  # my-volume-name:
  #   emptyDir: {}

## @param extraVolumeMounts [object] Specify volume mounts to the main container from `extraVolumes`
extraVolumeMounts: {}
  # my-volume-name:
  #   mountPath: /mnt/myvolume

## @param image.repository [string] NIM-LLM Image Repository
## @param image.tag [string] Image tag or version
## @param image.pullPolicy [string] Image pull policy
image:
  repository: nvcr.io/nim/nvidia/llama-3.2-nv-embedqa-1b-v2
  pullPolicy: IfNotPresent
  # Tag overrides the image tag whose default is the chart appVersion.
  tag: 1.3.0

## @extra imagePullSecrets Specify list of secret names that are needed for the main container and any init containers.
## @skip imagePullSecrets[0].name
imagePullSecrets:
- name: ngc-secret    # change this to whatever your image pull secret should be

## @param initContainers [object] Specify init containers, if needed.`initContainers` are defined as an object with the name of the container as the key. All other elements of the `initContainer` definition are the value.
initContainers: {}
  # my-init:
  #   image: busybox
  #   command: ["/bin/sh", "-c"]
  #   args:
  #     - "while true;do sleep 40; done"

## @param nodeSelector [object] Sets node selectors for the NIM -- for example `nvidia.com/gpu.present: "true"`
nodeSelector: {}  # likely best to set this to `nvidia.com/gpu.present: "true"` depending on cluster setup

## @param podAnnotations [object] Sets additional annotations on the main deployment pods
podAnnotations: {}

## @extra podSecurityContext Specify privilege and access control settings for pod
## @param podSecurityContext.runAsUser Specify user UID for pod.
## @param podSecurityContext.runAsGroup Specify group ID for pod.
## @param podSecurityContext.fsGroup Specify file system owner group id.
podSecurityContext:
  runAsUser: 1000
  runAsGroup: 1000
  fsGroup: 1000

## @param replicaCount Specify static replica count for deployment.
replicaCount: 1

## @extra resources [object] Specify resources limits and requests for the running service.
## @param resources.limits.nvidia.com/gpu Specify number of GPUs to present to the running service.
resources:
  limits:
    nvidia.com/gpu: 1  # Number of GPUs to present to the running service

## @exta serviceAccount Options to specify service account for the deployment.
## @param serviceAccount.create Specifies whether a service account should be created.
## @param serviceAccount.annotations [object] Sets annotations to be added to the service account.
## @param serviceAccount.name Specifies the name of the service account to use. If it is not set and create is `true`, a name is generated using a `fullname` template.
serviceAccount:
  # Specifies whether a service account should be created
  create: false
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is `true`, a name is generated using the `fullname` template
  name: ''

## @param statefulSet.enabled Enables `statefulset` deployment. Enabling `statefulSet` allows PVC templates for scaling. If using central PVC with RWX `accessMode`, this isn't needed.
statefulSet:
  enabled: false

## @extra tolerations Specify tolerations for pod assignment. Allows the scheduler to schedule pods with matching taints.
## @skip tolerations[0].key
## @skip tolerations[0].operator
## @skip tolerations[0].effect
tolerations:
- key: nvidia.com/gpu
  operator: Exists
  effect: NoSchedule


## @section Autoscaling parameters
## @descriptionStart
## Values used for creating a `Horizontal Pod Autoscaler`. If autoscaling is not enabled, the rest are ignored.
## NVIDIA recommends usage of the custom metrics API, commonly implemented with the prometheus-adapter.
## Standard metrics of CPU and memory are of limited use in scaling NIM.
## @descriptionEnd
## @param autoscaling.enabled Enables horizontal pod autoscaler.
## @param autoscaling.minReplicas Specify minimum replicas for autoscaling.
## @param autoscaling.maxReplicas Specify maximum replicas for autoscaling.
## @param autoscaling.metrics Array of metrics for autoscaling.
autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 10
  metrics: []


## @section Ingress parameters
## @param ingress.enabled Enables ingress.
## @param ingress.className Specify class name for Ingress.
## @param ingress.annotations Specify additional annotations for ingress.
## @extra ingress.hosts Specify list of hosts each containing lists of paths.
## @param ingress.hosts[0].host Specify name of host.
## @param ingress.hosts[0].paths[0].path Specify ingress path.
## @param ingress.hosts[0].paths[0].pathType Specify path type.
## @param ingress.tls Specify list of pairs of TLS `secretName` and hosts.
ingress:
  enabled: false
  className: ''
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
  - host: chart-example.local
    paths:
    - path: /
      pathType: ImplementationSpecific

  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local


## @section Probe parameters
## @param livenessProbe.enabled Enables `livenessProbe``
## @param livenessProbe.method choose either `httpGet` or `script`
## @param livenessProbe.path `LivenessProbe`` endpoint path
## @param livenessProbe.initialDelaySeconds Initial delay seconds for `livenessProbe`
## @param livenessProbe.timeoutSeconds Timeout seconds for `livenessProbe`
## @param livenessProbe.periodSeconds Period seconds for `livenessProbe`
## @param livenessProbe.successThreshold Success threshold for `livenessProbe`
## @param livenessProbe.failureThreshold Failure threshold for `livenessProbe`
livenessProbe:
  enabled: true
  method: httpGet
  path: /v1/health/live  # correct for LLM container
  # method: script
  # command: # list of commands to be run
  # - cat
  # - /tmp/healthy
  initialDelaySeconds: 15
  timeoutSeconds: 1
  periodSeconds: 10
  successThreshold: 1
  failureThreshold: 3

## @param readinessProbe.enabled Enables `readinessProbe`
## @param readinessProbe.method choose either `httpGet` or `script`
## @param readinessProbe.path Readiness Endpoint Path
## @param readinessProbe.initialDelaySeconds Initial delay seconds for `readinessProbe`
## @param readinessProbe.timeoutSeconds Timeout seconds for `readinessProbe`
## @param readinessProbe.periodSeconds Period seconds for `readinessProbe`
## @param readinessProbe.successThreshold Success threshold for `readinessProbe`
## @param readinessProbe.failureThreshold Failure threshold for `readinessProbe`
readinessProbe:
  enabled: true
  method: httpGet
  path: /v1/health/ready  # correct for LLM container
  # method: script
  # command: # list of commands to be run
  # - cat
  # - /tmp/healthy
  initialDelaySeconds: 15
  timeoutSeconds: 1
  periodSeconds: 10
  successThreshold: 1
  failureThreshold: 3

## @param startupProbe.enabled Enables `startupProbe`
## @param startupProbe.method choose either `httpGet` or `script`
## @param startupProbe.path `StartupProbe` Endpoint Path
## @param startupProbe.initialDelaySeconds Initial delay seconds for `startupProbe`
## @param startupProbe.timeoutSeconds Timeout seconds for `startupProbe`
## @param startupProbe.periodSeconds Period seconds for `startupProbe`
## @param startupProbe.successThreshold Success threshold for `startupProbe`
## @param startupProbe.failureThreshold Failure threshold for `startupProbe`
startupProbe:
  enabled: true
  method: httpGet
  path: /v1/health/ready  # correct for LLM container
  # method: script
  # command: # list of commands to be run
  # - cat
  # - /tmp/healthy
  initialDelaySeconds: 40
  timeoutSeconds: 1
  periodSeconds: 10
  successThreshold: 1
  failureThreshold: 180


## @section Metrics parameters
## @param metrics.enabled Enables metrics endpoint
## @param metrics.port For NIMs with a separate metrics port, this opens that port on the container
## @extra serviceMonitor Options for `serviceMonitor` to use the Prometheus Operator and the primary service object.
## @param metrics.serviceMonitor.enabled Enables `serviceMonitor` creation.
## @param metrics.serviceMonitor.additionalLabels [object] Specify additional labels for ServiceMonitor.
metrics:
  enabled: false
  port: 0
  serviceMonitor:  # for use with the Prometheus Operator and the primary service object
    enabled: false
    additionalLabels: {}


## @section NIM parameters
## @param nim.nimCache [string] Path to mount writeable storage or pre-filled model cache for the NIM
## @param nim.modelName [string] Optionally specifies the name of the model in the API. This can be used in helm tests.
## @param nim.ngcAPISecret [string] Name of pre-existing secret with a key named `NGC_API_KEY` that contains an API key for NGC model downloads
## @param nim.ngcAPIKey [string] NGC API key literal to use as the API secret and image pull secret when set
## @param nim.serverPort Specify other server Port.
## @param nim.httpPort Specify HTTP Port.
## @param nim.grpcPort Specify GRPC Port.
## @param nim.labels [object] Specify extra labels to be add to on deployed pods.
## @param nim.jsonLogging Whether to enable JSON lines logging. Defaults to true.
## @param nim.logLevel Log level of NIM service. Possible values of the variable are TRACE, DEBUG, INFO, WARNING, ERROR, CRITICAL.
nim:
  nimCache: /opt/nim/.cache
  modelName: ''
  ngcAPISecret: ngc-api
  ngcAPIKey: ''
  httpPort: 8000
  serverPort: 0
  grpcPort: 0
  labels: {}  # any extra labels desired on deployed pods
  jsonLogging: true
  logLevel: INFO


## @section Storage parameters
## @extra persistence Specify settings to modify the path `/model-store` if `model.legacyCompat` is enabled else `/.cache` volume where the model is served from.
## @param persistence.enabled Enables the use of persistent volumes.
## @param persistence.existingClaim Specifies an existing persistent volume claim. If using `existingClaim`, run only one replica or use a `ReadWriteMany` storage setup.
## @param persistence.storageClass [nullable] Specifies the persistent volume storage class. If set to `"-"`, this disables dynamic provisioning. If left undefined or set to null, the cluster default storage provisioner is used.
## @param persistence.accessMode Specify `accessMode`. If using an NFS or similar setup, you can use `ReadWriteMany`.
## @param persistence.stsPersistentVolumeClaimRetentionPolicy.whenDeleted Specifies persistent volume claim retention policy when deleted. Only used with Stateful Set volume templates.
## @param persistence.stsPersistentVolumeClaimRetentionPolicy.whenScaled Specifies persistent volume claim retention policy when scaled. Only used with Stateful Set volume templates.
## @param persistence.size Specifies the size of the persistent volume claim (for example 40Gi).
## @param persistence.annotations [object] Adds annotations to the persistent volume claim.
persistence:
  enabled: false
  existingClaim: ''  # if using existingClaim, run only one replica or use a `ReadWriteMany` storage setup
  storageClass: ''
  accessMode: ReadWriteOnce  # If using an NFS or similar setup, you can use `ReadWriteMany`
  stsPersistentVolumeClaimRetentionPolicy:
    whenDeleted: Retain
    whenScaled: Retain
  size: 50Gi  # size of claim in bytes (for example 8Gi)
  annotations: {}

## @extra hostPath Configures model cache on local disk on the nodes using `hostPath` -- for special cases. You should understand the security implications before using this option.
## @param hostPath.enabled Enable `hostPath`.
## @param hostPath.path Specifies path on the node used as a `hostPath` volume.
hostPath:
  enabled: false
  path: /model-store

## @extra nfs Configures the model cache to sit on shared direct-mounted NFS. NOTE: you cannot set mount options using direct NFS mount to pods without a node-intalled nfsmount.conf. An NFS-based `PersistentVolumeClaim` is likely better in most cases.
## @param nfs.enabled Enable direct pod NFS mount
## @param nfs.path Specify path on NFS server to mount
## @param nfs.server Specify NFS server address
## @param nfs.readOnly Set to true to mount as read-only
nfs:
  enabled: false
  server: nfs-server.example.com
  path: /exports
  readOnly: false

## @section Service parameters
## @param service.type Specifies the service type for the deployment.
## @param service.name Overrides the default service name
## @param service.serverPort Specifies the server Port for the service.
## @param service.httpPort Specifies the HTTP Port for the service.
## @param service.grpcPort Specifies the GRPC Port for the service.
## @param service.metricsPort Specifies the metrics port on the main service object. Some NIMs do not use a separate port.
## @param service.annotations [object] Specify additional annotations to be added to service.
## @param service.labels [object] Specifies additional labels to be added to service.
service:
  type: ClusterIP
  httpPort: 8000
  serverPort: 0
  grpcPort: 0
  metricsPort: 0
  annotations: {}
  labels: {}
  name: ''  # override the default service name


## @section ingress Specifies the ingress endpoints for the service; will be added as an env var with prefix 'ingress_'
ingress_endpoint: {}
  # ingress-endpoint-name: port_number


## @section egress Specifies the egress endpoints for the service; will be added as an env var with prefix 'egress_'
egress_endpoint: {}
  # egress-endpoint-name: port_number


## @section params Specifies the params mentioned in a separate config file inside nim-workspace dir; will be added as env var
params: {}
