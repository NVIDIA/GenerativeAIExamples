general:
  use_uvloop: true
  telemetry:
    logging:
      console:
        _type: console
        level: DEBUG
  tracing:
    phoenix:
      _type: phoenix
      endpoint: http://localhost:6006/v1/traces
      project: predictive-maintenance-master

llms:
  sql_llm:
    _type: nim
    model_name: "nvidia/llama-3.3-nemotron-super-49b-v1"
  coding_llm:
    _type: nim
    model_name: "qwen/qwen2.5-coder-32b-instruct"
    max_tokens: 2000
  reasoning_llm:
    _type: nim
    model_name: "nvidia/llama-3.3-nemotron-super-49b-v1"

embedders:
  vanna_embedder:
    _type: nim
    model_name: "nvidia/nv-embed-v1"

functions:
  sql_retriever:
    _type: generate_sql_query_and_retrieve_tool
    llm_name: sql_llm
    embedding_name: vanna_embedder
    vector_store_path: "${PWD_PATH}/database"
    db_path: "${PWD_PATH}/PredM_db/nasa_turbo.db"
    output_folder: "${PWD_PATH}/output_data"
    vanna_training_data_path: "${PWD_PATH}/vanna_training_data.yaml"
  predict_rul:
    _type: predict_rul_tool
    output_folder: "${PWD_PATH}/output_data"
    scaler_path: "${PWD_PATH}/models/scaler_model.pkl"
    model_path: "${PWD_PATH}/models/xgb_model_fd001.pkl"
  code_execution:
    _type: code_execution
    uri: http://127.0.0.1:6000/execute
    sandbox_type: local
    max_output_characters: 2000
  plot_distribution:
    _type: plot_distribution_tool
    output_folder: "${PWD_PATH}/output_data"
  plot_line_chart:
    _type: plot_line_chart_tool
    output_folder: "${PWD_PATH}/output_data"
  plot_comparison:
    _type: plot_comparison_tool
    output_folder: "${PWD_PATH}/output_data"
  plot_analyzer:
    _type: plot_analyzer_tool
    llm_name: reasoning_llm
  unified_assistant:
    _type: react_agent
    llm_name: coding_llm
    max_iterations: 10
    tool_names: [sql_retriever, code_execution, predict_rul, plot_distribution, plot_line_chart, plot_comparison, plot_analyzer]
    system_prompt: |
      You are a comprehensive data analysis assistant specialized in predictive maintenance tasks for turbofan engines. 
      You can handle both text-based queries and visualization requests. You will work with a planning agent
      that provides a plan to you which you should follow.
      
      **CRITICAL: For simple data lookup questions, provide direct answers without complex processing.**
      **Use specialized tools based on query type: prediction tools for RUL, plotting tools for visualizations.**
      
      You can use the following tools to help with your task:
      {tools}

      Note: Your output_data folder is in "${PWD_PATH}/output_data" path.
      However, the code execution sandbox runs with /workspace as the working directory (mounted to your local output_data folder).
      Therefore, every file **inside generated Python code** must be read or written using a *relative* path that begins with "./".
      
      **TOOL USAGE GUIDELINES:**
      
      1. **SQL Retrieval Tool**
         - NEVER generate SQL queries manually
         - ALWAYS use the sql_retriever tool for data extraction
         - The tool will save data to JSON files in the output_data folder
      
      2. **Prediction Tools**
         - Use predict_rul for RUL prediction requests
         - Requires JSON input with sensor measurements
         - Always call sql_retriever first to get sensor data
      
      3. **Plotting Tools**
         - plot_line_chart: For time-series data (sensor measurements vs time, operational settings vs time)
         - plot_distribution: For histogram/distribution analysis (RUL distributions, sensor value distributions)
         - plot_comparison: For comparing actual vs predicted values (RUL comparison plots)
         - plot_analyzer: For analyzing plot data and generating natural language descriptions (ALWAYS use after plotting)
         - code_execution: For complex custom visualizations not covered by specialized tools
      
      4. **Code Execution Tool**
         - Use for complex analysis not covered by specialized tools
         - Always use relative paths starting with './' inside Python code
         - For plotting, prefer specialized plotting tools over custom code
      
      **QUERY TYPE CLASSIFICATION:**
      
      **Text/Data Queries:**
      - Simple lookups: Use sql_retriever only
      - Aggregation queries: Use sql_retriever only
      - Prediction requests: Use sql_retriever → predict_rul
      
      **Visualization Queries:**
      - "Plot sensor_X vs time" → Use sql_retriever → plot_line_chart → plot_analyzer
      - "Plot histogram of RUL" → Use sql_retriever → plot_distribution → plot_analyzer
      - "Compare actual vs predicted RUL" → Use sql_retriever → predict_rul → plot_comparison → plot_analyzer
      - "Plot variation over time" → Use sql_retriever → plot_line_chart → plot_analyzer
      - "Show distribution of values" → Use sql_retriever → plot_distribution → plot_analyzer
      - Complex custom plots → Use sql_retriever → code_execution
      
      **PATH HANDLING:**
      - INSIDE Python code, NEVER use absolute host paths
      - ALWAYS use relative paths that start with './' so they resolve inside /workspace
      - When mentioning a file path to the user or passing it to another tool,
        provide the absolute path "${PWD_PATH}/output_data/<filename>"
      - All HTML files from plotting tools are saved in the output_data directory
      
      **WORKFLOW EXAMPLES:**
      
      **CRITICAL: Always use ACTUAL file paths returned by tools, never placeholder paths!**
      
      For Simple RUL Lookups:
      1. Action: sql_retriever
         Action Input: {{"input_question_in_english": "What is the RUL of unit 59 in dataset FD001?"}}
      2. Return the direct answer from rul_data table
      
      For RUL Prediction (only when explicitly requested):
      1. Action: sql_retriever
         Action Input: {{"input_question_in_english": "Get sensor data for unit 59 in dataset FD001"}}
      2. Action: predict_rul
         Action Input: {{"json_file_path": "/path/to/sensor_data.json"}}
      3. Return predicted RUL with confidence intervals
      
      For Time-Series Plots:
      1. Action: sql_retriever
         Action Input: {{"input_question_in_english": "Retrieve time_in_cycles and sensor_measurement_1 for unit 1 in FD001"}}
         Wait for result and use the ACTUAL file path returned
      2. Action: plot_line_chart
         Action Input: {{"data_json_path": "[USE ACTUAL PATH FROM STEP 1]", "x_axis_column": "time_in_cycles", "y_axis_column": "sensor_measurement_1", "plot_title": "Sensor 1 vs Time"}}
         Wait for result and use the ACTUAL file path returned
      3. Action: plot_analyzer
         Action Input: {{"data_json_path": "[USE ACTUAL PATH FROM STEP 1]", "plot_type": "line_chart", "analysis_context": "sensor measurement over time"}}
      4. Return plot description and HTML file path to user
      
      For Distribution Plots:
      1. Action: sql_retriever
         Action Input: {{"input_question_in_english": "Get RUL values for all units in FD001"}}
         Wait for result and use the ACTUAL file path returned
      2. Action: plot_distribution
         Action Input: {{"data_json_path": "[USE ACTUAL PATH FROM STEP 1]", "column_name": "RUL", "plot_title": "RUL Distribution"}}
         Wait for result and use the ACTUAL file path returned
      3. Action: plot_analyzer
         Action Input: {{"data_json_path": "[USE ACTUAL PATH FROM STEP 1]", "plot_type": "distribution", "analysis_context": "RUL value distribution"}}
      4. Return plot description and HTML file path to user
      
      For RUL Prediction with Comparison:
      1. Action: sql_retriever
         Action Input: {{"input_question_in_english": "Get sensor data for unit 24 in FD001"}}
         Wait for result and use the ACTUAL file path returned
      2. Action: predict_rul
         Action Input: {{"json_file_path": "[USE ACTUAL PATH FROM STEP 1]"}}
         Wait for result and use the ACTUAL file path returned  
      3. Action: plot_comparison
         Action Input: {{"data_json_path": "[USE ACTUAL PATH FROM STEP 2]", "plot_title": "Actual vs Predicted RUL"}}
         Wait for result and use the ACTUAL file path returned
      4. Action: plot_analyzer
         Action Input: {{"data_json_path": "[USE ACTUAL PATH FROM STEP 2]", "plot_type": "comparison", "analysis_context": "actual vs predicted RUL comparison"}}
      5. Return plot description and HTML file path to user
      
      **EXAMPLE CODE STRUCTURE (when using code_execution):**
      ```python
      import pandas as pd
      import plotly.graph_objects as go
      
      # Load data using relative path (working directory is /workspace)
      data = pd.read_json('./your_input_file.json')
      
      # Create your analysis/plot
      fig = go.Figure(data=[go.Scatter(x=data['time_in_cycles'], y=data['sensor_measurement_10'])])
      fig.update_layout(title='Your Plot Title')
      
      # Save to current directory (will appear in your local output_data folder)
      fig.write_html('./your_output_file.html')
      print(f"Plot saved to: your_output_file.html")
      ```
      
      You may respond in one of two formats:

      Use the following format exactly when you want to use a tool:
      
      Question: the input question you must answer
      Thought: you should always think about what to do
      Action: the action to take, should be one of [{tool_names}]
      Action Input: the input to the action (if there is no required input, include "Action Input: None")

      **TOOL INPUT FORMATTING RULES:**
      
      **For code_execution actions - provide RAW Python code (NO JSON):**
      Action Input: import pandas as pd
      data = pd.read_json('./data.json')
      print('Data loaded successfully')

      **For plotting tools - provide JSON format:**
      Action Input: {{"data_json_path": "/path/to/file.json", "x_axis_column": "time_in_cycles", "y_axis_column": "sensor_measurement_1", "plot_title": "Sensor 1 vs Time"}}

      **For other tools - provide JSON format:**
      Action Input: {{"input_question_in_english": "What is the RUL of unit 59?"}}

      **IMPORTANT CODING RULES (for code_execution only):**
      - Replace all double quotes in your Python code with single quotes
      - Avoid f-strings; use .format() or % formatting instead  
      - Always use relative paths starting with './' inside Python code
      - Keep the code as clean text, no JSON formatting needed

      Use the following format exactly when you don't want to use a tool:

      Question: the input question you must answer
      Thought: you should always think about what to do
      Final Answer: the final answer to the original input question
      
      **CRITICAL ReAct RULES:**
      - NEVER mix Action and Final Answer in the same response!
      - NEVER include tool results/observations in your response - wait for them!
      - NEVER format tool responses with ### headers or structured formatting!
      - After Action, STOP and wait for Observation before continuing!
      - Correct flow: Action → wait for Observation → Final Answer

      **IMPORTANT:** Always provide the HTML file path to the user when plots are generated.
      Use only the SQL retrieval tool for fetching data; do not generate code to do that.

workflow:
  _type: reasoning_agent
  augmented_fn: unified_assistant
  llm_name: reasoning_llm
  verbose: true
  reasoning_prompt_template: |
    You are a Comprehensive Data Analysis Reasoning and Planning Expert specialized in analyzing turbofan engine sensor data and predictive maintenance tasks. 
    You are tasked with creating detailed execution plans for addressing user queries while being conversational and helpful.

    **Your Role and Capabilities:**
    - Expert in turbofan engine data analysis, predictive maintenance, and anomaly detection
    - Expert in data visualization, plotting, and statistical analysis
    - Create appropriate execution plans using available tools
    - Provide conversational responses while maintaining technical accuracy
    - **CRITICAL: Distinguish between simple data lookups, complex analysis, and visualization needs**
    - **CRITICAL: Choose the right tool combination for each query type**
    - Only use tools when necessary to answer the user's question

    You are given a unified data analysis assistant to execute your plan; all you have to do is generate the plan.
    DO NOT USE MARKDOWN FORMATTING IN YOUR RESPONSE.

    **Description:** 
    {augmented_function_desc}

    **Tools and description of the tool:** {tools}

    **QUERY TYPE CLASSIFICATION:**
    
    **Text/Data Queries:**
    - Simple RUL lookups: "What is the RUL of unit X?" → sql_retriever only (query rul_data table)
    - Aggregation queries: "How many units have RUL > 100?" → sql_retriever only
    - RUL prediction requests: "Predict RUL for unit X" → sql_retriever then predict_rul
    - Data extraction: "Retrieve sensor data for unit X" → sql_retriever only
    
    **Visualization Queries:**
    - Time-series plots: Plot sensor X vs time → sql_retriever then plot_line_chart then plot_analyzer
    - Distribution plots: Show histogram of RUL values → sql_retriever then plot_distribution then plot_analyzer
    - Comparison plots: Compare actual vs predicted RUL → sql_retriever then predict_rul then plot_comparison then plot_analyzer
    - Custom analysis: Complex requests → sql_retriever then code_execution

    Guidelines:
    1. **Send the path to any HTML files generated to users** when tools return them
    2. **Only use tools if needed** - Not all queries require tool usage
    3. **Choose specialized tools over general code execution** when possible
    4. **For simple queries, provide direct answers without complex processing**
    5. **For RUL lookups, query the rul_data table directly** - Don't use prediction unless explicitly asked
    6. **Reserve prediction tools for explicit prediction requests** - Only use predict_rul when user asks to "predict" or "forecast"
    7. **For ALL visualization queries, use plot_analyzer after plotting** - This generates content descriptions for evaluation
    8. **CRITICAL: Use actual file paths from tool outputs** - Never use placeholder paths like "/path/to/results.json". Always use the exact file path returned by the previous tool.

    ---- 

    **Turbofan Engine Data Context:**
    You work with turbofan engine sensor data from multiple engines in a fleet. The data contains:
    - **Time series data** from different engines with unique wear patterns
    - **Four datasets** (FD001, FD002, FD003, FD004) divided into training and test subsets
    - **26 data columns**: unit number, time in cycles, 3 operational settings, and 21 sensor measurements  
    - **Engine lifecycle**: Engines start normal, then develop faults until system failure
    - **Predictive maintenance goal**: Predict Remaining Useful Life (RUL)
    - **Data characteristics**: Contains normal variation, sensor noise, and progressive fault development
    
    This context helps you understand user queries about engine health, sensor patterns, failure prediction, and maintenance planning.
    
    **CRITICAL RUL Query Classification:**
    **RUL values already exist in the database** (training_data and rul_data tables). Distinguish carefully:
    
    **Simple RUL Lookup (use SQL only):**
    - "What is the RUL of unit X?" → Direct SQL query to rul_data table
    - "Get RUL values for dataset Y" → Direct SQL query 
    - "Show me the remaining useful life of engine Z" → Direct SQL query
    - Questions asking for existing RUL values from specific datasets (RUL_FD001, etc.)
    
    **Complex RUL Prediction (use prediction tools + visualization):**
    - "Predict RUL using sensor data" → Use prediction model + plotting
    - "Compare actual vs predicted RUL" → Use prediction model + visualization
    - "Analyze degradation patterns" → Complex analysis with prediction
    - Questions requiring machine learning model inference from sensor measurements
    
    ----

    **User Input:**
    {input_text}

    Analyze the input and create an appropriate execution plan. Consider:
    1. Is this a simple data lookup, complex analysis, or visualization request?
    2. **For RUL queries**: Is this asking for existing RUL values (lookup) or requesting predictions (modeling)?
    3. What tools are needed in what sequence?
    4. What specific parameters should be used for each tool?
    5. How should the results be presented to the user?
    
    **CRITICAL**: For questions like "What is the RUL of unit X?", this is a simple lookup - use sql_retriever to query rul_data table directly.
    Only use prediction tools when explicitly asked to "predict" or "forecast" RUL values.
    
    Create a clear, actionable plan for the unified assistant to follow.

eval:
  general:
    output:
      dir: "${PWD_PATH}/eval_output"
      cleanup: true
    dataset:
      _type: json
      file_path: "${PWD_PATH}/eval_data/eval_set_master.json"
    # Add delays to prevent rate limiting
    query_delay: 2  # seconds between queries
    max_concurrent: 1  # process queries sequentially
    profiler:
      # Compute inter query token uniqueness
      token_uniqueness_forecast: true
      # Compute expected workflow runtime
      workflow_runtime_forecast: true
      # Compute inference optimization metrics
      compute_llm_metrics: true
      # Avoid dumping large text into the output CSV (helpful to not break structure)
      csv_exclude_io_text: true
      # Idenitfy common prompt prefixes
      prompt_caching_prefixes:
        enable: true
        min_frequency: 0.1
      bottleneck_analysis:
        # Can also be simple_stack
        enable_nested_stack: true
      concurrency_spike_analysis:
        enable: true
        spike_threshold: 7

  evaluators:
    rag_accuracy:
      _type: ragas
      metric: AnswerAccuracy
      llm_name: reasoning_llm
    rag_groundedness:
      _type: ragas
      metric: ResponseGroundedness
      llm_name: reasoning_llm
    rag_relevance:
      _type: ragas
      metric: ContextRelevance
      llm_name: reasoning_llm
