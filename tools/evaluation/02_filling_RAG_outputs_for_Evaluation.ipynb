{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4afa980c-21be-44b8-807e-710b5de56198",
   "metadata": {},
   "source": [
    "##  Notebook 2: Filling RAG outputs For Evaluation\n",
    "\n",
    "In this notebook, we will use the deployed RAG pipeline to populate the RAG outputs: contexts (retrieved relevant documents) and answer (generated by RAG pipeline).\n",
    "\n",
    "The RAG pipeline used as part of this repository needs to be deployed before using steps in [Build and Start API Catalog Containers](https://nvidia.github.io/GenerativeAIExamples/latest/api-catalog.html#build-and-start-the-containers) to expose required API calls from chain-server. \n",
    "\n",
    "If you want to learn more about how the deployed pipelione works in the backend, please see [03_llama_index_simple.ipynb](../notebooks/03_llama_index_simple.ipynb).\n",
    "\n",
    "- **Steps 1**: Setting up the dataset directory and Defining API endpoints \n",
    "- **Step 2**: Ingest Documents\n",
    "- **Step 3**: Fill the RAG outputs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191e7b90-128e-4432-82ab-897426389d06",
   "metadata": {},
   "source": [
    "### Steps 1: Set up Dataset directory and define API endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a18dfc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!test -d dataset || unzip dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a80987e-1ddb-4248-b76c-f3ce16745ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "url_upload = f\"http://chain-server:8081/documents\"\n",
    "url_generate = f\"http://chain-server:8081/generate\"\n",
    "url_doc_search = f\"http://chain-server:8081/search\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e10c13",
   "metadata": {},
   "source": [
    "### Steps 2: Ingest documents\n",
    "Ingest the dataset using the /documents endpoint in the chain-server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdc51db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import mimetypes\n",
    "\n",
    "def upload_document(file_path, url):\n",
    "    headers = {\n",
    "        'accept': 'application/json'\n",
    "    }\n",
    "    mime_type, _ = mimetypes.guess_type(file_path)\n",
    "    files = {\n",
    "        'file': (file_path, open(file_path, 'rb'), mime_type)\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, files=files)\n",
    "\n",
    "    return response.text\n",
    "\n",
    "def upload_pdf_files(folder_path, upload_url):\n",
    "    for files in os.listdir(folder_path):\n",
    "        _, ext = os.path.splitext(files)\n",
    "        # Ingest only pdf files\n",
    "        if ext.lower() == \".pdf\":\n",
    "            file_path = os.path.join(folder_path, files)\n",
    "            print(upload_document(file_path, upload_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c89f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "upload_pdf_files(\"dataset\",url_upload )\n",
    "print(f\"--- {time.time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a58983-2069-450e-adf9-24b0f8736498",
   "metadata": {},
   "source": [
    "### Step 3: Fill the RAG outputs \n",
    "\n",
    "Let's now query the RAG pipeline and fill the outputs `contexts` and `answer` on the evaluation JSON file.\n",
    "\n",
    "First, we need to load the previously generated dataset. So far, the RAG outputs fields are empty.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f0f304-3476-42e3-9be7-1ab38f9e14cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the relevant libraries\n",
    "import json\n",
    "from IPython.display import JSON\n",
    "\n",
    "# load the evaluation data\n",
    "f = open('qa_generation.json')\n",
    "data = json.load(f)\n",
    "\n",
    "# show the first element\n",
    "JSON(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b4321b-dfce-4c72-a8f1-2e2264b3c59d",
   "metadata": {},
   "source": [
    "Let now query the RAG pipeline and populate the `contexts` and `answer` fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339cbb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "\n",
    "generate_api_params={\"use_knowledge_base\": True, \"temperature\":0.2,\"top_p\":0.7,\"max_tokens\": 256}\n",
    "document_search_api_params={\"num_docs\": 1}\n",
    "new_data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f238d58-071a-4bb9-956c-d014748c15ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for entry in data:\n",
    "    entry_generate = {\n",
    "        \"messages\":[\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\":entry[\"question\"]\n",
    "            }\n",
    "        ],\n",
    "        \"use_knowledge_base\": generate_api_params[\"use_knowledge_base\"],\n",
    "        \"temperature\": generate_api_params[\"temperature\"],\n",
    "        \"top_p\": generate_api_params[\"top_p\"],\n",
    "        \"max_tokens\": generate_api_params[\"max_tokens\"],\n",
    "        \"stop\":[\n",
    "                \"string\"\n",
    "        ]\n",
    "    }\n",
    "    entry[\"answer\"] = \"\"\n",
    "    try:\n",
    "        with requests.post(url_generate, stream=True, json=entry_generate) as r:\n",
    "            for chunk in r.iter_lines():\n",
    "                raw_resp = chunk.decode(\"UTF-8\")\n",
    "                if not raw_resp:\n",
    "                    continue\n",
    "                resp_dict = None\n",
    "                try:\n",
    "                    print(raw_resp)\n",
    "                    resp_dict = json.loads(raw_resp[6:])\n",
    "                    resp_choices = resp_dict.get(\"choices\", [])\n",
    "                    if len(resp_choices):\n",
    "                        resp_str = resp_choices[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "                        entry[\"answer\"] += resp_str\n",
    "                except Exception as e:\n",
    "                    print(f\"Exception Occured: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception Occured: {e}\")\n",
    "        entry[\"answer\"] = \"Answer couldn't be generated.\"\n",
    "    print(entry[\"answer\"])\n",
    "    entry_doc_search = {\n",
    "            \"query\": entry[\"question\"],\n",
    "            \"top_k\": document_search_api_params[\"num_docs\"]\n",
    "        }\n",
    "    response = requests.post(url_doc_search, json=entry_doc_search).json()\n",
    "    context_list =typing.cast(typing.List[typing.Dict[str, typing.Union[str, float]]], response)\n",
    "    contexts = [context.get(\"content\") for context in context_list['chunks']]\n",
    "    try:\n",
    "        entry[\"contexts\"] = [contexts[0]]\n",
    "    except Exception as e:\n",
    "        print(f\"Exception Occured: {e}\")\n",
    "        entry[\"contexts\"] = \"\"\n",
    "    new_data.append(entry)\n",
    "    print(len(entry[\"contexts\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14407673-a8f1-4245-8748-d6885e08f06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_list_string=json.dumps(data)\n",
    "\n",
    "# show again the first element\n",
    "JSON(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa9f140-5989-4c3c-98af-18ec63a954b9",
   "metadata": {},
   "source": [
    "Let now save the new evaluation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958653ba-4228-4c81-8f65-81ead7c8254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('eval.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248982b8-9f9e-4021-a326-657e2e82d43d",
   "metadata": {},
   "source": [
    "In the next notebook, we will evaluate the [Corp Comms Copilot](https://gitlab-master.nvidia.com/chat-labs/rag-demos/corp-comms-copilot) RAG pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
